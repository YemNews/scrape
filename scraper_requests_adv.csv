title,link,published,source,text
Generative AI Is Coming for Sales Execs' Jobs—and They're ... - WIRED,https://www.wired.com/story/generative-ai-chatgpt-is-coming-for-sales-jobs/,"Thu, 05 Oct 2023 11:00:00 GMT",WIRED,
Hurtling toward generative AI adoption? Why skepticism is your best protection - ZDNet,https://www.zdnet.com/article/hurtling-toward-generative-ai-adoption-why-skepticism-is-your-best-protection/,"Wed, 04 Oct 2023 17:36:41 GMT",ZDNet,"zf L/Getty Images

With some organizations moving ahead to adopt generative artificial intelligence (AI), it is critical they do so while mitigating potential risks and with some level of skepticism.

As it is, 45% of businesses are currently piloting generative AI, while 10% already have such tools in production, revealed a Gartner study released Tuesday. The survey polled 1,419 executives during a webinar last month to discuss business costs and risks of generative AI.

Also: AI safety and bias: Untangling the complex chain of AI training

These figures are significantly higher than a previous poll that Gartner ran in March and April this year, during which 15% reported piloting the technology and just 4% had these tools in production.

In the latest survey, some 78% said the benefits of generative AI outweighed its risks, higher than the 68% who thought likewise in the earlier poll.

Gartner noted that 45% of businesses were scaling up their generative AI investments across multiple functions, with 22% doing so across at least three different functions. Investment or adoption of generative AI in software development clocked the highest rate, at 21%, followed by marketing and customer service at 19% and 16%, respectively.

""Organizations are not just talking about generative AI -- they're investing time, money, and resources to move it forward and drive business outcomes,"" said Frances Karamouzis, Gartner's group chief of research and distinguished analyst, noting that 55% of organizations had increased their investment in generative AI since its emergence in the public domain 10 months ago.

""Executives are taking a bolder stance on generative AI as they see the profound ways that it can drive innovation, optimization, and disruption,"" said Karamouzis. ""Business and IT leaders understand that the 'wait and see' approach is riskier than investing.""

When having doubt is necessary

Should businesses decide to move ahead, though, they should have the framework in place to ensure they are adopting generative AI responsibly and ethically.

Some level of skepticism also should apply, including toward tools used to detect when AI has been applied, said Kathy Baxter, Salesforce.com's principal architect of responsible AI.

Also: How AI can improve cybersecurity by harnessing diversity

Baxter noted that the technology has become democratized, enabling anyone to use generative AI without many handrails. But while many organizations are doing a decent job in trying to weed out toxic content and continuing to invest in such efforts, there still is not yet a lot of understanding on ""how big a grain of salt"" one should take with regard to AI-generated content.

Users regard all of such content as fact even if it is fabricated, Baxter said in an interview with ZDNET, noting that even AI detecting tools can be wrong in some instances, but may be deemed to be always accurate. Such perceptions may have an adverse impact when generative AI and its associated tools are used in some areas such as education, where students may be wrongly accused of using AI in their work.

Expressing her concerns over such risks, she urged any individual or organization using generative AI to do so with ""enough skepticism"".

Like others in the industry, she echoed the need for sufficient guardrails in place to ensure AI is accurate and safe. It would help, too, if deployments were rolled out alongside risk mitigation tools, she added. These can include fault detection and reporting features, and mechanisms to collect and provide human feedback.

Also: 5 handy AI tools for school that students, teachers, and parents can use, too

Grounding AI also is critical, she said, stressing the importance of data used to train AI models. Not many organizations, though, have good data hygiene, she noted.

In fact, just 4% of business and technology leaders described their data as fully accessible, according to the C-Suite Global AI Indicator Report released last month. Commissioned by Workday, the study polled 2,355 executives across Asia-Pacific, Japan, North America, and EMEA, who led various functions and included CEOs, CIOs, and CFOs.

More than half of respondents, at 59%, described their data as somewhat or completely siloed, the survey found.

While 98% believed there would be some immediate business benefit from deploying AI and machine learning, 49% said their organization was unprepared to do so due to a lack of tools, skills, and knowledge.

Some 43% expressed concern about the trustworthiness of AI and machine learning, with 67% of CEOs pointing to potential errors as a top risk of bringing on AI and machine learning.

Also: Is AI lying to us? These researchers built an LLM lie detector of sorts to find out

Increased transparency is needed to build trust, but siloed data is obscuring leaders' ability to lean in. Of organizations surveyed, 59% reported that their data is somewhat or completely siloed. Only 4% of all respondents said their data is fully accessible.

Workday CTO Jim Stratton said: ""Despite some uncertainty, leaders are optimistic that AI and machine learning will augment their workforce and drive productivity. Trust is paramount to embracing these benefits, and building trust requires the right data foundation and commitment to governance.""

Stratton urged organizations to prioritize data quality and transparency when implementing AI, in order to benefit from the technology."
Advancing generative AI exploration safely and securely - TechCrunch,https://techcrunch.com/2023/10/05/advancing-generative-ai-exploration-safely-and-securely/,"Thu, 05 Oct 2023 14:21:23 GMT",TechCrunch,"Security concerns are inexorably intertwined with the exploration and implementation of generative AI. According to a recent report featuring data we commissioned, 49% of business leaders consider safety and security risks a top concern, while 38% identified human error or human-caused data breaches arising from a lack of understanding of how to use GPT tools.

While these concerns are valid, the benefits early adopters stand to see far outweigh the potential downsides of limiting integration.

I want to share what I have learned from helping our teammates and clients alike understand why security should not be an afterthought but a prerequisite for integrating AI into the business, and some best practices for doing so.

The AI conversation starts with a safe-use policy

Companies understand the urgency with which they need to respond to the new security risks AI presents. In fact, according to the report referenced above, 81% of business leaders said their company already has implemented or was in the process of establishing user policies around generative AI.

Guardrails for testing and learning are essential to accelerating exploration while minimizing security risks.

However, because of the rapidly evolving nature of the technology — with new applications and use cases emerging every day — the policy should be continuously updated to address emerging risks and challenges.

Guardrails for testing and learning are essential to accelerating exploration while minimizing security risks. The policy also should not be created in a silo. Representation from across the business is important to understand how the technology is being or could be used by each function to account for unique security risks.

Importantly, skunkworks exploration of AI should not be banned altogether. Companies that resist it out of fear will no longer have to worry about competitors eroding their market share; they’ve already done that for themselves.

Enabling citizen developers

In order to ensure we use AI in a safe manner, we first gave our citizen developers carte blanche access to use a private instance of our large language learning model, Insight GPT. This has not only helped us identify potential use cases but also allowed us to stress test its outputs, enabling us to make continued refinements."
AI Model Collapse Prevention: Analyzing the Best Practices - Appinventiv,https://appinventiv.com/blog/ai-model-collapse-prevention/,"Thu, 05 Oct 2023 08:54:37 GMT",Appinventiv,"Artificial Intelligence (AI) has significantly transformed our everyday lives by suggesting personalized content on streaming platforms and enabling digital assistants on smartphones. Now, these advancements are made possible by sophisticated AI models that learn from vast amounts of data.

As per various reports, AI-generated content is becoming increasingly prevalent on the internet, potentially comprising up to 90% of online information in the coming years.

With such an influx of information, one can easily say that in today’s data-rich world, AI faces a unique challenge, and that is choking on its abundance of data.

The reports further suggest that the significant amount of this AI-generated content can overwhelm people with excessive information, making it difficult for them to determine what is trustworthy and human-generated. In addition, there are concerns about the potential loss of jobs in creative fields such as art, journalism, and writing, all because AI is becoming more capable of producing content traditionally created by humans.

Coming to the AI systems themselves, there are emerging issues like “Model Collapse,” which refers to a problem where AI models that are trained on large datasets produce lower-quality outputs by prioritizing common word choices over creative alternatives. “Model Autophagy Disorder” or “Habsburg AI” is another concern where AI systems excessively trained on the outputs of other AI models can exhibit undesirable features or may have biases.

These challenges can potentially harm the quality and reliability of AI-generated content, destroying the trust in such systems and worsening the information overload.

Our blog will help you understand everything related to addressing AI model collapse prevention. As the generative AI revolution progresses, it brings forth significant challenges and uncertainties for the online information landscape. So, let’s dive into the details head-on.

Understanding AI Model Collapse

In machine learning, “model collapse” refers to a situation where the AI model fails to provide a variety of useful outputs. Instead, it produces a narrow set of repetitive or low-quality results. This issue can occur in various models, but it’s often observed during training complex models like generative adversarial networks (GANs). Model collapse can hamper the model’s ability to generate diverse and valuable outputs, impacting its overall performance.

Let’s illustrate a model collapse example. Imagine a highly enthusiastic art student representing our AI model, which is tasked with creating paintings of zebras. In the beginning, their artwork is impressive and distinctly resembles zebras. However, their paintings gradually lose their resemblance to zebras as they continue, and the quality declines. This is similar to “model collapse” in machine learning, where the AI model, like our art student, initially performs well but then struggles to maintain the essential characteristics it was designed to perform.

As per the recent advancements in AI, researchers have become very interested in using artificial or synthetic data to train new AI models when it comes to generating images and text. However, a concept called ‘Model Autophagy Disorder’ (MAD) compares this process to a self-destructive loop.

Unless we keep adding fresh real-world data regularly, the quality and variety of the AI models we create using synthetic data could worsen over time. So, it’s essential to strike a balance between synthetic and real data to keep AI models performing well.

This balance is crucial to prevent a decline in the quality and diversity of the models as they continue to learn. Finding out how to effectively use synthetic data for AI model collapse prevention is an ongoing challenge when it comes to the evolution of generative AI and the use of synthetic data.

According to The New Yorker, if ChatGPT is considered a compact version of the internet, similar to that of a JPEG file compressing a photograph, then training the future chatbots on the results of ChatGPT’s is digitally equivalent to repeatedly making photocopies of photocopies just like the old days. Simply, the image quality is bound to get worse with each iteration.

Thus, to overcome this challenge, organizations need to focus on refining their approaches to ensure these generative AI products continue to provide accurate responses in this digital landscape.

[Also Read: Responsible AI – Addressing Adoption Challenges With Guiding Principles and Strategies]

How Does AI Model Collapse Happen?

Model collapse occurs when new AI models are trained using data generated by older models. These new models rely on the patterns seen in the generated data. Model collapse is rooted in the idea that generative models tend to repeat patterns they have already learned, and there’s a limit to the information they can extract from these patterns.

In cases of model collapse, events that are likely to happen are exaggerated, while less likely events are underestimated. Over multiple generations, likely events dominate the data, and the less common but still crucial parts of the data, called tails, diminish. These tails are essential to maintaining the accuracy and diversity of the model’s outputs. As generations progress, errors conquer the data, and the model increasingly misinterprets it.

According to the research, there are two types of model collapse: early and late. Early model collapse involves the model losing information about rare events. In late-model collapse, the model blurs distinct patterns in the data, resulting in outputs that have little resemblance to the original data.

Let us look at multiple reasons for AI model collapse in detail below:

Loss of Rare Events

When AI models are repeatedly trained on data generated by their previous versions, they try to focus on common patterns and forget rare events. This phenomenon is similar to the models losing their long-term memory. Rare events often hold significant importance, such as identifying anomalies in manufacturing processes or detecting fraudulent transactions. For example, when it comes to fraud detection, specific language patterns may signal fraudulent behavior, making it crucial to retain and learn these rare patterns.

Amplification of Biases

Each training iteration on AI-generated data can amplify the existing biases in the training data. Since the model’s output usually reflects the data it was trained on, any biases within that data can be exaggerated with time. This can lead to bias amplification in various AI applications. For instance, the results can lead to issues like discrimination, racial bias, and biased social media content. Thus, implementing controls to detect and mitigate bias is extremely essential.

Narrowing of Generative Capabilities

As AI models continue learning from their generated data, their generative capabilities can narrow. The model becomes rather influenced by its own interpretations of reality, producing increasingly similar content that lacks diversity and representation of rare events. This can lead to a loss of originality. For instance, when it comes to Large Language Models (LLMs), the variation imparts each writer or artist with their distinct tone and style.

Research simply suggests that if fresh data is not added regularly during the training process, future AI models could end up becoming less accurate or producing less varied results over time.

Functional Approximation Error

A functional approximation error can occur when the function approximators used in the model are not expressive enough. While this error can be mitigated by employing more expressive models, it can also introduce noise and lead to overfitting. Striking the right balance between the model expressiveness and noise control is crucial to prevent these errors.

Implications of Model Collapse: Why AI Model Stability Matters?

Model collapse can ultimately impact the quality, reliability, and fairness of AI-generated content, which can further pose several risks to organizations. Let us look at the implication of model collapse in detail below:

Quality and Reliability

As AI models degenerate in their learning, the content they generate becomes less reliable, and their quality degrades. This happens when the models detach from the original data distribution and rely more on their own interpretations of reality. For instance, an AI model designed for news generation may produce inaccurate or even completely fabricated news articles.

Fairness and Representation

Model collapse is also a cause for concern when it comes to fairness and representation of the generated content. When models forget rare events and limit their generative abilities, content related to less common topics may be inadequately represented. This leads to biases, stereotypes, and the exclusion of certain perspectives.

Ethical Concerns

Model collapse poses significant ethical concerns, specifically when AI-generated content has the power to influence decision-making. The consequences of model collapse include the spread of biased and inaccurate content, which can significantly impact people’s lives, opinions, and access to opportunities.

Economic and Social Impact

On an economic and social scale, model collapse can influence trust and adoption of AI technologies. If AI-generated content cannot be relied upon, businesses and consumers may hesitate to embrace these technologies. This can have economic implications, and trust in AI technologies can hamper consequently.

AI Hallucination

AI hallucination is when AI models create imaginative or unrealistic content that doesn’t align with facts or is coherent in any way. This can result in inaccurate information, potentially causing misinformation or confusion. It’s significantly problematic in applications like generating news, diagnosing medical conditions, or creating legal documents where accuracy and reliability are extremely vital.

Let us explain the context with an AI hallucination example. Suppose there is an AI model that is trained to generate pictures of animals. Now, upon requesting a picture of an animal, the model might produce an image of a “zebroid,” a hybrid between a zebra and a horse. While this image may feel visually realistic, it is vital to understand that it is only a creation of the AI model’s imagination, as no such animal exists in the real world.

AI Model Collapse Prevention: Understanding the AI Model Collapse Solutions

To ensure the AI model stability and reliability, it is essential to explore strategies and best practices for effectively addressing AI model collapse prevention. Thus, it is recommended to partner with a dedicated AI development firm like Appinventiv that can provide expertise and guidance in implementing these preventive measures while ensuring your AI systems consistently deliver high-quality results.

Diverse Training Data

For effectively addressing AI model collapse and preventing undesired outputs, it is crucial to curate a training dataset that includes a variety of data sources and types. This dataset should consist of both synthetic data generated by the model and real-world data that accurately represent the complexities of the problem. It is important to regularly update this dataset with new and relevant information. The model is exposed to a wide range of patterns by incorporating diverse training data. This helps in preventing data stagnation.

Regularly Refresh Synthetic Data

Model collapse is a risk when AI models rely heavily on their own generated data. For effective risk mitigation in AI, it is important to regularly introduce new, authentic, real-world data into the training pipeline. This practice ensures the model remains adaptive and avoids getting stuck in a repetitive loop. This can help in generating diverse and relevant outputs.

Augment Synthetic Data

Enhancing synthetic data through data augmentation techniques is a proven method to prevent model collapse. These techniques introduce variability into the synthetic data using the natural variations in real-world data. Adding controlled noise to the generated data encourages the model to learn a wider range of patterns, reducing the chances of generating repetitive outputs.

Monitoring and Regular Evaluation

Regularly monitoring and evaluating AI model performance is crucial for early detection of model collapse. Implementing an MLOps framework ensures ongoing monitoring and alignment with the goals of an organization, thereby enabling timely interventions and adjustments.

[Also Read: How to Avoid Compliance Violations While Developing AI Products]

Fine-Tuning

It is important to consider implementing fine-tuning strategies to maintain model stability and prevent collapse. These strategies for preventing AI model failure enable the model to adapt to new data while preserving its previous knowledge.

Bias and Fairness Analysis

Rigorous bias and fairness analysis are crucial in preventing model collapse and ethical issues. It is essential to identify and address biases in the model’s outputs. You can maintain reliable and unbiased model outputs by actively addressing these concerns.

Feedback Loops

Implementing feedback loops that incorporate user feedback is crucial in preventing model collapse. By consistently gathering user insights, informed adjustments can be made to the model’s outputs. This refinement process guarantees that the model remains relevant, reliable, and aligned with user expectations.

How can Appinventiv Help with Risk Mitigation in AI Models?

In the evolving landscape of AI, the challenges posed by model collapse have been a concern for both tech giants and innovators alike. The long-term deterioration of language model datasets and the manipulation of content have left their mark on this digital ecosystem.

As AI advances, it is vital to differentiate between artificially generated data and human-generated content. The line between genuine content and what’s generated by a machine is becoming increasingly blurred.

Now, amidst these challenges and preventing AI model failure, partnering with a dedicated AI development company like Appinventiv can provide you with much-needed solace. With expertise in AI model development and a dedicated commitment to ethical AI practices, we can help you navigate the complexities of AI while ensuring the reliability and integrity of your AI systems.

Our experts can work with you in addressing AI model collapse prevention effectively, promote transparency, and build a future with authentic content that doesn’t compromise the authenticity of human-generated content.

We understand that training AI models with fresh, diverse data is essential to prevent model degradation. AI model evaluation is a pivotal step in our model development process that employs metrics to assess performance, pinpoint weaknesses, and ensure effective future predictions.

Our expert team can help ensure that your AI systems continue to learn and adapt to the evolving digital landscape. Get in touch with our experts to mitigate the risks associated with model collapse and ensure their effectiveness.

FAQs

Q. What is AI model collapse?

A. AI Model collapse in machine learning refers to the AI model’s failure to produce a diverse range of useful outputs. Instead, it generates repetitive or low-quality results. This problem can occur in different types of models, but it is particularly observed during the training of complex models like generative adversarial networks (GANs).

Q. What are the common causes of AI model collapse?

A. Common causes of AI model collapse include loss of rare events, amplification of biases, narrowing of generative capabilities, functional approximation errors, etc. These factors can lead to models producing suboptimal outputs.

Q. How can I prevent AI model collapse?

A. For effective AI model collapse prevention, using different and real-world-like training data is vital, continuously monitoring and evaluating data, fixing any biases, and implementing rigorous testing and quality control. Partnering with the AI experts at Appinventiv can offer you valuable insights and solutions to mitigate model collapse risks."
AI in Cybersecurity: A Mixed Bag for Vulnerability Detection ... - Cryptopolitan,https://www.cryptopolitan.com/ai-in-cybersecurity/,"Wed, 04 Oct 2023 17:50:27 GMT",Cryptopolitan,"TLDR The intersection of artificial intelligence (AI) and cybersecurity has been scrutinized.

One of the primary areas of interest is the feasibility of employing generative AI chatbots for code vulnerability assessment.

The report highlights a promising application of machine learning (ML) models in the realm of cybersecurity.

In a recent report released by NCC Group, the intersection of artificial intelligence (AI) and cybersecurity has been scrutinized, shedding light on both the promises and limitations of generative AI in the context of code vulnerability detection. The report, titled “Safety, Security, Privacy & Prompts: Cyber Resilience in the Age of Artificial Intelligence,” offers a comprehensive analysis of various AI cybersecurity use cases.

Generative AI and code vulnerabilities

The explosive growth of generative AI technology in late 2022 sparked discussions and concerns regarding its implications for cybersecurity. One focal point of this discourse revolves around the potential security risks posed by generative AI chatbots. These risks range from inadvertent exposure of sensitive business information to the possibility of malicious actors exploiting these advanced self-learning algorithms to bolster their cyberattacks.

One of the primary areas of interest within the report is the feasibility of employing generative AI chatbots for code vulnerability assessment. Can these AI systems, when provided with source code, conduct an interactive form of static analysis and accurately pinpoint security weaknesses? The report’s findings indicate a mixed bag of results. While generative AI shows promise and productivity gains in code and software development, its effectiveness in detecting code vulnerabilities remains variable.

On the flip side, the report highlights a promising application of machine learning (ML) models in the realm of cybersecurity. Specifically, ML models can be instrumental in identifying novel zero-day attacks, enabling an automated response to safeguard users from malicious files. To validate this concept, NCC Group sponsored a master’s student at University College London’s Centre for Doctoral Training in Data Intensive Science (CDT DIS) to develop a classification model for identifying malware.

The results of this endeavor are compelling. The classification model achieved an impressive accuracy rate of 98.9%. This success underscores the potential of ML models in bolstering cybersecurity defenses by swiftly identifying and mitigating emerging threats.

Harnessing threat intelligence with AI

Another critical facet explored in the report revolves around threat intelligence, a pivotal component of proactive cybersecurity. Threat intelligence involves the continuous monitoring of various online data sources, which provide valuable insights into newly identified vulnerabilities, evolving exploits, and emerging trends in attacker behavior. This data, often in the form of unstructured text from forums, social media, and the dark web, can be a goldmine of information.

Machine learning models can play a vital role in processing this data, extracting key cybersecurity nuances, and identifying patterns and trends in attacker tactics, techniques, and procedures (TTP). Armed with these insights, defenders can take a proactive and pre-emptive approach to implement additional monitoring or control systems, especially when new threats pose a significant risk to their business or technology landscape.

In an era marked by rapid technological advancement, the role of AI in cybersecurity continues to evolve. While generative AI chatbots offer promise in certain aspects of code development, their reliability in detecting vulnerabilities remains a matter of ongoing exploration. On the other hand, ML models demonstrate a high level of potential in identifying and combating novel cyber threats, making them a valuable asset in the defender’s arsenal.

It is crucial to acknowledge that AI in cybersecurity is not a one-size-fits-all solution. Rather, it complements human expertise and vigilance. The partnership between human cybersecurity professionals and AI systems is essential to strike a balance between harnessing the power of automation and maintaining the critical human oversight needed to navigate the ever-evolving threat landscape."
Walmart experiments with generative AI tools that can help you plan a party or decorate - TechCrunch,https://techcrunch.com/2023/10/04/walmart-experiments-with-new-generative-ai-tools-that-can-help-you-plan-a-party-or-decorate-a-space/,"Wed, 04 Oct 2023 20:21:23 GMT",TechCrunch,"After launching a generative AI tool for corporate employees in August, Walmart is bringing the technology to its customers. During a demo with TechCrunch, a company spokesperson outlined how the retail giant is experimenting with generative AI to help shoppers in all stages of the shopping experience, from the search and discovery phase to making a purchase. Three features coming down the pipeline include a shopping assistant, generative AI-powered search and an interior design feature.

Walmart declined to share which AI models it’s using to develop these features, but says it’s using a variety of different external models and they may change over time.

“Other companies are essentially locking themselves into working with Anthropic or OpenAI,” the spokesperson told us. “We want to have that flexibility to put in and out different models.”

The new shopping assistant — which is launching in the coming weeks — will allow customers to have a more interactive and conversational experience as it can answer specific questions, provide personalized product suggestions and share detailed information about a certain product. For instance, it can give shoppers Halloween costume ideas to wear to a horror-themed party or which cell phone a parent should buy for their child.

Similarly, users will soon be able to enter specific questions directly in the search bar. With the use of generative AI, Walmart’s search tool can understand context and generate a collection of items relevant to one query. For example, if a customer wants to plan for a unicorn-themed birthday, the AI displays a wide array of products such as balloons, paper napkins, streamers and so on. Instead of having to type in numerous separate searches, Walmart’s new AI search tool is designed to save customers time.

We also see this being done by other companies like Instacart, which recently rolled out a ChatGPT-powered search tool that can generate suggestions like a selection of high-protein foods or Thanksgiving dinner ideas. Plus, Meta announced a new Bing-backed AI Assistant last month as well as an AI personality chatbot, among other tools.

Walmart is also developing an interior design assistant for customers to decorate their rooms. In addition to generative AI, the feature also leverages AR technology; users must upload a photo of a room and it will then take an image capture of every item that’s in the space. Customers ask the chat assistant for advice on how they should redecorate, and the AI places items in the room that they suggest. Users can express their opinions on which items they want to keep or buy. The AI also asks for a budget so it can find items that are affordable.

The continued investment in generative AI tools is a common theme these days as more companies rush to integrate the technology into their products and services.

“Generative AI technology is a priority for the company,” said the Walmart spokesperson.

The new tools come on the heels of Walmart rolling out its AI app, “My Assistant,” to 50,000 corporate employees in the U.S. to streamline tasks like summarizing documents, helping prep for meetings and speeding up projects. Walmart has been getting “great feedback” about the app and even found some employees using the assistant to draft “funny out-of-office messages,” the spokesperson added."
New Generative AI-Native Health Company RhythmX AI Announces ... - PR Newswire,https://www.prnewswire.com/news-releases/new-generative-ai-native-health-company-rhythmx-ai-announces-precision-care-platform-for-doctors-to-deliver-hyper-personalized-care-to-the-right-patient-at-the-right-time-301947898.html,"Thu, 05 Oct 2023 10:30:00 GMT",PR Newswire,"Founded by healthcare leader Deepthi Bathina, chaired by AI entrepreneur Dr. Romesh Wadhwani, with an initial funding of $50M by enterprise AI investment company SAIGroup, RhythmX AI will address nearly $4T spent annually on chronic conditions

PALO ALTO, Calif., Oct. 5, 2023 /PRNewswire/ -- SAIGroup announced the funding and launch of RhythmX AI, a generative AI-native precision care company building a platform to free up doctors to deliver hyper-personalized patient care. RhythmX AI delivers to doctors advanced generative AI capabilities and predictive AI algorithms based on extensive longitudinal data. These provide patient-specific prescriptive actions and recommendations doctors can drill into using a generative AI-enabled natural language interface and AI-native copilots.

""It's time to apply AI to the massive challenges doctors and hospital systems face in providing the best treatments for patients,"" said Dr. Romesh Wadhwani, founder and CEO of SAIGroup and recently honored on the inaugural TIME100 AI list. ""SAIGroup's strategy of combining deep domain expertise with advanced AI has a successful track record with SymphonyAI and ConcertAI and will do the same with RhythmX AI. The rapidly growing team at RhythmX AI has the right assets, data, AI expertise, and the right capital and leadership to solve these barriers.""

RhythmX AI's platform works in concert with existing healthcare systems. The data and rationale behind AI-enabled recommendations are explained, summarized, and presented in a single workflow. RhythmX AI's models will tap into various assets of SAIGroup including longitudinal data related to 300 million patients, more than 4.4 billion total annual claims, and more than 1.8 million healthcare professionals at more than 300 thousand facilities. The company will continue to expand its network of data sources as the range of chronic and acute conditions covered in the platform increases.

""Providing the right care at the right time to the right patient is more challenging than ever,"" said RhythmX AI CEO Deepthi Bathina, former chief clinical product officer at Humana. ""Chronic conditions absorb nearly 90% of healthcare spending in the U.S. That's exacerbated by a shortage of physicians who in turn face increasingly high expectations to deliver integrated care above and beyond their current load. This is where we need to focus new AI technologies, as we help doctors operate at the top of their license each day.""

The RhythmX AI team includes clinical leaders, operators and healthcare and technology experts. Additionally, RhythmX AI is also building a clinical advisory board with progressive visionary leaders in the healthcare industry with deep leadership experience in various areas including clinical, strategy, operations and innovation. The inaugural clinical advisory board which will be providing strategic guidance to RhythmX AI includes:

Gregg Meyer , MD, MSc President of Community Division and Executive Vice President of Value-based Care at Mass General Brigham

, MD, MSc President of Community Division and Executive Vice President of Value-based Care at Mass General Brigham Sunny Bhatia, MD, CEO of Prime Healthcare, Region I, and Corporate Chief Medical Officer for all Prime Health locations

Jordan Asher, MD, MS, Executive Vice President and Chief Clinical Officer of Sentara Health

""It's never been more important to support doctors and free them up to deliver the integrated whole-person care which is so difficult to do given how much data needs to be read and processed within seconds,"" said Dr. Gregg Meyer, president of community division and executive vice president of value-based care at Mass General Brigham. ""Physicians are now considering clinical experience, social determinants, lifestyle factors and mental health factors to deliver on hyper-personalized interventions, especially to patients with rising risk. There is a critical need in the industry for a platform that can aid physicians to solve these issues. This is the mission of RhythmX AI, and I am thrilled to join their inaugural clinical advisory board.""

SAIGroup's backing brings to RhythmX AI the expertise and resources of portfolio companies SymphonyAI and ConcertAI. ConcertAI is the leader in real-world data and enterprise AI for life sciences and healthcare. SymphonyAI is the leader in enterprise AI for vertical sectors, including retail, financial services, manufacturing, media, and IT.

RhythmX AI will use SAIGroup's Eureka AI platform, which serves as the foundation for advanced AI solutions for thousands of global customers including Fortune 500 companies. EurekaAI uses unsupervised, supervised, and semi-supervised machine learning techniques to uncover new insights and predictions. Worldwide, 35 of the top life sciences companies, nine of the top 10 oncology companies, and more than 900 leading healthcare providers use EurekaAI-based solutions.

About RhythmX AI

RhythmX AI is a generative AI-native health company driving a paradigm shift in hyper-personalized care. RhythmX AI's precision care platform helps physicians pioneer a new era of whole person care through generative and predictive AI-powered copilots. An SAIGroup company, RhythmX AI will leverage various assets of the firm including the advanced Eureka AI platform and longitudinal data related to 300 million patients, more than 4.4 billion total annual claims, and more than 1.8 million healthcare professionals at more than 300 thousand facilities. RhythmX AI comprises healthcare and technology experts, operators, and the industry's leading clinical advisors.

About SAIGroup

SAIGroup is a private investment firm building leading enterprise AI businesses by accelerating innovation and growth. SAIGroup companies ConcertAI, SymphonyAI, and RhythmX AI comprise more than 4,000 employees. Founder and CEO Dr. Romesh Wadhwani has committed $1 billion of investment capital to SAIGroup. www.saigroup.ai.

Media Contact: Chris Gale at [email protected]

SOURCE SAIGroup"
Robust Intelligence and MongoDB Partner to Secure Generative AI ... - PR Newswire,https://www.prnewswire.com/news-releases/robust-intelligence-and-mongodb-partner-to-secure-generative-ai-and-enterprise-data-301947767.html,"Thu, 05 Oct 2023 10:00:00 GMT",PR Newswire,"SAN FRANCISCO, Oct. 5, 2023 /PRNewswire/ -- Robust Intelligence , the leading end-to-end AI risk management company, today announced a partnership with MongoDB to help customers thoroughly and efficiently secure generative AI models enhanced with enterprise data. The offering combines Robust Intelligence's real-time AI Firewall with MongoDB Atlas Vector Search for an enterprise-ready solution that enables responsible innovation.

Recent advancements in generative AI have motivated companies to experiment with potential applications, but a lack of security, ethical, and operational controls may have exposed companies to unmanaged risk. This challenge is exacerbated when sensitive company information is used to enrich pre-trained models, such as connecting vector databases, in order to increase the relevance to the end user.

The technology partnership between Robust Intelligence and MongoDB helps solve these challenges. Customers can confidently connect MongoDB Atlas Vector Search to any commercial or open-source large language models (LLMs) for retrieval-augmented generation knowing that Robust Intelligence's AI Firewall is validating the inputs and outputs. This provides real-time protection against prompt injection, PII extraction, hallucination, and many other risks.

""Generative AI introduces an unmanaged security risk, which is compounded when enriching LLMs with supplemental data,"" said Lena Smart, Chief Information Security Officer of MongoDB. ""Robust Intelligence's AI Firewall solves this critical problem, giving enterprises the confidence to use LLMs at scale. Our partnership makes it easier for customers to use generative AI while also keeping their data secure with guardrails in place.""

Through the integration, customers will also be able to pass AI Firewall logs to MongoDB to store historical data. This can be used to identify advanced security attacks that often manifest across a cluster of data points as opposed to a single data point, such as data poisoning and model extraction.

""Enterprises rely on MongoDB to streamline the development of AI-enriched applications. It's essential that this sensitive information remains secure,"" explained Yaron Singer, Chief Executive Officer and co-founder of Robust Intelligence. ""We're thrilled to bring the joint value of AI Firewall and MongoDB Atlas Vector Search to our customers.""

Robust Intelligence is part of the MongoDB Partner Program. To learn more and sign up for access to AI Firewall, please visit www.robustintelligence.com/ai-firewall-mongodb .

About Robust Intelligence

Robust Intelligence is the leader in end-to-end AI risk management, protecting organizations from security, ethical, and operational risks. The company's platform protects models in real time with AI Firewall and automates testing and compliance across the AI lifecycle through continuous validation. This combined approach enables Robust Intelligence to proactively manage risk for any model type and gives organizations the confidence to unleash the true potential of AI. The company is backed by Sequoia Capital and Tiger Global, and trusted by leading companies including ADP, JPMorgan Chase, Expedia, Deloitte, Cisco, and the U.S. Department of Defense.

Media Contact

press@robustintelligence.com

SOURCE Robust Intelligence"
POSITIVE OUTLOOK ON GENERATIVE AI FUELLING 70 ... - PR Newswire,https://www.prnewswire.com/news-releases/positive-outlook-on-generative-ai-fuelling-70-workplace-adoption-rate-but-training-gaps-persist-301948648.html,"Thu, 05 Oct 2023 16:00:00 GMT",PR Newswire,"Adecco Group releases annual worker perceptions study, Global Workforce of the Future Report 2023

70% of workers are already using Generative AI (GenAI) at work, but less than half are doing so with guidance from employers

Despite expert anticipation of widespread impact, only 7% of workers expect their jobs to become obsolete as GenAI becomes ubiquitous

Gaps in access to GenAI training and adoption rates have emerged, with executives, high-earners, and advanced degree holders advantaged

GenAI is set to replace many technical skills, increasing the value of soft skills in the workplace

ZURICH, Oct. 5, 2023 /PRNewswire/ -- Today, the Adecco Group unveiled the results of the fourth edition of its annual global study: Global Workforce of The Future Report 2023.1

The report examines the world of work through the lens of 30,000 workers from 23 countries across multiple industries, spanning entry-level workers to senior executives. This year's survey sought to identify worker readiness and sentiment related to the anticipated impacts of GenAI, offering recommendations to future-proof the workforce.

Denis Machuel, Chief Executive Officer of the Adecco Group, said: ""The world of work is shifting from a jobs-based to a skills-based economy, and this shift is being accelerated by the rapid adoption of Generative AI. This year's report uncovered substantial gaps in access to GenAI training and guidance despite widespread use and highlighted the urgent need for organisations to embrace technology transformation, boost career mobility, enhance worker skills and capabilities, and protect employee wellbeing. In a world being disrupted by technology, talent remains a true competitive advantage; the companies that focus on their people are most likely to ensure the future-readiness of their organisations.""

Key Global Workforce of the Future 2023 Report findings:

GenAI use is widespread, but access to training is unequal

While 70% of workers are already using GenAI in the workplace, less than half are receiving any form of GenAI guidance from their employers. There is also a significant education divide, with 76% of degree holders using GenAI versus just 51% of those secondary school educated. And 66% of leaders are more likely to receive guidance for using AI compared to 32% of non-managers. Fortunately, 57% of workers overall expressed that they'd like to receive AI training – which is an opportunity for employers to meet workers where they are.

Workers are experiencing a ""honeymoon"" phase with GenAI

Sixty-two percent of workers have a positive outlook on AI, fuelling widespread adoption. Only 7% of workers believe GenAI could cause them to lose their jobs, though recent estimates2 indicate that over 300 million jobs worldwide will be disrupted by AI in some way. To bridge the gap, organisations must urgently deploy upskilling measures at scale.

Invest in honing uniquely human skills

Sixty-one percent of workers believe human skills will remain more influential than GenAI in the workplace, especially emotional intelligence, empathy, and interpersonal skills. Cultivating these human skills will require connecting workers to coaching, leadership development and training.

Upskilling has become the workplace perk of choice

This year, there was a 10-point increase in workers indicating they intend to stay with their current employer for the next 12 months, jumping from 61% in 2022 to 73% in 2023. However, a majority only plan to stay if they have access to training and career progression opportunities. To retain and engage workers, it's crucial for employers to encourage and support lifelong learning and internal mobility opportunities, which are more important than salary when deciding whether to stay or leave a company.

Skills are a precious currency

Fifty-six percent of workers believe their skills are transferable to other roles or industries, and the vast majority report they intend to take more control of their upskilling. Workers in tech, professional and financial services are most confident their skills can be transferred, compared to insurance, automotive and defence workers who are least confident. The shift from a job-based economy to a skills-based one is unfolding rapidly. Organisations can help workers keep their skills current by investing in development for everyone at every level.

Burnout is pervasive

Sixty-five percent of workers report they have suffered from burnout. Managers are more burned out than any other level at 68%, exacerbated by layoffs, with 44% reporting they took on more responsibility post-redundancies. Seventy-eight percent of workers also don't feel supported to take their full annual leave. This year's results reaffirm one of the most important lessons of the pandemic – organisations need to put people first by investing in their wellbeing.

Notes to editors:

Download the research -´What's Working, Navigating the GenAI Revolution and the Shifting Future of Work 2023', which includes infographics that visually present the key findings.

Register for the Webinar on October 18th for more insights and a conversation with executives from global companies here.

for more insights and a conversation with executives from global companies here. Learn more about the Adecco Group and Microsoft GenAI Memorandum of Understanding to prepare workers for the GenAI shift here.

About the research:

For the fourth consecutive year, the Adecco Group surveyed over 30,000 workers from 23 countries across 25 industries, presenting a global view of critical workforce trends to support decision-makers in the private and public sector as they navigate the fast-changing world of work. Respondents answered a 20-minute online survey.

* 23 countries include:

Australia

Belgium

Brazil

China

Denmark

Finland

France

Germany

Greece

Italy

Japan

Mexico

Netherlands

Norway

Poland

Romania

Slovenia

Spain

Sweden

Switzerland

Turkey

UK

USA

About The Adecco Group

The Adecco Group is a global leader in talent and technology expertise. Our purpose is making the future work for everyone. Through our three global business units - Adecco, Akkodis and LHH - across 60 countries, we enable sustainable and lifelong employability for individuals, deliver digital and engineering solutions to power the Smart Industry transformation and empower organisations to optimise their workforces. The Adecco Group leads by example and is committed to an inclusive culture, fostering sustainable employability, and supporting resilient economies and communities. The Adecco Group AG is headquartered in Zurich, Switzerland (ISIN: CH0012138605) and listed on the SIX Swiss Exchange (ADEN).

For further information please contact:

The Adecco Group Press Office: [email protected] or +41 (0) 44 878 87 87

https://www.adeccogroup.com/ | LinkedIn: linkedin.com/company/theadeccogroup | X: @AdeccoGroup #GWoF or #GWOF2023

1 2020 and 2021 editions appeared as Resetting Normal study.

2 Goldman Sachs (2023). Generative AI could raise global GDP by 7%. https://www.goldmansachs.com/intelligence/pages/generative-ai-could-raise-global-gdp-by-7-percent.html

SOURCE The Adecco Group"
"SuccessConnect '23 - under the hood of SAP's generative AI news, and beyond - diginomica",https://diginomica.com/successconnect-23-under-hood-saps-generative-ai-news-and-beyond,"Wed, 04 Oct 2023 21:25:26 GMT",diginomica,"(SuccessFactors leadership at analyst Q/A)

As expected, Tuesday's SuccessConnect keynote opener was loaded with HXM-related AI announcements, building on SAP's recent announcement of its Joule copilot, which will provide a digital AI assistant across a range of SAP products and workflows.

But would this show be all-about-AI, all-the-time - at the expense of other important topics to HR customers?

And when will this AI functionality be released? How are the issues of customer data privacy being addressed, in the context of AI-related data movement?

As I write this, there is a full day of the event (and embedded analyst program) still to go. But I already have some useful answers to these questions. Start with the all-AI question: during the keynote, SAP made clear that they want to tackle a broader purview of HR challenges and possibilities. I welcome this type of messaging for two reasons.

First, I prefer to validate vendor news with customer proof points. With generative AI, I can't really do that - too few customer are ready to talk. I can press vendors on issues of accuracy, bias, explainability, and AI design principles, but not on results. Customers are knee deep in talent and workforce management issues that go beyond the reach of where generative AI can go - at least today. At a user event, you never want to miss an opportunity to deliver for those customers - with more mature functionality.

And yes, for SAP, like most forward-thinking vendors, that mature functionality does include many forms of AI already in use. It is only generative AI that lacks the proof points I am looking for. SAP's news center includes fresh news on several important HR topics. We got into all of that, including details on SAP's AI-for-HR plans, during an analyst session with David Ludlow, Group Vice President, Product Strategy and Research at SAP SuccessFactors.

On generative AI release timing

SuccessFactors customers won't have to wait long. As Ludlow confirmed, two generative AI scenarios are generally available with the upcoming SuccessFactors release in November - along with a slew of digital assistant scenarios.

This is the ability to create a job description, and the ability to create interview questions or suggestions for a manager to prepare [for an interview]...

The two gen AI use cases are embedded in SuccessFactors, powered by Microsoft OpenAI. Then there is the enhanced digital assistant:

There are about 40 use cases for the digital assistant [via Joule] that are being delivered next month, primarily focused on Employee Central and core HR type transactions, but there's a few talent ones as well. We're putting in some more capabilities throughout next year as well.

Such as?

One at the top of the list [for Joule in HR] is manager self-service, a scenario for the manager to create a new position within Employee Central - that was one of the top ones being requested. Another is the incorporation of Large Language Models, to assist in FAQ-type claims. So what is our vacation policy? What was our benefit policy - and then actually get information back from there.

More gen AI plans are in the works too:

In May next year, use cases planned for delivery are using gen AI to provide candidate screening in the recruiting area. And then the ability to suggest employee goals about development, as well as performance goals... And then we'll look at some other things as well, as we mature.

In addition to gen AI, predictive AI for HR is expanding also:

On predictive AI, once again, the ability to take information that's being generated in the system, and then to use that information to provide a suggestion or a recommendation for somebody to pick it up. The best example here would be to say, 'Okay, it looks like as a result of your performance review, you picked up this skill. Would you like me to update your profile?'

Looking under the SuccessFactors R&D hood - investments in AI and beyond

Ludlow says a top question is where SAP SuccessFactors is investing its R&D. The answer goes well beyond AI:

A key question we get asked a lot is: 'Where do you spend your R&D? Where does the money go?' I divide this into four or five areas - a non-exhaustive list. We're making a lot of investments in user experience to connect the end users of the services you're providing to the technology that's providing. Secondly, build a great future-ready workforce - all about skills, capabilities, internal mobility, upskilling, and rescaling HR agility, compliance. The ongoing updates we're making to the solution - including other legal compliance that's coming in, but also all of the customer requests or requirements for innovation and ongoing improvements that we're making to the solution as well. [Then there is] integration and extensions,.We continue to refine the integrations within SuccessFactors, as well as deliver new integrations to connect SuccessFactors more seamlessly to the rest of the SAP suite.

Of course, AI is a crucial part of that R&D also:

For simplicity purposes, I like to divide this into the three main types of AI that we are embedding into SuccessFactors, and the use cases that we're delivering associated with it. The first is generative AI, also known as ChatGPT. Secondly, conversational AI, also known as digital assistant and chatbots, and the third, predictive AI - so taking information in the system, and making suggestions and recommendations to end users.

Ludlow's answer indicated how SAP SuccessFactors thinks about AI overall - with humans decidely in the loop:

When we talk about AI, we will never take a decision for the end user, the decision machine or the software simply makes a suggestion or recommendation to an end user, but it's still up to them to actually take the decision to update something. So in that case, we help reduce or eliminate bias, and any other kind of bad data that may get into the system. On the generative AI side, we're partnering very closely with Microsoft in SuccessFactors, leveraging some of the open API services running out of this Azure, that is ChatGPT 3.5 turbo.

Ludlow also noted the evolution of conversational AI:

We've had some conversational AI capabilities in the solution, some using native technology, SAP, SAP for decision to retire that technology. Instead, we've incorporated IBM Watson code into the platform. So going forward, the IBM Watson capabilities will drive our digital assistant in SuccessFactors.

SuccessFactor's UX redesign - will AI disrupt it?

I've focused on clarifying the AI news/approach, but that gives short shrift to the range of new offerings underway. Another big topic was the enhancement of the SuccessFactors UX. Ludlow explains:

So in SuccessFactors, we've been on a multi-year journey to redesign and reimagine some of the user interactions of the applications within SuccessFactors. So these include things like reimagining the goal experience, reimagining the performance experience, reimagining the homepage. We've just delivered, in the September off cycle release, a completely new redesigned user experience for recruitment. In the November release, we will deliver a brand new user experience for the [Work Zone].

SuccessFactors is also part of SAP's Horizons project, which standardizes UI style sheets across products, from S/4HANA to SuccessFactors to Ariba. Some of those UI views have already shipped, but the Horizons project is ongoing, and outside the scope of this piece. What caught my ears? SuccessFactors' push to embed functions in users' preferred collaboration environments, including Microsoft Teams and Google Workplace:

For commonly-used employee/manager self service for transactions, we're doing a lot of integration to Microsoft Teams. So things like give feedback, receive feedback, request a day off, enter time, these kinds of things, we can actually connect the SuccessFactors transactions directly into the Teams environment. So an end user might never have to leave the Teams envrionment to do these very simple and basic HR transactions. We delivered some of the first integrations already in the May release this year. We'll deliver some additional ones in November, and then into next year as well. We are also in the process of doing the same with Google Workspace.

Bringing interactions/transactions to the users' preferred workspace or UI makes sense. But I asked Ludlow: when you think about putting a prompt-based AI in front of software, doesn't that fundamentally disrupt UX plans? He responded:

I think the disruption will occur from multiple perspectives. The ability, like I mentioned, to integrate the self-services into Teams is one aspect, However, I can also do that through the digital assistant as well. I think you can actually get to a point where the homepage just becomes similar to a Google search bar. And so I want to do this, or I want to do that, and you do it by conversation. If you think about an [enterprise] homepage today, fundamentally, it just has multiple links, right? Now I can go here; I can go here. And there may be some search technology to find the right link. But in this case, if you really take it to the Nth degree with these digital assistants - it's just ""I want to do something,' and the system will respond to what I want to do. It makes it so much easier.

My take - airing out AI issues and more

How AI disrupts enterprise UX led to a spirited discussion. There is no one right answer, but the obvious note is that an AI conversational front end won't be able to complete complex transactions anytime soon. Nor would that type of conversational interface work for all employees. Some will insist upon their screens; some will need them.

Good UX design must expand to anticipate all of that. In general, going to where users already are, including Teams/Google etc - and automating as many processes as possible along the way - is the winning design principle. The conversational AI interface will start with simpler transactions, and then we'll see. The Joule copilot should eventually be able to jump in with relevant, role-based next steps.

One of the most interesting discussions we had during the analyst sessions was the potential for more transformative AI. How AI could change the user experience is just one small way to get into that bigger conversation. Will SuccessFactors be able to lead its HR customers through more profound AI changes - changes that could change the nature of work, and certainly how we manage talent and skills? Time will tell.

From my digging so far, an important piece will be SuccessFactors' progression on their own skills ontology, as well as using AI to enable real-time updates of that skills ontology. That's hardly the only AI use case, but if you want to transform work, that comes down to talent, which comes down to skills, which comes down to skills data that users buy into, trust - and help to maintain.

I ran into a few customers that are eager to do more with SuccessFactors on skills, but in the short term, they have gone for other third party skills solutions. This was a random sample, not necessarily a trend. Nor does that preclude SuccessFactors AI using that externally-integrated skills ontology - that should not pose any problems. But: I think the continued emphasis on skills ontologies will strengthen SuccessFactors' overall AI push.

During Ludlow's session, analysts asked the expected question about customer data privacy and LLMs. What I'm learning is that even when vendors use external LLMs, if they do this right, the LLM vendor in question does not really have any access to that data - not for model training or anything else. LLM data movement is an important question, but it's a problem a responsible AI vendor can avoid. Ludlow's answer underscored this:

The way we're working with Large Language Models is: we are not sharing data out. So we're using data, but the relationship we have with the supplier is they may not use it to train their LLMs. We would never send personal data out to begin with, but [this applies to] company level data as well. A lot of companies don't want that shared out. So once again, even though it's not PII type data, we are not allowing the LLM suppliers to use that data to train their models.

That brings me to pricing. I've said before that I like many aspects of SAP's AI strategy, with the important exception of pricing. I stand by that criticism for now, but AI pricing is something of a moving target, for most if not all vendors. Pricing discussions were not part of the agenda at SuccessConnect, but I'd expect more details on AI pricing for SuccessFactors to be revealed soon, obviously by the November release. I would expect these pricing plans to be 'umbrella' plans across SAP's products.

During our analyst sessions, I pressed the issue on a couple topics I believe are important to customers. However, those sessions were mostly under NDA, except for Ludlow's. The good news is that what we discussed under NDA is largely shorter term, so that content should eventually be appropriate to surface. One thing I can say: talking to a number of analysts about SuccessFactor's positioning, they believe that SuccessConnect can go much further in tying SAP's HCM approach to its formidable industry competencies (and software reach).

Yes, you can get that immersion at SAP Sapphire, but getting more of that industry vibe at SuccessConnect is high on the list of improvements from analysts. I think that fits well with SuccessFactors' goal to support business cases that HR leaders need for boardroom relevance - including the collaboration needs of a more fluid workforce. Ergo, the progress made on integrating more deeply with Fieldglass.

In the meantime, I am also recording podcasts with long-time SuccessFactors community leaders. Those podcasts will allow me to go directly into what matters to customers now - including AI impact and a lot more. Customer sessions were abundant - as were project lessons. Stay tuned.

Updated October 5, 6am UK time with a number of small tweaks fro reading clarity."
The generative AI easy button: How to run a POC in your datacenter ... - Blocks & Files,https://blocksandfiles.com/2023/10/05/the-generative-ai-easy-button-how-to-run-a-poc-in-your-datacenter/,"Thu, 05 Oct 2023 13:05:00 GMT",Blocks & Files,"Commissioned: Generative AI runs on data, and many organizations have found GenAI is most valuable when they combine it with their unique and proprietary data. But therein lies a conundrum. How can an organization tap into their data treasure trove without putting their business at undue risk? Many organizations have addressed these concerns with specific guidance on when and how to use generative AI with their own proprietary data. Other organizations have outright banned its use over concerns of IP leakage or exposing sensitive data.

But what if I told you there was an easy way forward already sitting behind your firewall either in your datacenter or on a workstation? And the great news is it doesn’t require months-long procurement cycles or a substantial deployment for a minimum viable product. Not convinced? Let me show you how.

Step 1: Repurpose existing hardware for trial

Depending on what you’re doing with generative AI, workloads can be run on all manner of hardware in a pilot phase. How? There are effectively four stages of data science with these models. The first and second, inferencing and Retrieval-Augmented-Generation (RAG), can be done on relatively modest hardware configurations, while the last two, fine-tuning/retraining and new model creation, require extensive infrastructure to see results. Furthermore, models can be of various sizes and not everything has to be a “large language model”. Consequently, we’re seeing a lot of organizations finding success with domain-specific and enterprise-specific “small language models” that are targeted at very narrow use cases. This means you can go repurpose a server, find a workstation a model can be deployed on, or if you’re very adventurous, you could even download LLaMA 2 onto your laptop and play around with it. It’s really not that difficult to support this level of experimentation.

Step 2: Hit open source

Perhaps nowhere is the open-source community more at the bleeding edge of what is possible than in GenAI. We’re seeing relatively small models rivaling some of the biggest commercial deployments on earth in their aptitude and applicability. The only thing stopping you from getting started is the download speed. There are a whole host of open-source projects at your disposal, so pick a distro and get going. Once downloaded and installed, you’ve effectively activated the first phase of GenAI: inferencing. Theoretically your experimentation could stop here, but what if with just a little more work you could unlock some real magic?

Step 3: Identify your use cases

You might be tempted to skip this step, but I don’t recommend it. Identify a pocket of use cases you want to solve for. The next step is data collection and you need to ensure you’re grabbing the right data to deliver the right results via the open source pre-trained LLM you’re augmenting with your data. Figure out who your pilot users will be and ask them what’s important to them – for example, a current project they would like assistance with and what existing data they have that would be helpful to pilot with.

Step 4: Activate Retrieval-Augmented-Generation (RAG)

You might think adding data to a model sounds extremely hard – it’s the sort of thing we usually think requires data scientists. But guess what: any organization with a developer can activate retrieval-augmented generation (RAG). In fact, for many use cases this may be all you will ever need to do to add data to a generative AI model. How does it work? Effectively RAG takes unstructured data like your documents, images, and videos and helps encode them and index them for use. We piloted this ourselves using open-source technologies like LangChain to create vector databases which enable the GenAI model to analyze data in less than an hour. The result was a fully functioning chatbot, which proved out this concept in record time.





Source: Dell Technologies

In Closing

The unique needs and capabilities of GenAI make for a unique PoC experience, and one that can be rapidly piloted to deliver immediate value and prove its worth to the organization. Piloting this in your own environment offers many advantages in terms of security and cost efficiencies you cannot replicate in the public cloud.

Public cloud is great for many things, but you’re going to pay by the drip for a PoC, it’s very easy to burn through a budget with users who are inexperienced at prompt engineering. Public cloud also doesn’t offer the same safeguards for sensitive and proprietary data. This can actually result in internal users moving slower as they think through every time they use a generative AI tool whether the data they’re inputting is “safe” data that can be used with that particular system.

Counterintuitively, this is one of the few times the datacenter offers unusually high agility and a lower up front cost than its public cloud counterpart.

So go forth, take an afternoon and get your own PoC under way, and once you’re ready for the next phase we’re more than happy to help.

Here’s where you can learn more about Dell Generative AI Solutions.

Brought to you by Dell Technologies.

"
Generative AI set to reshape SD-WAN market - Network World,https://www.networkworld.com/article/3708288/generative-ai-set-to-reshape-sd-wan-market.html,"Thu, 05 Oct 2023 15:43:00 GMT",Network World,"There are baseline security and connectivity requirements for any SD-WAN service, and then there are optional, emerging product capabilities that indicate how the market is maturing and customer requirements are expanding. AI networking support – such as for proactive remediation and incident management – is one of those optional capabilities, according to Gartner, which just released its latest analysis of the SD-WAN vendor landscape.

There’s a trend toward AI capabilities that enable networking decisions to be made with little or no human intervention. These capabilities can help enterprises to streamline network design, configuration and ongoing management as well as increase agility and improve performance, according to Gartner. The research firm predicts that by 2026, generative AI technology embedded in SD-WAN offerings will be used for 20% of initial network configuration, up from near zero in 2023.

“Although it is still early in many vendors’ product development, we are seeing this functionality incorporated into an increasing number of vendor solutions offering differentiation. The longer-term challenge will be customer trust in using such solutions,” Gartner wrote in its new Magic Quadrant for SD-WAN.

Among the vendors that are working to build AI networking support into their respective SD-WAN products is Fortinet. “Fortinet’s planned innovations in GenAI and ‘as a service’ consumption models have an above-average chance of delivering game-changing capabilities to the market,” Gartner wrote.

Huawei, dubbed a challenger in the field of SD-WAN vendors, is expected to invest in its AI-driven predictive route selection and AI-based IoT terminal authorization and access over the next 18 months, Gartner said. Versa Networks, too, has a product roadmap that aligns with emerging requirements for AI networking, according to the report.

Another trend that’s influencing the SD-WAN market is the shift toward secure access service edge (SASE) offerings. According to Gartner’s definition, SASE combines five major technologies: cloud-access security broker, secure web gateway, zero-trust network access, integrated SD-WAN, and firewall as a service. Security service edge (SSE) is a security-focused subset of SASE, and it typically includes CASB, SWG, and ZTNA.

In the big picture, the SD-WAN market is evolving toward single-vendor SASE, as five technologies converge: SD-WAN, SSE, enhanced internet/WAN backbone, cloud onramp, and multicloud networking. Getting the full SASE stack from a single vendor can simplify deployment and management, but it can be complicated by factors such as an enterprise’s existing multi-vendor SD-WAN environments and poor WAN visibility.

“Today, we primarily see SD-WAN and SSE offerings being integrated and deployed as dual-vendor SASE. This is largely driven by the move to distribute internet access to support cloud applications and change the security perimeter. This goes along with the deployment of SD-WAN at branch locations to manage the internet transport,” the report states. “As part of a desire to minimize branch sprawl and support access to the cloud, we observe more organizations looking for integrated cloud-delivered security and thin branch SD-WAN solutions.”

By 2026, 60% of new SD-WAN purchases will be part of a single-vendor SASE offering, up from 15% in 2022, Gartner predicts.

Meanwhile, the SD-WAN market continues to grow. Gartner forecasts a compound annual growth rate (CAGR) of 14.6% in end-user spending on SD-WAN from 2022 through 2027, with market penetration of about 60% in 2023.

One driver for SD-WAN market growth is aging infrastructure. Existing branch office router equipment or first-generation SD-WAN equipment needs a refresh either because it has reached the end of its support lifecycle, or it lacks the necessary capabilities for today’s connectivity. Also, application rollouts with changing traffic patterns are increasing the use of cloud and multicloud resources, which is making on-premises data center WAN architecture obsolete, according to Gartner.

Organizations are also consolidating branch functions such as routing and security, and IT leaders are considering SD-WAN investments to increase scalability, agility, and automation to support digital business transformation and reduce operating expenses, Gartner says,

Leading the SD-WAN pack

Based on its evaluation criteria, Gartner classified six vendors as leaders in the SD-WAN market, one challenger, one visionary, and six niche players. Here’s a look at the strengths and weaknesses of the leaders, which Gartner defines as those vendors that have well established products, long-term viability, and the ability to shape the SD-WAN market.

Cisco

Two products, Cisco Catalyst SD-WAN and Cisco Meraki SD-WAN, help land the vendor on the leader list. With high market visibility and a loyal installed base, Cisco is in a good position for future success with a product strategy that includes AI networking, integrated security, and cloud onramp. Cisco is estimated to have 46,000 SD-WAN enterprise customers globally.

Yet Gartner identifies Cisco’s multiple SD-WAN products as a potential caution for the vendor, because the separate products with different management platforms limits investment protection for customers. And Cisco’s customer experience is below average, based on Gartner client interactions.

Fortinet

Fortinet’s Security SD-WAN product is singled out for its strong features focused on integrated security. Coupling security with its SD-WAN offering provides Fortinet customers with a simplified approach. Also, as noted before, Gartner says Fortinet’s plans around generative AI and as-a-service consumption could deliver game-changing capabilities to the market.

Still, Fortinet has a few hurdles to clear, according to Gartner. Some clients have expressed doubt about Fortinet’s ability to meet complex enterprise networking requirements, and Gartner reports customer experience with Fortinet is below average. Fortinet also has limited integrations with third-party SSE vendors, Gartner says.

HPE (Aruba)

HPE Aruba’s SD-WAN offerings, Aruba EdgeConnect SD-WAN (with optional WAN optimization) and Aruba EdgeConnect SD-Branch, are both managed through the Aruba Central platform. This vendor has high ratings with customer experience and a proven track record of delivering cloud and SSE integrations as well as new consumption models when needed, Gartner says.

Gartner identifies HPE Aruba’s multiple products that apply to different use cases as a potential caution with customers who could select the wrong offering for their business. Also, Gartner finds HPE Aruba’s planned innovation in its unified fabric and single-vendor SASE functionality “unlikely to delivery game-changing capabilities” to the market.

Palo Alto Networks

Palo Alto Networks’ Prisma SD-WAN offering includes Instant-On Network (ION) edge appliances and orchestration, and the vendor also offers the PAN-OS branch firewall with limited SD-WAN capabilities. Gartner highlights Palo Alto Networks’ “recent and planned innovations in AIOps, visibility, and granular policy control” as having the potential to bring game-changing capabilities to the market.

Potential challenges for this vendor include its high SD-WAN pricing, lack of performance optimization capabilities, and multiple SD-WAN products, which can introduce some market confusion, according to Gartner. “Customers are required to choose between a strong on-premises security offering with limited SD-WAN functionality or a strong SD-WAN offering with limited on-premises security functionality,” the report states.

Versa Networks

Versa Networks’ two offerings, Secure SD-WAN and Versa Titan, are built on the same platform with the latter being delivered as a cloud-based offering. Gartner estimates that the company has some 24,000 SD-WAN enterprise customers globally and expects the vendor to invest in AI, observability, and multicloud support in the next 18 months, which could bolster its already strong product portfolio.

Still, Gartner cautions that the two-product strategy could lead to some confusion among customers because they offer different capabilities, making it possible customers will select the wrong offering. Also, Gartner pinpoints pricing as an issue for this vendor, which could make its Secure SD-WAN product more difficult to procure for some IT buyers.

VMware

VMware SD-WAN includes Edge appliances, optional gateway points of presence, software licenses, and a cloud-based orchestrator. Gartner estimates that VMware has about 18,000 SD-WAN customers globally, and the vendor is expected to make future investments in SD-WAN Cloud Transport that would integrate multiple capabilities into a single platform. Gartner also expects VMware to invest more in AI-based digital experience assurance and analytics.

Even with its expected investments, Gartner states that VMware lags behind “in terms of integrated security features natively available in its on-premises appliances.” VMware also lacks a native SD-brand offering integrating WLAN, LAN, network security, and SD-WAN into a single platform, Gartner says."
Laying the foundation for data- and AI-led growth - MIT Technology Review,https://www.technologyreview.com/2023/10/05/1080618/laying-the-foundation-for-data-and-ai-led-growth/,"Thu, 05 Oct 2023 13:00:00 GMT",MIT Technology Review,"Following are the study’s key findings:

CIOs are doubling down on their investments in data and AI. Faced with increasing audience expectations, new competitive pressures, a challenging economic backdrop, and an unprecedented speed of innovation, technology leaders need their data and AI assets to deliver more growth to the business than ever before. They are investing to secure this future: every organization surveyed will boost its spending on modernizing data infrastructure and adopting AI during the next year, and for nearly half (46%), the increase will exceed 25%.

Consolidation of data and AI systems is a priority. The proliferation of data and AI systems is particularly extensive in the survey’s largest organizations (those with annual revenue of more than $10 billion). Among these, 81% operate 10 or more of these systems, and 28% use more than 20. The executives we interviewed aim to pare down their multiple systems, connecting data from across the enterprise in unified platforms to break down silos and enable AI initiatives to scale.

Democratization of AI raises the stakes for governance. As business units and their staff clamor to use generative AI, executives seek assurance that governance frameworks for the technology can provide not only the needed data accuracy and integrity but also adequate data privacy and security. That’s probably why 60% of respondents say a single governance model for data and AI is “very important.”

Executives expect AI adoption to be transformative in the short term. Eighty percent of survey respondents expect AI to boost efficiency in their industry by at least 25% in the next two years. One-third say the gain will be at least 50%.

As generative AI spreads, flexible approaches are favored. Eighty-eight percent of organizations are using generative AI, with one-quarter (26%) investing in and adopting it and another 62% experimenting with it. The majority (58%) are taking a hybrid approach to developing these capabilities, using vendors’ large language models (LLMs) for some use cases and building their own models when IP ownership, privacy, security, and accuracy requirements are tighter.

Lakehouse has become the data architecture of choice for the era of generative AI. Nearly three-quarters of surveyed organizations have adopted a lakehouse architecture, and almost all of the rest expect to do so in the next three years. Survey respondents say they need their data architecture to support streaming data workloads for real-time analytics (a capability deemed “very important” by 72%), easy integration of emerging technologies (66%), and sharing of live data across platforms (64%). Ninety-nine percent of lakehouse adopters say the architecture is helping them achieve their data and AI goals, and 74% say the help is “significant.”

Investment in people will unlock more value from data and AI. In our survey, talent and skills gaps overshadow organizations’ other data and AI challenges. When asked where their company’s data strategy needs to improve, the largest share of respondents (39%) say investing in talent. The number-one difficulty they face with their data and AI platforms, with 40% citing this as a top concern, is training and upskilling staff to use them.

A subsequent report will examine these survey results in detail, accompanied by insights from additional executive interviews across six sectors: financial services, health care and life sciences, retail and consumer packaged goods, manufacturing, media and entertainment, and government.

Download the report.

This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff."
Alteryx Launches New Alteryx AiDIN Innovations to Fuel Enterprise ... - PR Newswire,https://www.prnewswire.com/news-releases/alteryx-launches-new-alteryx-aidin-innovations-to-fuel-enterprise-wide-adoption-of-generative-ai-301947933.html,"Thu, 05 Oct 2023 09:00:00 GMT",PR Newswire,"Powered by Alteryx AiDIN, Alteryx AI Studio helps customers responsibly and easily harness the power of large language models (LLMs) to enhance customer experiences, streamline operations, and drive personalized interactions

IRVINE, Calif., Oct. 5, 2023 /PRNewswire/ -- Alteryx, Inc. (NYSE: AYX), the Analytics Cloud Platform company, today announced new Alteryx AiDIN innovations, including AI Studio, one of the industry's first deployment-agnostic interfaces that is purpose-built for no-code users to leverage generative AI. Nearly 90 percent of companies currently using generative AI reported seeing benefits from the technology, and the new Alteryx AiDIN innovations are designed to help organizations incorporate custom business data into LLMs in a governed manner to drive operational agility and deliver competitive advantage.

""With generative AI showing immense potential across the analytics value chain, we need to take action now and help our clients accelerate adoption securely and responsibly so they can make better, faster decisions at scale,"" said Brad Collins, partner and enterprise digital transformation leader at RSM US. ""We're excited to work with a trusted vendor like Alteryx and use Alteryx AiDIN to develop new solutions that will help our clients quickly identify new opportunities for digital innovation as they navigate changing markets.""

Harnessing the Power of Generative AI with Alteryx AI Studio

Built on the end-to-end unified Alteryx analytics automation platform and powered by Alteryx AiDIN, the new Alteryx AI Studio is designed to give organizations the power to select an LLM of their choice from a list of available options, then tune it using their own custom business data to adapt to the specific context of their business.

Alteryx AI Studio seamlessly integrates with Alteryx Designer so customers can easily consume their models through existing workflows and construct applications with a conversational interface. Further, Alteryx AI Studio is designed to help safeguard sensitive information and facilitate data security and compliance by giving customers full control of their LLM lifecycle and the option to host and manage the LLM within Alteryx or in their own environment.

Accelerating Time to Insight with Playbooks

Alteryx AiDIN continues to unlock innovation with the newest upcoming Auto Insights feature, Playbooks. Playbooks is being designed to make it faster and easier to get insights from data by using generative AI to automate the initial stages of the analytics delivery process including use case ideation, use case selection, and developing a proof-of-concept data story. Users will simply provide their role and company, then Playbooks will suggest relevant and important analytics use cases to explore and build.

""From staying ahead of the competition and expanding into new markets to increasing productivity, organizations are looking for new ways to win with generative AI,"" said Suresh Vittal, chief product officer at Alteryx. ""With Alteryx AiDIN, we're helping customers propel their organizations forward by making it easy for any user to responsibly use LLMs and generate outcomes that drive business growth and productivity.""

Learn more about Alteryx AiDIN innovations at Inspire On Tour: London, where Alteryx also unveiled the brand new Alteryx Marketplace, a place for customers to easily discover Alteryx-verified, creator-supported solutions that expand the functionality, usage, and power of Alteryx to drive further business growth.

Safe Harbor Statement

This press release includes ""forward-looking statements"" within the meaning of the federal securities laws that involve risks and uncertainties, including, but not limited to, statements regarding Alteryx's product offerings. The expectations expressed or implied in these forward-looking statements may not turn out to be correct. All forward-looking statements speak only as of the date hereof and are based on current expectations and involve a number of assumptions, risks and uncertainties that could cause the actual results to differ materially from such forward-looking statements. A further description of the risks and uncertainties relating to Alteryx's business is contained in Alteryx's reports filed with the Securities and Exchange Commission, including Alteryx's Annual Report on Form 10-K for the year ended December 31, 2022, Quarterly Reports on Form 10-Q, and Current Reports on Form 8-K. Alteryx does not undertake to update, and expressly disclaims any duty to update, its forward-looking statements, whether as a result of circumstances or events that arise after the date they are made, new information, or otherwise.

Any unreleased services or features referenced in this or other press releases, presentations or public statements are only intended to outline Alteryx's general product direction. They are intended for information purposes only and may not be incorporated into any contract. This is not a commitment to deliver any material, code, or functionality (which may not be released on time or at all) and customers should not rely upon this press release or any such statements to make purchasing decisions. The development, release, and timing of any features or functionality described for Alteryx's products remains at the sole discretion of Alteryx.

About Alteryx

Alteryx (NYSE: AYX) powers analytics for all with the award-winning Alteryx Analytics Cloud Platform. With Alteryx, enterprises can make intelligent decisions across their organizations with automated, AI-driven insights. More than 8,000 customers globally rely on Alteryx to democratize analytics across use cases and deliver high-impact business outcomes. To learn more, visit www.alteryx.com.

Alteryx is a registered trademark of Alteryx, Inc. All other product and brand names may be trademarks or registered trademarks of their respective owners.

SOURCE Alteryx, Inc."
Vera wants to use AI to cull generative models’ worst behaviors - TechCrunch,https://techcrunch.com/2023/10/05/vera-wants-to-use-ai-to-cull-generative-ais-worst-behavior/,"Thu, 05 Oct 2023 13:00:23 GMT",TechCrunch,"Liz O’Sullivan is on a mission to make AI “a little bit safer,” in her own words.

A member of the National AI Advisory Committee, which drafts recommendations to the White House and Congress on how to foster AI adoption while regulating its risks, O’Sullivan spent 12 years on the business side of AI startups overseeing data labeling and operations and customer success. In 2019, she took a job at the Surveillance Technology Oversight Project, mounting campaigns to protect New Yorkers’ civil liberties, and co-founded Arthur AI, a startup that partners with civil society and academy to shine light into AI’s “black box.”

Now, O’Sullivan is gearing up for her next act with Vera, a startup building a toolkit that allows companies to establish “acceptable use policies” for generative AI — the type of AI models that generate text, images, music and more — and enforce these policies across open source and custom models.

Vera today closed a $2.7 million funding round led by Differential Venture Partners with participation from Essence VC, Everywhere VC, Betaworks, Greycroft and ATP Ventures. Bringing Vera’s total raised to $3.3 million, the new cash will be put toward growing Vera’s five-person team, R&D and scaling enterprise deployments, O’Sullivan says.

“Vera was founded because we’ve seen, firsthand, the power of AI to address real problems, just as we’ve seen the wild and wacky ways it can cause damage to companies, the public and the world,” O’Sullivan told TechCrunch in an email interview. “We need to responsibly shepherd this technology into the world, and as companies race to define their generative AI strategies, we’re entering an age where it’s critical that we move beyond AI principles and into practice. Vera is a team that can actually help.

O’Sullivan co-founded Vera in 2021 with Justin Norman, formerly a research scientist at Cisco, a lead data scientist in Cloudera’s AI research lab and the VP of data science at Yelp. In September, Norman was appointed a member of the Department of the Navy Science and Technology board, which provides advice and counsel to the U.S. Navy on matters and policies relating to scientific, technical and related functions,

Vera’s platform attempts to identify risks in model inputs — for example, a prompt like “write a cover letter for a software engineering role” to a text-generating model — and block, redact or otherwise transform requests that might contain things like personally identifiable information, security credentials, intellectual property and prompt injection attacks. (Prompt injection attacks, essentially carefully-worded malicious prompts, are often used to “trick” models into bypassing safety filters.)

Vera also places constraints on what models can “say” in response to prompts, according to O’Sullivan, giving companies greater control over the behavior of their models in production.

How does Vera achieve this? By using what O’Sullivan describes as “proprietary language and vision models” that sit between users and internal or third-party models (e.g. OpenAI’s GPT-4) and detect problematic content. Vera can block “inappropriate” prompts to — or answers from a model in any form, O’Sullivan claims, whether text, code, image or video.

“Our deep tech approach to enforcing policies goes beyond passive forms of documentation and checklists to address the direct points at which these risks occur,” O’Sullivan said. “Our solution … prevents riskier responses that may include criminal material or encourage users to self-harm.”

Companies are certainly encountering challenges — mainly compliance-related — in adopting generative AI models for their purposes. They’re worried about their confidential data ending up with developers who trained the models on user data, for instance; in recent months, major corporations including Apple, Walmart and Verizon have banned employees from using tools like OpenAI’s ChatGPT.

And offensive models are obviously bad for publicity. No brand wants the text-generating model powering their customer service chatbot, say, to spout racial epithets or give self-destructive advice.

But this reporter wonders if Vera’s approach is as reliable as O’Sullivan suggests.

No model is perfect — not even Vera’s — and it’s been demonstrated time and time again that content moderation models are prone to a whole host of biases. Some AI models trained to detect toxicity in text see phrases in African-American Vernacular English, the informal grammar used by some Black Americans, as disproportionately “toxic.” Meanwhile, certain computer vision algorithms have been found to label thermometers held by Black people as “guns” while labeling thermometers held by light-skinned subjects as “electronic devices.”

To be fair to O’Sullivan, she doesn’t claim Vera’s models are bulletproof — only that they can cull the worst of a generative AI models’ behaviors. There may be some truth to that (depending on the model, at least) — and the degree to which Vera has iterated and refined its own models.

“Today’s AI hype cycle obscures the very serious, very present risks that affect humans alive today,” O’Sullivan said. “Where AI overpromises, we see real people hurt by unpredictable, harmful, toxic and potentially criminal model behavior … AI is a powerful tool and like any powerful tool, should be actively controlled so that its benefits outweigh these risks, which is why Vera exists.”

Vera’s possible shortcomings aside, the company has competition in the nascent market for model-moderating tech.

Similar to Vera, Nvidia’s NeMo Guardrails and Salesforce’s Einstein Trust Layer attempt to prevent text-generating models from retaining or regurgitating sensitive data, such as customer purchase orders and phone numbers. Microsoft provides an AI service to moderate text and image content, including from models. Elsewhere, startups like HiddenLayer, DynamoFL and Protect AI are creating tooling to defend generative AI models against prompt engineering attacks.

So far as I can tell, Vera’s value proposition is that it tackles a whole range of generative AI threats at once — or promises to at the very least. Assuming that the tech works as advertised, that’s bound to be attractive for companies in search of a one-stop content moderation, AI-model-attack-fighting shop.

Indeed, O’Sullivan says that Vera already has a handful of customers. The waitlist for more opens today.

“CTOs, CISOs and CIOs all over the world are struggling to strike the ideal balance between AI-enhanced productivity and the risks these models present,” O’Sullivan said. “Vera unlocks generative AI capabilities with policy enforcement that can be transferred not just to today’s models, but to future models without the vendor lock-in that occurs when you choose a one-model or one-size-fits-all approach to generative AI.”"
69% of generative AI users are concerned their data might be misused - Security Magazine,https://www.securitymagazine.com/articles/99976-69-of-generative-ai-users-are-concerned-their-data-might-be-misused,"Wed, 04 Oct 2023 17:55:59 GMT",Security Magazine,"A recent Malwarebytes report found that online threats are affecting consumer behavior. Seventy percent of respondents have experienced some kind of cybersecurity threat such as online scams and viruses or malware, and roughly one tenth have experienced serious personal violations like stalkerware/spyware and ransomware.

According to the report, people readily give up a host of private information online by engaging in activities such as sharing their birthdate on social media (59%), interacting with strangers (54%) and taking quizzes that reveal personal info (45%).

Nearly 80% say they are ""very"" concerned about the risks of being online. Half feel confident in their ability to keep themselves safe. Financial and data breaches are people's top concerns. Despite high anxiety and the fact that 70% have experienced cybersecurity threats before, 35% use antivirus software.

Sixty-nine percent of generative AI users and 63% of TikTok users are concerned their data might be misused or stolen.

Identity theft ranks as people's third biggest concern when it comes to online security, just behind fear of financial accounts and personal data being breached Sixty-four percent agree identity theft protection is one of the most important cybersecurity tools and 13% have it.

One in four respondents feel there's no point in using cybersecurity tools given the vast number of threats, and 41% are unsure how cybersecurity tools can help protect them. Three in four parents feel they need better tools and education to keep kids safe online.

Read the full report here."
Visa establishes US$100M generative AI venture fund - Mugglehead,https://mugglehead.com/visa-establishes-us100m-generative-ai-venture-fund/,"Wed, 04 Oct 2023 22:18:13 GMT",Mugglehead,"California’s major credit card company Visa (NYSE: V) is launching a US$100 million venture fund for generative AI startups, an initiative aimed at solving system issues online that will be led by its Visa Ventures investment arm.

On Monday, the head of Visa Ventures David Rolf said that the company was excited to utilize the funding for working with startups and improving the company’s performance as a result. He said that generative AI was one of the most transformative technologies of our time.

Visa says the funds are intended to help companies involved with developing generative AI create innovative new solutions for problems related to commerce, payments and financial technology infrastructure.

Generative AI focuses on generating new content rather than analyzing or processing pre-existing data. The AI subset built on large language models can produce original text, images, video and other media.

Visa says it has been using AI for its payment systems since the technology’s very early days in 1993. VisaNet + AI is its most recently developed system, a suite of services powered by the technology designed to prevent fraud and make online payments more secure.

VisaNet is capable of processing 76,000 transactions per second, caters to approximately 3.6 billion account holders and analyzes trillions of dollars in payments volume with AI analytics.

Read more: Microsoft partners with Mercy to improve patient care using generative AI

Read more: Cisco secures US$28B deal to acquire leading cybersecurity firm Splunk

“While much of generative AI so far has been focused on tasks and content creation, this technology will also meaningfully change commerce in ways we need to understand,” said Visa’s Chief Product and Strategy Officer Jack Forestell.

Other major California tech companies that have invested in AI include NVIDIA (NASDAQ: NVDA), Adobe Inc. (NASDAQ: ADBE), Alphabet Inc. (NASDAQ: GOOGL), Cisco (NASDAQ: CSCO) and Salesforce (NYSE: CRM).

Visa shares have steadily risen by almost 25 per cent in the past year and they are currently trading for US$230.36 on the New York Stock Exchange.

Follow Mugglehead on X

Follow Rowan Dunne on X

rowan@mugglehead.com"
"Generative AI roundup: IBM, Wolters Kluwer and others offer new ... - Healthcare IT News",https://www.healthcareitnews.com/news/generative-ai-roundup-ibm-wolters-kluwer-and-others-offer-new-products-and-services,"Thu, 05 Oct 2023 15:05:43 GMT",Healthcare IT News,"Each day, more companies add generative artificial intelligence assistants to their products and services. This week, some of the biggest names in software announced integrations and implementations they say are safe and transparent uses of AI while a healthcare IT industry research organization published guidance on automation, ethics and trust.

IBM introduces Watsonx legal protections

To ease customer apprehensions about use of generative AI, IBM announced that it would indemnify its clients against intellectual property claims against IBM-developed watsonx models.

The company's standard contractual intellectual property protections for IBM products will apply to its specialized Granite models that apply generative AI to the modalities of language and code, according to its announcement last week.

Clients can develop AI applications using their own data along under the client protections, afforded by IBM foundation models.

IBM also said that it would publish its underlying training data sets.

Trained on business-relevant datasets from internet, academic, code, legal and finance, IBM-developed foundation models are curated for business uses.

""When it comes to today's AI innovation boom, the businesses that are positioned for success are the ones outfitted with AI technologies that demonstrate success at scale and have built-in guardrails and practices that enable their responsible use,"" Dinesh Nirmal, IBM Software's senior vice president of products, said in a statement.

On Monday, IBM announced on its website that it has partnered with telemedicine company Ovum Health to scale web and mobile app-based chat and scheduling solutions on its family-building platform providing pregnancy, prenatal and postnatal healthcare.

IBM assisted Ovum Health in the creation of a no-code platform for an AI assistant that leverages natural language models, according to a blog post. Ovum then fully integrated watsonx Assistant into its web interface and iOS app in less than two months

Wolters Kluwer unveils AI Labs

On Tuesday the Waltham, Massachusetts-based company introduced a new UpToDate integration called AI Labs.

The clinical decision support system is relied on by more than two million users at over 44,000 healthcare organizations in 190 countries to view more than 650 million topics per year, according to Wolters Kluwer Health.

""Bringing together the power of UpToDate and generative AI can help drive value for both clinicians and patients,"" Greg Samios, president and CEO of clinical effectiveness, said in the announcement.

""With this advanced capability, we have an implementation of generative AI that could help clinicians make better and more informed decisions to deliver the best care everywhere.""

Dr. Peter Bonis, Chief Medical Officer, said the company has long incorporated AI to synthesize medical literature and the experience of physicians into 12,400 clinical topics.

To help hospitals and health plans better aggregate data from disparate electronic health records after mergers, Wolters Kluwer developed a machine learning model to improve the process mapping lab results and other data to standardized LOINC codes.

""We are committed to setting a standard for the responsible application of generative AI to the complex realities of front-line healthcare,"" Bonis said.

""The approach they have taken is the right one and I look forward to seeing how it evolves,"" Julio Ramirez, chief scientific officer at Norton Infectious Diseases Institute, added.

Chilmark offers an industry guide for AI adoption

Also this week, Chilmark Research released its first eBook, ""Building Responsible AI in Healthcare: A Journey into Automation, Ethics and Trust.""

The ebook from the healthcare IT research and advisory firm explores how to develop trust in AI technologies and implementation that creates a positive impact on patients, providers and organizations.

Content includes a combination of its public and premium articles and reports from the last three years, and covers:

The evolving regulatory landscape and need for guide rails.

Emerging best practices on developing and implementing AI.

Bias in AI and how to address health equity mandates.

""We're still in the early days of mass adoption, so most use cases are low-risk, focused more on administrative and operations use cases,"" John Moore, Chillmark's managing partner, said in a statement.

""With overtures being made about broader adoption for clinical decision support, understanding the limitations of these tools and the need for human interpretation is critical.""

""Organizations will need to have a deep understanding of fairness and equity from a political philosophy or anthropological perspective, develop design expertise relevant to machine learning, and consciously monitor applications over their entire lifespan in order to improve and maintain trust of users and patients,"" added lead author Dr. Jody Ranck.

Ranck, the firm's senior analyst, has explored state-of-the-art processes for AI bias and risk mitigation and how develop more trustworthy machine learning tools for healthcare.

Andrea Fox is senior editor of Healthcare IT News.

Email: afox@himss.org

Healthcare IT News is a HIMSS Media publication."
"SucceedSmart Unveils Generative AI Tool for Crafting Unbiased, Accomplishment-Based Job Descriptions Within Minutes - Yahoo Finance",https://finance.yahoo.com/news/succeedsmart-unveils-generative-ai-tool-103000873.html,"Thu, 05 Oct 2023 10:30:00 GMT",Yahoo Finance,"Flawed Job Descriptions Cost Companies Top Talent and Hinder Diversity Efforts

LOS ANGELES, Oct. 5, 2023 /PRNewswire/ -- Sound familiar? When a company re­cognizes the nee­d for a new role or replace­ment, the process of de­fining that position begins. Sometimes, te­am members may search the­ internet for inspiration from various sources, re­sulting in a job description that combines responsibilitie­s from multiple roles. This well-inte­ntioned effort then re­aches the hiring manager and is either poste­d to attract applicants or given to external firms to start the search.

Connecting corporations with the world's best executive talent. (PRNewsfoto/SucceedSmart)

At the heart of the matter lies this concern: an inadequately crafted job description can introduce unintended biases. More than that, it sends everyone on a misguided hunt for talent, squandering precious time, energy, effort, and money, let alone keeping a leadership position open for longer.

Enter SucceedSmart. Recognized for its AI-driven executive search platform, which matches talent based on accomplishments and experience, SucceedSmart identifies the flaws inherent in job description creation as the root of many hiring issues. To address this, SucceedSmart proudly unveils Taylor, a generative AI platform currently in Beta, designed to innovate creating and vetting job descriptions.

""Job descriptions are the starting point of any hiring process. If they're flawed, everything that follows can be skewed,"" remarks Sanjay Sathe, Founder and CEO of SucceedSmart. ""Our new tool, Taylor, either crafts a fresh, unbiased job description that's accomplishment-focused, or reviews an existing one, flagging biases and recommending essential changes.""

For instance, Taylor might identify terms like ""young and enthusiastic,"" suggesting alternatives to avoid age bias. Gender-specific pronouns and language potentially deterring candidates with disabilities are also flagged, ensuring companies maintain an inclusive hiring approach.

Story continues

In a world where­ inclusivity is expected, Taylor offe­rs an invaluable solution to the hiring process, prioritizing fairne­ss and accuracy. Seamless integrated with the SucceedSmart platform, Taylor ensures impeccable executive matches.

Experience Taylor's transformative potential first hand reach out to us at taylor@succeedsmart.com

About SucceedSmart

SucceedSmart is an award-winning executive recruiting platform that leverages proprietary and patent pending artificial intelligence and a unique, privacy-centric approach to match executives with organizations. Committed to diversity and transparency, SucceedSmart removes inefficiencies and inflated costs common in traditional job boards and recruiting methods. To learn more about SucceedSmart, visit www.succeedsmart.com .

Media Contact:

Jeff Schwartz

917-847-6329

pr@succeedsmart.com

Cision

View original content to download multimedia:https://www.prnewswire.com/news-releases/succeedsmart-unveils-generative-ai-tool-for-crafting-unbiased-accomplishment-based-job-descriptions-within-minutes-301947781.html

SOURCE SucceedSmart"
Temple's new AI policy prioritizes student learning - Temple University News,https://news.temple.edu/news/2023-10-04/temples-new-ai-policy-prioritizes-student-learning,"Wed, 04 Oct 2023 19:29:30 GMT",Temple University News,"When ChatGPT was publicly released on Nov. 30, 2022, it rocked higher education and left educators asking how they could protect learning against its improper use. At Temple University, this question propelled Lori Salem, assistant vice provost and director of the Student Success Center, and Stephanie Fiore, associate vice provost and senior director of the Center for the Advancement of Teaching, to find an answer.

Salem and Fiore had been tasked with developing an AI policy for Temple in response to ChatGPT that would allow students to benefit from the tool while simultaneously guarding against its misuse. At the same time, they also had to keep in mind that generative AI would likely become a foundational tool in most industries, which would then require students to be well-versed in the technology to be competitive in the job market.

Ultimately, the pair succeeded. In late August, Provost Greg Mandel announced through an email to the Temple community that Temple’s first AI policy would allow faculty to determine whether or not they permitted the use of generative AI in their classes. The policy also stated that when a faculty member has not explicitly stated their stance on the use of AI, the default policy, for now, must be that its use is prohibited. The student code of conduct was also updated ahead of the start of the semester to reflect the university’s new policy. In addition, faculty who request access to the university licensed Turnitin AI detector will be required to complete a brief asynchronous training to ensure they understand the limitations of the tool.

“I think its notable and exciting that the director of the Student Success Center and the director of the Center for the Advancement of Teaching are partnering together on this issue to develop Temple’s AI policy,” said Dan Berman, vice provost for undergraduate studies. “This is the right approach because it means the focus is on protecting students’ ability to learn and thrive in the classroom, in partnership with their instructors.”

Salem echoed this sentiment when describing Fiore and her approach to developing the policy. She feels confident that their approach to the AI policy reflects how Temple strives to work with students. “We wanted the policy to emphasize the importance of the learning experience here,” she said. “It’s not supposed to be about catching and disciplining people.”

During the spring and summer semester following ChatGPT’s launch, Salem and Fiore were methodical in developing Temple’s new AI policy. They spoke with hundreds of Temple faculty, including the Faculty Senate, and over 100 Temple students to better understand how the Temple community felt about incorporating this new technology in the classroom. They also engaged with peer institutions to learn how they were responding to generative AI tools. Fiore joined a national group of educational developers that meet monthly to discuss AI issues and exchange ideas and updates on AI policies.

It became increasingly clear to Salem and Fiore through their conversations that they also needed to investigate whether there were reliable ways to detect the improper uses of AI. However, ChatGPT was such a new technology that there was little data about the effectiveness of AI detectors. So, Salem and Fiore decided to run their own research test using an AI detection tool from Turnitin, which they found to be the strongest of the available AI detection tools.

They created 120 samples of writing that were broken into four categories: entirely human-generated, entirely AI-generated, generated using an AI paraphrasing technique, and a hybrid of both human- and AI-generated text. They then ran these texts through Turnitin’s AI detection tool and found that it almost always correctly identified the entirely human and entirely AI-generated texts but struggled with the hybrid and paraphrased texts.

This study was instrumental in helping Salem and Fiore develop Temple’s AI policy. Paired with the extensive conversations they’d had with the Temple community and industry peers, they were able to establish the temporary AI policy for the fall 2023 semester that was announced through Provost Mandel’s email.

Fiore says that she has received positive feedback from colleagues at other institutions about Temple’s nuanced policy. “It puts the decision-making about the use of AI in the hands of faculty where it belongs, but also proactively includes a blanket policy for the fall semester,” she says. Fiore believes the blanket policy provides “breathing room” for faculty to develop more expertise with generative AI before deciding to incorporate it in their classes.

The policy ultimately empowers faculty to prioritize learning. “If the whole purpose of an assignment was for the student to wrestle with figuring out how to articulate something, then using AI would disrupt the purpose of the assignment,” says Fiore. “But, in other cases, when the purpose of the assignment is to just get background knowledge of a topic so that they can do something with it in class, in that case, using AI is not necessarily a problem.”

Salem and Fiore’s work is far from over. Their initial policy took a cautious approach to ensure that the Temple community had clear guidance on the use of generative AI for the fall semester. It also gives Salem and Fiore more time now to continue exploring more nuanced stances on AI for future semesters, while also allowing their colleagues time to learn more about the technology. In the meantime, Salem and Fiore received an invitation to formally present their findings to the team at Turnitin in order to help further refine their AI detection tool. The pair readily accepted the invitation with the hope that their work will help their peers around the world be better equipped to facilitate learning in the time of AI.

“It is important for students to understand how to use these AI ethically and effectively, as it has the capacity to be helpful to students in learning and in their future workplaces when used appropriately,” says Fiore. She just wants students to remember that learning happens through the thinking, writing and iterative process of doing their classwork. “Using these tools as a shortcut will ultimately cut short their learning and growth—which is the ultimate goal of a college education.”"
Getty Images CEO Craig Peters has a plan to defend photography ... - The Verge,https://www.theverge.com/23903700/getty-images-craig-peters-generative-ai-images-disinformation-payment,"Thu, 05 Oct 2023 14:04:39 GMT",The Verge,"We’ve got another great conversation from the Code Conference today: my chat with Getty Images CEO Craig Peters. Getty is one of the most important photography services in the world, and as you might imagine, we talked quite a bit about the promise and peril of generative AI when it comes to photography. Craig was great onstage — he’s direct and no-nonsense about what AI can and can’t do, and we got right into it.

About a year ago, Getty banned users from uploading or selling AI-generated content. At the time, the company said it was concerned about copyright issues in AI. Eventually, it sued Stability AI for training the Stable Diffusion tool on Getty’s photos — at times, Stable Diffusion even generated Getty watermarks on its images.

But Craig doesn’t want to completely stop AI from happening: just before Code, the company announced Generative AI by Getty Images — a tool that generates pretty solid AI photography of its own. Getty trained the tool itself, using images it already had the rights to, and it’s put up some pretty strict guardrails around what it can do. (It certainly cannot generate any images of known celebrities.) What’s more, Getty’s come up with a way to compensate the photographers whose images are being used to generate images, which is pretty interesting — and pretty complicated.

Listen to Decoder, a show hosted by The Verge’s Nilay Patel about big ideas — and other problems. Subscribe here!

I had early access to the new Getty tool, and we had some fun coming up with prompts to show the Code audience. I encourage you to watch the video of this episode, available on YouTube, so you can get a look at the images we’re talking about.

You’ll hear Craig talk a lot, not just about copyright issues, but about what people are really talking about when they talk about intellectual property: money. What does compensation for being part of an AI training set look like? How can you distribute that money fairly?

We also talked about the other elephant in the room when it comes to AI: deepfakes and disinformation. Getty has a long history as a repository of significant, important, and, most importantly, REAL photos of people and events. The 2024 US election is barrelling toward us quickly, and Craig told us that while Getty doesn’t yet have “perfect solutions’’ for disinformation, the date isn’t moving, and he’s working with both partners and competitors to race against the clock to make sure authentic images are the ones people see.

Okay, Craig Peters, CEO of Getty Images. Here we go.

This transcript has been lightly edited for length and clarity.

We should start with the news, because I think a lot of people expected you to show up and rail against the taking of content by AI but you actually announced an AI tool this week.

We did, we did. We launched it on Monday after coming out of Alpha. We launched that in partnership with Nvidia. So, we partnered up with them and their capabilities to launch what we think is a pretty unique tool. A tool that, first off, respects the IP that it was trained upon. It’s permissioned — it’s trained only off of Getty Images creative content. We are providing rewards back to the creators of that content. So, as we grow revenues from this service, those creators are rewarded for their contributions to the tool. It’s entirely commercially safe, so it cannot produce third-party intellectual property. It cannot produce deepfakes. It doesn’t know what the Pope is, it doesn’t know what [Balenciaga] is, and it can’t produce a merging of the two. And we think for version one, the quality is quite remarkable. Because obviously, we’re a big believer that quality in gives you a better outcome.

I have a lot to talk about with you. Craig very boldly allowed me [early] access to this tool. I told him what prompts I was going to use, but I didn’t show him the results. So, here’s the first one I put up.

Screenshot by Nilay Patel / The Verge

“The well-dressed and influential attendees at the Code Conference, [in a] fancy hotel ballroom.” I will say, I originally said, “In the Ritz-Carlton,” and [the tool] wouldn’t let me do it. Because, I think, it thinks “Ritz-Carlton” is a very fussy name for someone here. Wide angle shot of the crowd. So, here’s the result. Here’s all of you. You look great. Very excited.

AI-generated photo by Getty Images

I asked it to do it again, and I think next year, we’re going to have you all sit on the floor in the round. Pretty good.

AI-generated photo by Getty Images

So, then I thought I should do something on the news cycle. “Famous pop star and Super Bowl-winning tight end holding hands in a convertible.” I think y’all know where this is going. It’s obviously Zac Efron having the time of his life.

AI-generated photo by Getty Images

Now, to be fair, I did not specify gender, sexuality, ethnicity — anything. This is a reasonable result for this query, in my opinion. And again, Zac and Marcedes Lewis look great. And then here, I asked it to do it again. This is great. This is more or less what Travis and Taylor look like.

AI-generated photo by Getty Images

I don’t know why she’s wearing pads, but it’s good. And then lastly, there’s the image that I personally really wanted, which is “the CEO of a major car company running away from our conference.”

AI-generated photo by Getty Images

Here’s Mary and our security guard looking good. These are remarkable results. There are the AI problems — you pay too much attention to the hands or whatever, but the hardest problems have been solved. And I can see how, if I was actually writing the story, if I was being a little bit meaner to GM than I might otherwise, I might use a photo like this. You think that that’s what people want in the markets that you’re in?

Definitively. First of all, generative AI did not just burst onto the scene. It’s been something that has been around for years. Nvidia, our partner, actually launched the first GANs model from text to image. And so we knew it was coming, and our question to our customers was, “How are you going to use it? What do you need?”

We create services for our customers that really allow them to create at a higher level, that save them time, save them money, and eliminate their IP risk. And that last piece is critical within AI. Everything that we heard from our customers was, “We want to use this technology.” And that could vary from media customers to agency customers to corporate customers. They want to unlock some of their creativity through these tools, but they need to make sure that they aren’t in violation of third-party intellectual property.

That can also vary around the globe. If you have an image and it produces an image of a third-party brand or somebody of name and likeness like [Travis] Kelce or [Taylor] Swift, that’s a problem. But there’s much more nuanced problems in intellectual property, like showing an image of the Empire State Building. You could actually get sued for that. Tattoos are copyrighted. So, fireworks can actually be copyrighted. That smiley firework that shows up? Grucci Brothers actually own that copyright. So, there’s a lot of things that we baked in here to make sure that our customers could use this and be absolutely safe. And then we actually put our indemnification around that so that if there are any issues, which we’re confident there won’t be, we’ll stand behind that.

There’s a flip side to that. So, you know all the training data is yours. We asked a bunch of provenance questions of [Microsoft CTO] Kevin [Scott] earlier. You know the provenance, right? And the next thing that enables you to do is say, “Okay, we’re going to go pay our creators.” How does that work? What’s the actual formula for saying, “We generated this image. Someone paid us for it, and now upstream of that, we’re going to pay you however many cents”?

“If we find fairer ways of doing this, we’ll certainly embrace it.”

Right. I think Kevin talked a little bit — I was getting mic-ed up in the back — but I think he talked a little bit about attribution and whether the technologies exist in order to do that. In our case, at a pixel level, I think the question was earlier around audio. The answer is, right now, those models don’t exist. We tested out a bunch and didn’t find them to be sufficient in order to do that attribution. So, the way we’re doing it is we’re doing it off of two things: What proportion of the training set does your content represent? And then, how has that content performed in our licensing world over time? It’s kind of a proxy for quality and quantity. So, it’s kind of a blend of the two.

So you’re just doing sort of a fixed model.

Yeah, and we’ll evaluate that over time. If we find fairer ways of doing this, we’ll certainly embrace it. We looked for technology that might do that, but at this point in time, I think it falls short of the goal.

The dynamic here is really interesting. So, your customers want this — I need to generate a stock photo or something for an ad campaign, and instead of hiring a photographer, I might go to the Getty tool. Will the Getty tool be cheaper? Will it undercut the hiring of a real photographer?

I think that’s yet to play out. I think it is an entirely different model. It’s a cost-per-call type model, generative model. You played with the tool; I think this is a very good tool in terms of how it walks you through the prompts and what you can get out of it — quality from the start. It gives you high res from the start. But it’s work. I think comparing and contrasting that to licensing pre-shot is something that we’ve done some time studies with customers and things along those lines. And I think it varies.

Ultimately, again, we try to save our customers time because that is the most expensive thing that they’re applying. And I think, in some cases, this can be very creative but not necessarily the most time-efficient. And I think our pre-shot, in many cases, can be much more authentic and much more efficient because you’re searching. You’re not paying for that search. You’re getting a wide variety of content back with real people, real locations. And in many cases, brands care about that. But that can be a much more efficient process. So, I think, really, we’re going to find out over time.

Getty’s a unique company in the space. You actually employ a bunch of photographers. You send them to dangerous places. You create a bunch of news photos. Are you hearing from your own creatives that this is a problem?

I wouldn’t say that we’re hearing from our own creatives that AI is a problem. We represent over half a million photographers worldwide. So you can imagine that within this audience, there’s a lot of different perspectives and points of view, and take that and multiply it times 1,000 and you’re going to get even more. What we hear is a lot of concern about intellectual property. We hear concerns that, ultimately, things are being trained on their intellectual property, and there’s value being created for that, either through subscription services or through other models. Ultimately, people want that to be solved for. But what we hear from our customers is, again, they want to create, and they want to use these tools.

Our point of view from the get-go has always been: We believe AI can have a constructive benefit for society as a whole, but it needs to account for certain things, and so we’ve always looked for transparency in trading data. We believe creators and IP owners have the right to decide whether their material is trained on. We believe the creators of these models shouldn’t be covered by something like Section 230, that you should have some skin in the game and take on some liability if you’re creating these things and putting them out there. Again, our tool is one that… We were very conscious — as a member of the media, the last thing we wanted to do was produce a tool that actually could produce deepfakes. So your Taylor Swift and Kelce example is a good one: you’re going to struggle because it doesn’t know who Taylor Swift is, and it doesn’t know who Kelce is.

“You’re going to struggle because [the AI] doesn’t know who Taylor Swift is ... and that’s intentional.”

The only thing in the world that doesn’t know who Taylor Swift is.

Yeah, that’s exactly right. And that’s intentional. And I’d like to think that Taylor Swift will appreciate that.

What are we all working for? It’s for Taylor Swift.

Exactly.

Inside of that, there’s some big ideas there. So, in my brief career as a copyright lawyer and my longer career as a journalist, I find that no one actually cares about copyright law. They don’t care about the IP. They care about the money. But the money right now is downstream of some very thorny copyright issues.

You heard Kevin say he thinks — Microsoft thinks — that all this is built on a fair use argument that will eventually succeed or be modified in some way. You are, in many ways, on the other side of this. You’re suing Stability for having trained on a bunch of Getty images. If you win, maybe this whole edifice falls down. Have you thought about the stakes of that lawsuit?

There are high stakes around that lawsuit. We brought it for a reason. We fundamentally believe that IP owners should have a right to have their content, whether it’s used in training sets or not, and they should have the right to be compensated if that’s their choice. And I don’t buy the argument that Kevin put out there that I read Moby Dick, and therefore... First of all, these computers are not humans. Secondly, they’re actually corporate entities and are making money, to your point. And in many cases, they’re targeting existing markets with these technologies. I think the Warhol case, I mean…

That’s why we’re here.

We’re a little bit more IP geeks than others, but I think the Warhol case—

Why do you think we played Prince in front of Kevin?

Yeah, I was wondering! What did I get? It was supposed to be the Bangles, I think. Interesting. But I think that’s going to play out. I think we’re in the right. I think a world that doesn’t reward investment in intellectual property is a pretty sad world. Whether that’s music, whether that’s editorial journalism, whether that’s imagery — I believe we want to see more creators, not less. And I think it’s actually interesting. Chris [Valenzuela] was on the stage last night from Runway doing some demos, and I think Chris’ point of view is one that we share. We want more creators because of this technology, not less. And I think that’s a great world.

So, how do we enable it? That’s why we put this tool out there. We put this tool out not to disintermediate creators; we put this tool out there to enable creators. The users of our tool are creators, and I think it’s going to allow them to create in more insightful and innovative ways. But I think others are, in some cases, pointing these technologies directly at the creators themselves or, in some cases, coders. And I don’t think that is the society that I want to necessarily push toward.

Obviously, you’re in litigation with Stability. There are lots of other companies that are potentially training on Getty Images, lots of other companies that are just out there crawling the web and training on that. Are you in productive conversations with the Microsoft or the Googles or the OpenAIs?

We are in productive conversations. Whether they result in something that’s productive, I don’t know.

First of all, I think there’s a PR bullshit layer of like, “Alright, I’m going to join this group, and I’m going to try to cleanse my reputation because I’m a member of that. Of course, I don’t implement anything around it. I don’t do anything. I just cite the fact that my corporate name is on that website.” I think that’s not real engagement. I think we can have different points of view on law, but I think one of the things I hope our model proves is that [putting] good quality ingredients in creates a better output. It creates a more socially responsible output, and it creates one that I think businesses will adopt.

“I think there’s a PR bullshit layer of like, ‘Alright, I’m going to join this group.’”

So, yeah, we’re in conversations there, but we aren’t going to move off of the fundamental point, which is: we believe if you’re an IP owner, you should have the right to decide whether your content’s used in training and you should be compensated for that right. And that doesn’t mean a de minimis check. It’s fundamental to these tools.

We’ve talked a lot about music at the conference generally. Again, I’m a nerd for this stuff, but broadly, the music industry has developed its own private copyright law because the courts are a coin flip in fair use arguments — like crazy coin flips in fair use arguments. And so the music industry is just like, “We’re going to make our own deals on the side. We’ll have our own norms.” My favorite example of this, by the way, is the publishing rights for the “Thong Song” by Sisqo are owned by Ricky Martin’s songwriter because Sisqo just whispers the words, “Livin’ La Vida Loca.”

If you apply that standard to AI, none of these companies are making money. But the music industry has developed that set of norms. Do you see that happening here where you’re going to need the courts to figure it out for you or that there will be an industry set of norms around licensing and deal-making because the courts are unreliable?

My hope is that we will not need to rely on the courts. Unfortunately, I can’t say that’s the case across the board. I think there are some very responsible technology organizations that are having dialogue, that are willing to figure out solutions. They understand the stakes at play. And I think you can have those conversations. I think there are others that are just off doing what they want to do and damn the consequences. Damn the consequences for IP ownership. Damn the consequences for deepfakes and what that means to press and facts and democracy. So, I hope we can all agree on it.

I don’t know that that’s necessarily going to be the case, which is why we not only invested a ton of time and resources to launch a product that we think actually proves that you can do this responsibly — by the way, a lot of those actors said, “Well, you could never do this. You could never get access to licensed data, so we didn’t even try because it’s an impossible thing.” Which, again, I call bullshit on, and I think this tool is a big bullshit on that statement.

But we launched. We’re spending millions of dollars to go on the other route because we don’t have 100 percent confidence that we’re going to be able to get there. We hope, and we’ll engage with anybody that wants to, but similarly, we needed to have that other track.

Two more themes I want to touch on: You and I have talked a lot about authenticity. You mentioned deepfakes. Getty does generate some of the most important photographs of our time. Historically, this is the role that Getty plays in our culture. You’ve said to me that just marking that stuff as authentic is not good enough, that there’s another problem here. Describe what you think that other problem is.

Well, I think there’s a problem where you can’t discern what is authentic. In a world where generative AI can produce content at scale and you can disseminate that content on a breadth and reach and on a timescale that is immense, ultimately, authenticity gets crowded out.

Now, I think our brand helps cut through. I think our reputation helps cut through. I do think, ultimately, that has value, but I do worry about a world where... I think this past year, I heard the stat that there were more AI images produced than were shot on a camera. That’s just staggering. Think about where we are in the adoption curve of AI — just play that out on an exponential basis. And then again, you think about a world where there are nefarious individuals and organizations and institutions, and that worries me. Our newsroom lit up when the Pentagon image was put out there. “Is it real?” And we’re getting calls asking for us to validate that. Now, let’s put that into an election in 2024.

You’re in the Content Authenticity Initiative group, right?

We’re in the discussion. We haven’t adopted it, to be quite frank. We’re not sure that that is the right solution right now. First of all, it puts the onus and the investment on the people creating original content, authentic content, rather than on the platforms and the generative tools that are producing generative content, and we fundamentally think that’s a little bit backwards. The generative tools should be investing in order to create the right solutions around that. In the current view, it’s largely in the metadata, which is easily stripped.

“In a world where generative AI can produce content at scale ... ultimately, authenticity gets crowded out.”

So, you guys are a customer of ours. You use our imagery. You strip our metadata immediately when you put it in your CMS because it’s lighter and page loads and everything else, which makes sense because you’re competing for SEO and everything else that you need to do. So, you strip it. And so I think what we need to look… And this is where we’re engaging with Kevin and Microsoft and their team — we’re really encouraged by the pledges that they made to the White House in order to identify generative content. Because we want to do the exact same thing, but we want to do it in a way that really gets at the core.

Are you taking any particular steps ahead of the 2024 election, knowing that you’re going to compete for real photographs — real images — in a world of generative AI?

We are, I would say. We’re talking with The Associated Press. We’re talking with Agence France-Presse. We’re talking with our partners and our competitors about, “How do we go about doing this?” While we’re taking steps, we don’t have perfect solutions. And again, that date isn’t moving, and we’re getting closer and closer to it.

I think this is one of those things where putting technology out into the world u

“I think if we try to eliminate creators, I think it’s a sad world.”

nder the “let’s just move fast and break things…” — we’re playing with bigger stakes here.

Last big thing, and then we’ll go to the audience here. When Craig and I first started talking, one of the things you and I discussed was that the market for photography changed inevitably forever when the internet arrived, and more people could create, and our distribution platforms changed. Pricing collapsed. I know a lot of professional photographers [whose] careers evaporated with the advent of the internet, effectively.

Does this feel like that? And you’ve built a business in response to that — you’ve changed the business. Is this that same moment, do you think? Is it the same level of change?

I think it’s clearly a lot of change. I think what we do has value, whether that’s a tool that can enable creativity or content that is highly authentic, that can engage an end audience in a meaningful way and move them — if you’re a media company, move them to understand an issue, or if you’re a corporation, move them to actually engage with your brand or your products. I don’t think that goes away.

I think this puts different challenges in that it’s actually fun to navigate and figure out. I think the most important thing that will allow photographers, videographers, writers… is that we enable more creators. That’s the end goal. If we do that, then I think the world’s a great place. And I think companies like Getty Images will thrive in that, and those that work with us will thrive within that. I think if we try to eliminate creators, I think it’s a sad world, and I think it’ll be challenging for our business and for those that try to make a living.

Audience Q&A

Andrew Sussman: Andrew Sussman. So, with copyright and patents both stemming from the same part of the Constitution, “Congress shall promote the useful arts and sciences...” yet patents over the years have seen a narrowing, a constriction in the exclusive rights that are being granted.

Yet copyright has seen largely only an expansion [of rights], whether it be how long they last, whether it’s what they cover. And in this case, it seems like some of the creative expression aspects are being wrapped into what are more procedural or data elements. Like if you were to take a text or an image and convert it into a series of numbers, where is the creative expression in that? So, just curious as to if, in connection with Congress revisiting what the scope of copyright includes, should they also be looking at how broad copyright is as a general nature?

Craig Peters: Well, first off, I think the Copyright Office right now is in an active open submission for input on AI and the degree to which copyright is or is not applied. Obviously, we have a point of view on that, and we’ll put a brief in and give input into that. But I think copyright needs to be something that constantly evolves. The world constantly evolves. I think that’s ultimately something… I think regulatory institutions — government, legislative — evolve at a slower pace than technology. They tend to lag. But I do think they are doing their best to go through and be contemplative about, “How does this move the needle or not on copyright?”

I think they’re bringing all the voices in together in order to do that, and I think they’ll come out in what is a reasonable space, I think. But my point is that copyright needs to evolve, and if we want it just to stay stagnant, it’s going to ultimately not match up to the world that we’re living in. So, I don’t know if that answers your question, but that evolution’s critical.

Jay Peters: Jay Peters, with The Verge. I know the new AI tool is designed not to create images of real people, but what if it does? What if it makes a Joe Biden? What if it makes a Donald Trump? What if it makes a Pope? What does Getty do in that situation?

Craig Peters: It can’t. It doesn’t know who they are.

JP: Is there any way for somebody to engineer a prompt, though, that gets a pretty close approximation?

CP: No, because it doesn’t know who they are. It really doesn’t. So, if you go on Bing and you do “Travis Kelce and Taylor Swift,” it will give you somebody wearing a Chiefs uniform that kind of looks like Kelce. You won’t be able to type “Taylor Swift and Travis Kelce,” but just do “Swift” and “Kelce,” and you’ll get an output. That’s because it was trained on the internet. It was trained on our content and others that sit out on that internet. Therefore, it knows who they are.

This content was trained in a universe where that doesn’t exist. So, it really does not know. Now, we put in prompt engineering. We put things in there that can inform you that that’s not something that this tool will respond to. But even if we missed that prompt because we didn’t think of that in terms of the architecture, it won’t produce that output.

Unless we open it up to train on other content, it cannot produce those outcomes. And I think that’s, again, thinking about how you build these tools so that they can really be beneficial to businesses and corporations and, at the same time, be responsible to society. I think it’s a really important element.

Now, I think what we can do is we can take third-party intellectual property where they actually have the ownership rights, and then we can do custom fitting or what is custom training of that along with Nvidia to produce a model that’s bespoke to that IP. But that’s the case again, where that IP will be owned or have the necessary permissions in order to bring that to the table. So, we’ll be doing that with brands and companies over the coming months and years in order to produce some of those. But the fundamental piece here is most large language models, generative models, because they’re trained on open data sets under the notion that that is fair use, they know a lot. And they have to now do prompt engineering in order to restrict it. And that’s like whack-a-mole, right?

Miles Fisher: Miles Fisher. Appreciate your candid responses. You talk about, big picture, enabling more creators. That’s the greater good, so I agree with that. With the advent now of deepfakes, a lot of the academic think pieces compare the criticism to the advent of the camera in the mid-1800s. Creators are left with nothing — artistry of painting, all of that rendered mute. I’d just like to know personally, what do you think makes an exceptional photograph?

CP: That’s a good question. To me, it’s the one that moves you. So, there’s a level of photography that I think, whether it’s computer generated or otherwise, it’s the one that makes you stop, think, react, have emotion, engage. That’s a great photo. Whether that’s in news, whether that’s in sport, entertainment, or in a creative moment with a brand, I think those are the things that talent truly can express. And that’s why I believe in creative talent. Because I don’t think the expertise that goes into… Just let’s take what people might call stock for a second — if you knew what went into producing a great piece of imagery that actually got your attention, these are people that are understanding how to bring empathy, trust, integrity into photos in a new way that you haven’t thought about before, and they can grab that attention to put that on an audience. That’s tough to do. I sometimes equate our business to fast fashion in the creative sense because we’re constantly having to do something new because somebody else is going to knock off what we just did yesterday. But that’s what makes photography great at its core. It’s something that makes you stop, think, emote, engage.

NP: Well, that’s a great place to end it. That was a great question. Thank you so much, Craig.

CP: My pleasure. Thank you."
SugarCRM Touts Generative AI's Potential at London Conference - Destination CRM,https://www.destinationcrm.com/Articles/CRM-News/CRM-Featured-Articles/SugarCRM-Touts-Generative-AIs-Potential-at-London-Conference-160859.aspx,"Wed, 04 Oct 2023 20:11:00 GMT",Destination CRM,"SugarCRM Touts Generative AI's Potential at London Conference

SugarCRM, on the first day of its Connected 2023 conference in London, reiterated its commitment to empowering companies with cutting-edge technology that automates much of their daily workflows

Everything in business is becoming more complicated, but businesses want solutions that make their sales much easier, said Stuart Hall, vice president of customer success for EMEA at SugarCRM, pointing to the combination of hyper-automation, artificial intelligence, social media, growing mountains of data, and supply chain disruptions that are challenging businesses on a daily basis. “We are connecting the dots for you to make your life easier,” he said.

For example, SugarCRM now automates messages from different parts of the platform rather than forcing users to move into messaging apps. Sales managers can now call up a wide variety of visual reports rather than needing to construct the reports and build graphic representations. End customers can use self-service to solve or correct a number of issues without involving SugarCRM technicians.

""Let the platform do the work; automate anything; accelerate everything; and anticipate what's next,"" said James Frampton, SugarCRM's senior vice president and general manager of the EMEA region. That work includes demand generation, lead nurturing, sales acceleration, opportunity pipleline processing, management and predictions, and service and support.

The pipeline capabilities are particularly important, he said, because more than half (54 percent) of sales leads generated by marketing are either poorly qualified or unqualified.

The SugarCRM platform includes cloud, workflow and automation, configurability, integration, identity/pricing, and security. What’s next, he predicted, is ""generative AI for everyone. The CRM revolution will be driven by generative AI.""

Generative AI will enable users to ask anything, find everything, create workflows, easily configure apps, and much more, he said. The technology will be able to compose personalized sales and marketing content; create ad-hoc reports and workflows.

SugarCRM is building its business on three primary pillars: user experience, generative AI, and a focus on the manufacturing and distribution industries, Clint Oram, the company's co-founder and chief strategy officer, said in an interview with DestinationCRM.

""If there's one thing I've learned in my 25 years in the CRM industry, CRM is a beauty show. You have to have a beautiful application, you have to be designing an app that's easy to use, if not even fun to use.""

Most CRM users don't have technical backgrounds, Oram explained. ""The people whom we focus in on are the people using an application. They want to use what they want to use as opposed to someone telling them what they have to use. So we invest in user experience continuously.""

Just as the three rules of real estate are ""location, location, location,"" the three rules of software are ""easy, easy, easy,"" according to Oram.

Now, and in the immediate future, that means investing in generative AI, SugarCRM’s second pillar, according to Oram. Generative AI, he said, ""is completely rewriting the way all software companies are going to be thinking about delivering the user experience, the voice-based user experience and the natural language-based user experience that is interpreting what you're saying and making very intelligent guesses on what you mean by what you're saying. The future of applications is all wrapped together.""

Rather than clicking through multiple screens, in the near future, sales managers will be able to use generative AI-powered applications via voice for complex questions about sales over a given time period, sales in a particular region, and predictive analytic questions, according to Oram.

Looking 12 months out, Oram predicted that generative AI will move from everyone talking about the technology to many businesses using it on a daily basis for CRM and a number of other applications.

As for SugarCRM's third pillar, Oram said there is a large need for a simple CRM solution in manufacturing and distribution, which rely on enterprise resource planning systems for inventory but typically don’t have updated CRM systems on the front end,

A third of SugarCRM’s customers are already in manufacturing and distribution, two industries where SugarCRM is seeing growth. SugarCRM is focusing on making its solutions as easy as possible for people in those industries to use."
Health tech startup Atropos reveals generative AI tool for parsing ... - Endpoints News,https://endpts.com/health-tech-startup-atropos-reveals-generative-ai-tool-for-parsing-patient-records/,"Thu, 05 Oct 2023 11:00:00 GMT",Endpoints News,"At­ro­pos Health, a start­up that works with health sys­tems and life sci­ences com­pa­nies to an­a­lyze clin­i­cal da­ta, is launch­ing a prod­uct to help re­searchers quick­ly get in­sights on pa­tient pop­u­la­tions.

The new tools, the com­pa­ny claims, can in min­utes turn around queries from large, messy datasets. One use, for ex­am­ple, would be to parse large num­bers of pa­tient records to bet­ter iden­ti­fy co­horts or datasets that oth­er­wise would have to be painstak­ing­ly sliced or an­a­lyzed. That could help more quick­ly iden­ti­fy whether a sub­set of rare dis­ease pa­tients would ben­e­fit from a par­tic­u­lar treat­ment."
3 hard truths about GenAI’s large language models - CIO,https://www.cio.com/article/654465/3-hard-truths-about-genais-large-language-models.html,"Wed, 04 Oct 2023 20:01:19 GMT",CIO,"I love technology. During the last year, I’ve been fascinated to see new developments emerge in generative AI large language models (LLMs). Beyond the hype, generative AI is truly a watershed moment for technology and its role in our world. Generative AI LLMs are revolutionizing what’s possible for individuals and enterprises around the world.

However, as enterprises race to embrace LLMs, there is a dark side to the technology. For enterprises to fully unleash the potential of generative AI and large language models, we need to be frank about its risks and the rapidly escalating effects of those risks. That way enterprises can select the proper approach, deployment, and use cases to mitigate LLMs’ risks before they cause harm—albeit unintentionally—to individuals, organizations, and beyond.

While general-purpose LLMs, like ChatGPT, Google Bard, and Microsoft Bing, are increasingly used by organizations, the stakes skyrocket. Potential negative consequences include the threats of influencing political outcomes, enabling wrongful convictions, generating deepfakes, and amplifying discriminatory hiring practices. That’s serious.

SUBSCRIBE TO OUR NEWSLETTER From our editors straight to your inbox Get started by entering your email address below. Please enter a valid email address Subscribe

The root cause lies in three hard truths about generative AI LLMs: Bias, discrimination, and fact or fiction.

Bias

By their very nature, generative AI LLMs are inherently biased. That’s because LLM algorithms are trained on massive text-based datasets, such as millions or billions of words from the Internet and other published sources. Data volumes of this magnitude cannot be checked for accuracy or objectivity by the LLM architects. And because the data is largely based on the Internet, it contains human bias, which then becomes part of the LLM algorithms and output.

But baked-in generative AI LLM bias can be worse than human bias.

For example, a recent study showed that OpenAI’s ChatGPT has a notable left-wing bias. Researchers shared findings of a “significant and systematic political bias toward the Democrats in the U.S., Lula in Brazil, and the Labour Party in the U.K.,” (Lula is Brazil’s leftist president, Luiz Inácio Lula da Silva).

This raises the potential impact of LLM bias to new levels. As political parties increasingly use LLMs to generate fundraising, create campaign emails, and write ad copy, this inherent bias can sway political outcomes, elevating its impact to a national and global level.

Discrimination

The use of generative AI LLMs has been piloted in talent acquisition applications. Gaps in data and existing human-based social stereotyping can be encoded in the data used to train the models and create risks. In talent acquisition, generative AI LLM can erode—and even reverse—the positive progress made in the areas of diversity, equity, and inclusion.

For example, a few years back, Amazon’s automated hiring tool was discarded upon discovering that it discriminated against female candidates. In another example, Meta’s LLM system had to be shut down by the company three days after launch because it generated biased and false information. Another LLM that generates images based on AI says CEOs are white males, doctors and lawyers are not female, and dark-skinned males commit crimes.

Left unchecked, LLM outcomes like these can have grave consequences. In talent acquisition, biased LLM outcomes could negatively and unfairly impact hiring decisions, altering an organization’s workforce, and hampering business outcomes. Even more, the negative ethical and social effects of biased data and discrimination based on race or gender can quickly outpace the organizational impacts.

Fact or fiction

Large language models identify patterns from text-based data to generate output. However, LLMs cannot create higher-order reasoning from their data or pattern recognition. That means LLMs—while valuable in distinct use cases—have a deceptive intelligence because their knowledge is limited to pattern recognition. In other words, generative AI LLMs cannot distinguish between fact or fiction. This hard truth can lead to deepfakes.

Deepfakes can use text-to-image generative AI technology to intentionally create false content—such as fake audio or video content. This disinformation can be used to mislead communities with fake emergencies, misrepresent politicians to influence elections, and introduce bias that causes unfair treatment. For example, AI text-to-image LLMs can generate suspected criminal sketches where inherent biases could result in erroneous convictions.

Solution: Purpose-built models

Good things, such as generative AI LLMs, often come with some downsides. In the case of generative AI LLMs, the potential downsides are serious and far-reaching. For enterprises, the solution lies in purpose-built generative AI LLM models, including build-from-scratch approaches or ones that use proprietary enterprise data.

Purpose-built models are tailored to specific organizational needs and distinct use cases. They differ from general-purpose LLMs in that they are trained and tuned to solve specific challenges, such as financial forecasting or customer support, and modeled with smaller data sets.

In short, purpose-built models provide agility, security, and performance and aim to accelerate the responsible enterprise deployment of generative AI. That helps enterprises realize the revolutionary potential offered by generative AI LLMs so they can capitalize on technology’s defining moment.

Read more about purpose-built generative AI LLMs

Bringing AI Everywhere – Intel

Responsibly Harnessing the Power of AI

Unlocking the Potential of GenAI"
Observe Inc. Brings Generative AI to Observability - DevOps.com,https://devops.com/observe-inc-brings-generative-ai-to-observability/,"Thu, 05 Oct 2023 14:45:28 GMT",DevOps.com,"Observe, Inc. today revamped the Hubble user interface to its observability platform that has been infused with generative artificial intelligence (AI).

Fresh from raising an additional $50 million in funding, Observe CEO Jeremy Burton said as the company’s software-as-a-service (SaaS) platform continues to be infused with AI using multiple large language models (LLMs), it’s becoming apparent that observability is rapidly becoming democratized.

Most IT organizations still rely primarily on legacy monitoring tools to track a set of predefined metrics. Observability platforms have arisen to aggregate metrics, logs and traces to enable DevOps teams to launch queries and surface the root cause of performance issues or IT incidents. The challenge is that most observability platforms have required IT teams to master a proprietary query language such as Observe’s RegEx.

However, with the rise of generative AI tools, it is now possible for IT professionals of all skill levels to employ a natural language chatbot to generate a RedEx query, noted Burton. A RegEx generation tool also parses data to add structure to logs on-the-fly, and there is also an OPAL Co-Pilot that generates OPAL code in response to natural language inputs.

The Hubble interface furthers those capabilities by simplifying the onboarding experience anytime there is a new member added to an IT team, he added. Hubble also expands the range of data access options available, including a public application programming interface (API), a command line interface (CLI), export to CSV and data sharing to the Snowflake cloud platform.

IT teams are also coping with an explosion of telemetry data generated by modern distributed applications based on microservices architectures. Legacy observability and monitoring tools were not designed for these data volumes, so when there is an incident, the mean-time-to-resolution (MTTR) is increasingly extended. In contrast, the Observe platform now features a ‘Live’ mode that enables data to be queried in 20 seconds or less from when it was created.

Other capabilities include an assistant embedded in Slack to help users troubleshoot issues and summarize threads for incident response.

While it’s still early days as far as the adoption of observability platforms are concerned, there is already no shortage of options. The pending acquisition of Splunk by Cisco next year will cause more organizations to reevaluate their IT management options, so the pace at which organizations are transitioning to cloud-hosted observability platforms should increase, noted Burton. Even after the merger is completed, it might be several more months before Cisco integrates its AppDynamics platform with the observability platforms that Splunk added to its IT operational analytics platform, he added.

In the meantime, IT environments are only going to become more complex. It won’t be feasible for most IT teams to manage highly distributed computing environments without some help from AI. The challenge, as always, will be finding the budget dollars needed to deploy an observability platform before the number of increased IT incidents makes the need for one painfully obvious."
"Zendesk extends its generative AI offering, balanced by new data privacy measures - diginomica",https://diginomica.com/zendesk-extends-generative-ai-offering-new-data-privacy,"Wed, 04 Oct 2023 23:33:33 GMT",diginomica,"Tom Eggemeier, Zendesk (Showcase NY screengrab)

At a special event in New York today, CX vendor Zendesk announced further enhancements to its generative AI offerings, most notably a voice transcription and summary capability, along with new data privacy measures to allow greater control over customer data management. Introducing the event, Tom Eggemeier, CEO of Zendesk, commented:

AI is reshaping how we all think about customer experience, and quite frankly, employee experience as well. AI is already having an enormous impact on how we all do business. And some of the biggest changes are going to come fortunately, or unfortunately, to the customer service space.

He cited the example of longstanding Zendesk customer, the upmarket London department store Liberty, which adopted Zendesk AI shortly after it was first introduced in May. He outlined the results at Liberty:

They've seen their customer satisfaction up by over nine percentage points already. Their first reply time is down by 73%. The time it takes to resolve the average ticket is down by 11%. They are providing quicker, more personalized service and their customers are noticing this. The customers don't know it's because of AI. They just know they're getting better service, which is connecting them with the Liberty London brand even more.

Extending Zendesk AI

The new generative AI capabilities announced today build on and extend the Zendesk AI package unveiled in May at the company's annual Relate conference. Today's announcements include:

Expanded intent detection founded on Zendesk's CX-specific large language models to serve additional industries including insurance and travel & tourism, or to match internal IT and HR use cases. These models can be further adapted by taking common intents that an individual company encounters from its customers or employees, and editing them for their specific needs. For example a travel agency might want to detect frequently asked questions by travellers and escalate them to agents who are specially equipped to handle these issues.

New tools to help agents, administrators and managers optimize and customize their CX processes. For example, Zendesk AI can identify gaps in the existing question and answer flows based on common topics customers are asking about and suggest new flows to plug these gaps. Or admins can adjust the tone of a bot's responses to be more casual or professional to match the brand persona.

The ability to summarize key information from multiple help centre articles, and automatically provide a more accurate and relevant answer. Bringing this information together in a more digestible format will enable agents and bots to respond to customers in a more consistent and natural conversation flow.

The launch of AI for Voice brings the ability to not only provide an immediate transcript and summary of the conversation, but also identify how the customer felt about the call. This promises to save time spent manually recording conversation details and allow agents to focus on ensuring the customer’s issue has been properly addressed.

Data privacy

For customers concerned about data privacy, Zendesk has announced an Advanced Data Privacy and Protection offering, which allows businesses to have greater control and flexibility over how they manage their customer data. Amang the new capabilities this brings, CX leaders can:

Safeguard their business with stronger encryption, including private keys and admin control of key rotation and revocation.

Elevate privacy by specifying what data is shown and kept, for example redacting email and shipping addresses, or setting custom rules for how the long the data can be retained and when it should be deleted.

Strengthen security at scale with greater visibility by logging who accessed and searched for data.

My take

When we spoke to Zendesk at the time of the May announcements, Cristina Fonseca, Head of AI at Zendesk, emphasized the company's ability to leverage its deep experience in CX to tune its generative AI models, contrasting it with the more generic approach of its partner, ChatGPT creator OpenAI. She told us:

OpenAI doesn't have the proprietary data that we have, the CX data that we have ... If you want to build intent detection and sentiment detection on top of OpenAI, that gives you a good advantage. But we go even one level further.

Today's announcements of industry-specific and function-specific intent detection build on those proprietary models and also offer customers the option to further fine-tune the response flows provided. This is where Zendesk has a real strength in the market, but it also needs to recognize the reservations enterprises have about the reliability and trustworthiness of generative AI models. Therefore the enhanced data privacy measures are welcome, but perhaps don't yet go as far as we've seen from other vendors with more extensive AI investments.

There's an important balance that vendors have to strike between on the one hand supporting customers in realizing the productivity and competitive advantages of generative AI, while on the other hand ensuring that trust and data privacy is fully respected. The speed at which generative AI has evolved is putting unprecedented demands on vendors to deliver new functionality while constrained by considerations of data privacy, accuracy and appropriate use. Getting this balance right will test the mettle of every vendor."
SnapLogic expands ‘SnapGPT’ generative AI capabilities with ... - iTWire,https://itwire.com/guest-articles/company-news/snaplogic-expands-%E2%80%98snapgpt%E2%80%99-generative-ai-capabilities-with-amazon-bedrock.html,"Wed, 04 Oct 2023 23:35:24 GMT",iTWire,"SnapLogic, a leader in generative integration, has announced it is working with Amazon Web Services (AWS) to expand the capabilities of SnapGPT, SnapLogic’s generative integration interface. As part of this collaboration, SnapLogic will make Anthropic’s cutting-edge Large Language Model (LLM), Claude 2, offered by Amazon Bedrock, available within the SnapGPT platform that was made generally available earlier this year. Amazon Bedrock is a fully managed service that provides access to industry-leading foundation models via an API to build and scale generative artificial intelligence (AI) applications.

SnapLogic introduced SnapGPT, an innovative generative integration solution, powered by proprietary and open-source AI, this spring. With hundreds of customers already experiencing its game-changing potential, SnapGPT has set a new standard for integration and automation, streamlining complex processes and powering businesses into a data-driven future. By using natural language prompts, customers are using SnapGPT to accelerate the creation of new pipelines, instantly document new and old pipelines, create sample data, and generate SQL queries, expressions, mappings, and more.

“SnapGPT has made an immediate and incredibly beneficial impact on our developer team,” said David Patterson, Head of Solutions and Delivery at Hampshire Trust Bank. “By leveraging the natural language prompts with SnapGPT, we have been able to automate up to 80% of common integration tasks, freeing up our skilled developers to focus on building more innovative services for our customers. We’re eager to explore the possibilities of this promising technology.”

SnapGPT will empower users to use Anthropic’s state-of-the-art LLM Claude 2 to build new integrations, define existing pipelines, create new expressions, and more using natural language prompts. SnapGPT users now have access to Claude 2’s advanced natural language processing and generation abilities that can accept prompts containing up to 75,000 words or 100,000 tokens. SnapGPT leverages the larger prompt size of Claude 2 to offer a more powerful integration co-pilot that enhances performance across a wider range of applications. SnapGPT’s ease of use will allow businesses to roll out citizen integration to clear the backlog and drive business agility.

Key benefits of SnapLogic using Amazon Bedrock include:

Integration Pipeline Generation: SnapLogic customers can generate integration pipelines directly from natural language instructions, making integration faster and more accessible for all users

Complex Data Mapping: Our platform can effortlessly create complex data mapping configurations using natural language inputs, eliminating the need for intricate data transformation coding

SQL Generation: SnapGPT can generate SQL queries from natural language queries, making it easier for users to interact with their data

Complex Pipeline Description: Users can describe intricate data pipelines in plain language, enhancing collaboration and understanding among teams

Sophisticated Chat-based Q&A: SnapLogic's documentation now offers a chat-based Q&A feature, allowing users to find answers to their integration questions more easily and intuitively

""SnapLogic is committed to providing our customers with the most advanced language models available, and our work with Amazon Bedrock and the integration of Anthropic’s model Claude 2 into SnapGPT is a testament to that commitment,"" said Jeremiah Stone, CTO of SnapLogic. ""This collaboration will empower our users to harness the full potential of natural language processing in their applications, making generative integration and automation even more accessible and powerful.""

""We are excited to work with SnapLogic to bring the power of Amazon Bedrock to SnapGPT users,"" said Rich Geraffo, vice president of North America at AWS. ""This collaboration will enable organizations to leverage the capabilities of Amazon Bedrock and AWS’s generative AI expertise to drive innovation and enhance their data processing workflows.""

SnapLogic's integration with Anthropic’s model Claude 2 will be available to SnapGPT users immediately, with comprehensive documentation and support to ensure a seamless transition. Customers can sign up for a free trial of SnapGPT at https://www.snaplogic.com/products/snapgpt.

About SnapLogic

SnapLogic is the leader in Generative Integration. As a pioneer in AI-led integration, the SnapLogic Platform accelerates digital transformation across the enterprise and empowers everyone to integrate faster and easier.

Whether you are automating business processes, democratizing data, or delivering digital products and services, SnapLogic enables you to simplify your technology stack and take your enterprise further. Thousands of enterprises around the globe rely on SnapLogic to integrate, automate and orchestrate the flow of data across their business."
History in the Making: 1 Remarkable Artificial Intelligence (AI ... - The Motley Fool,https://www.fool.com/investing/2023/10/05/history-in-the-making-1-ai-growth-stock-to-buy-now/,"Thu, 05 Oct 2023 09:25:00 GMT",The Motley Fool,"Last November, OpenAI launched ChatGPT. Within two months, the generative artificial intelligence (AI) platform reached 100 million monthly users, making it the fastest-growing application in history at the time. That steep adoption curve hints at the profound impact generative AI could have on the world. By democratizing automation with a natural language interface, generative AI promises to improve business productivity in ways that are unlike any other technology in history.

It's estimated that the total economic impact of this new technology could exceed $4 trillion in a few short years, according to research from Morgan Stanley. Analysts from the investment bank say generative AI will create a $30 billion revenue opportunity just in cybersecurity. If it does, CrowdStrike (CRWD -0.14%) is one of four companies best positioned to benefit.

Here's what investors should know.

CrowdStrike is a leader in multiple cybersecurity markets

CrowdStrike has a tremendous capacity for innovation that has kept it on the cutting edge of cybersecurity since it was founded in 2011. When other vendors were using reactive indicators of compromise to detect threats, CrowdStrike invented a new technique based on proactive indicators of attack. When other vendors were selling on-premises point solutions, CrowdStrike built a cloud-based platform that consolidated multiple products behind a single interface.

CrowdStrike was also one of the first companies to bring artificial intelligence to cybersecurity, and because its platform was designed to crowdsource data more effectively than other solutions on the market -- a quality from whence comes the name CrowdStrike -- management believes the company's AI models are uniquely effective in detecting attacks. Industry analysts echoed that sentiment.

As mentioned, Morgan Stanley sees CrowdStrike as one of the cybersecurity companies best positioned to benefit from generative AI, a prediction attributed to its unique datasets. Similarly, consultancy Frost & Sullivan offered the following insight in a recent report, ""CrowdStrike leads the industry with regards to the application of artificial intelligence/machine learning to endpoint security."" The report goes on to say that CrowdStrike offers unparalleled protection from malware and malware-free attacks.

Here's the upshot: Most enterprises are still buying north of 60 cybersecurity point products, and that creates a meaningful opportunity for CrowdStrike. Its platform reduces IT complexity by consolidating 27 different software modules behind a single interface. Those modules span multiple cybersecurity markets, and CrowdStrike is a recognized leader in many of them, including endpoint security, cloud security, and threat intelligence.

CrowdStrike is chasing a massive market opportunity

CrowdStrike looked sharp in the first half of fiscal 2024 (ended July 31). Revenue increased 39% to $1.4 billion, gross profit margin reached a record high of 78%, and free cash flow climbed 42% to $416 million. Those strong results reflect momentum with new and existing customers, and management sees that momentum increasing in the second half of the year.

Yet, CrowdStrike has just 23,000 customers, a very small number compared to the vendors listed below. It's worth mentioning that these are the other three cybersecurity companies that Morgan Stanley sees as key beneficiaries of the generative AI boom:

Palo Alto Networks : 80,000 customers

: 80,000 customers Fortinet : 680,000 customers

: 680,000 customers Microsoft: 1 million customers

The customer counts detailed above show in no uncertain terms that CrowdStrike has hardly scratched the surface of its total addressable market (TAM). Indeed, the company values its TAM at $100 billion in 2024, but management says its product development pipeline (coupled with growing demand for cybersecurity software) could push that figure to $225 billion by 2028.

One product of note is Charlotte AI, a generative AI security assistant that can be prompted in natural language to automate and accelerate tasks like data collection, risk assessment, threat detection, and incident response. CrowdStrike says Charlotte AI represents an incremental opportunity of $7 billion by 2028.

Another product of note is Falcon for IT, a solution (powered by Charlotte AI) that extends the platform beyond cybersecurity to streamline reporting, monitoring, and remediation across IT workflows. CrowdStrike says Falcon for IT represents an incremental opportunity of $8 billion by 2028.

CrowdStrike stock trades at a substantial discount

The average cost of a data breach to a company reached $4.45 million in 2023, up 15% from 2018, according to IBM. And damages inflicted by cybercriminals are projected to total $10.5 trillion annually by 2025, up 75% from 2021, according to Cybersecurity Ventures. Put simply, cyberattacks are becoming an increasingly costly problem, which means cybersecurity software is more important than ever.

CrowdStrike is well positioned to benefit from that tailwind given its leadership position in several cybersecurity markets and its knack for product innovation. Yet, shares currently trade at 14.6 times sales, a bargain compared to the three-year average of 32 time sales. That's why this growth stock is worth buying today."
"Google to Bring Bard Generative AI to Google Home, Assistant - CE Pro",https://www.cepro.com/control/whole-house-systems/google-event-bard-generative-ai-add-to-google-home-assistant/,"Thu, 05 Oct 2023 14:14:40 GMT",CE Pro,"Google’s Made by Google event this week was primarily all about the company’s new Pixel and Pixel 8 Pro phones, which include several upgrades, including new camera capabilities and AI upgrades. However, the company also made an under-the-radar announcement about bringing Bard’s generative AI to Google Home and Assistant.

The company is planning to bring some new AI capabilities to Google Home next year to make smart homes more intuitive and helpful, says Rick Osterloh, senior vice president of devices and services at Google, who spoke at the event.

Using generative AI capabilities, users will be able to see a streamlined view of recent activity, with a quick and easy summary, Osterloh says.

For example, users wondering about packages being delivered can ask about their home in their natural language and quickly find the clip they’re looking for from their Nest doorbell video history. Users can take action on these insights by typing a follow-up query, and the Home app will generate a list of suggested automations.

However, Osterloh calls these features “experimental” and for subscribers only, suggesting that these advanced AI capabilities won’t be free. They will be rolling out next year.

The Future of Digital Lighting & Control As a custom integrator, lighting is in demand. Effective communication, education and showcasing the value proposition of LED light fixtures in conjunction with integrative control systems are the keys to overcoming challenges and closing sales in this specialized market. Join us as we discuss the future of digital lighting and control with David Warfel from Light Can Help You and Patrick Laidlaw and Mark Moody from AiSPIRE. As a custom integrator, lighting is in demand. Effective communication, education and showcasing the value proposition of LED light fixtures in conjunction with integrative control systems are the keys to overcoming challenges and closing sales in this specialized market. Join us as we discuss the future of digital lighting and control with David Warfel from Light Can Help You and Patrick Laidlaw and Mark Moody from AiSPIRE. Register Now!

Google Infuses Assistant with Bard Generative AI

Although not specifically related to Google’s smart home ecosystem, the company also said it is bringing its generative AI tool Bard to Assistant, essentially infusing advanced AI into its intelligent assistant that is often the center of smart homes using Google controls.

According to Google, this combines Bard’s generative and reasoning capabilities with Assistant’s personalized help.

“You can interact with it through text, voice or images — and it can even help take actions for you,” writes Sissi Hsiao, vice president and general manager, of Google Assistant and Bard, in a blog.

Assistant with Bard is being billed as a “more personalized helper” that will be integrated with popular Google services like Gmail and Docs. However, the company did not specifically mention how this will integrate with Google Home.

That may be because Assistant with Bard is “still an early experiment,” Hsiao writes. It will be rolling out to testers first to get their feedback before general availability.

These announcements come shortly after Amazon announced big upgrades to its own AI, Alexa, including a new large language model (LLM) designed to make controlling smart home systems easier, more intuitive and more conversational. The recent CEDIA Expo 2023 also saw announcements from professional smart home manufacturer Savant saying they have incorporated Siri’s natural language processing capabilities into its own ecosystem."
William Ammerman: Unveiling the power and influence of ... - Chatham Journal Weekly,https://chathamjournal.com/2023/10/04/william-ammerman-unveiling-the-power-and-influence-of-generative-ai/,"Thu, 05 Oct 2023 02:59:38 GMT",Chatham Journal Weekly,
"Salesforce Dreamforce 2023: Generative AI, Data Cloud and ... - Coresight Research",https://coresight.com/featured/salesforce-dreamforce-2023-generative-ai-data-cloud-and-commerce-cloud/,"Thu, 05 Oct 2023 07:45:32 GMT",Coresight Research,"This report is for subscribers only. Learn more about subscriptions here.

If you are a subscriber, please log in.

This document was generated for"
Microsoft Envision | The Tour: How to lead in the era of AI - The ... - Microsoft,https://blogs.microsoft.com/blog/2023/10/04/microsoft-envision-the-tour-how-to-lead-in-the-era-of-ai/,"Wed, 04 Oct 2023 17:27:41 GMT",Microsoft,"I recently highlighted how generative AI technology is opening doors for organizations to imagine new ways to solve challenges, while unlocking innovation and delivering greater business value for those who adopt it. Organizations with modern data estates fortified with the Microsoft Cloud are already accelerating their AI transformation; and as many business leaders seek to keep pace they are turning to Microsoft and our partner ecosystem for industry expertise, scale and copilot capabilities.

Microsoft has built a foundation of successfully delivering AI solutions for many years. Now, we are infusing generative AI capabilities across the services customers know and love, while remaining committed to helping them apply it responsibly and securely. With so many compelling AI opportunities to discover, it is important leaders across industries understand how to successfully use this groundbreaking technology to meet their business imperatives.

At our kickoff experience in New York City last month, we highlighted Microsoft’s copilot technology and learned from customers about the business results and productivity gains they are realizing today. I am pleased to announce additional dates for Microsoft Envision | The Tour — an in-person experience bringing together senior decision makers and industry experts in AI. Attendees will leave feeling equipped with the latest information to begin — or build upon — their AI transformation.

Please join us on Oct. 18 as we continue the tour in London, where Satya Nadella will discuss the opportunity for organizations around the world to transform every aspect of their business with AI. To register and learn more about upcoming dates across Mumbai, Sydney, Mexico City, Paris and Tokyo, visit: Microsoft Envision | The Tour.

I look forward to connecting with you as we begin one of the most exciting and pivotal years for technology in our lifetimes.

Tags: AI, Microsoft Cloud, Microsoft Envision"
"Mango launches 'Lisa', a conversational generative AI platform - Fashion Network US","https://ww.fashionnetwork.com/news/Mango-launches-lisa-a-conversational-generative-ai-platform,1563540.html","Wed, 04 Oct 2023 23:37:48 GMT",Fashion Network US,"Mango launches 'Lisa', a conversational generative AI platform By



Rocío ALONSO LOPEZ Translated by

Roberta HERRERA Published

Oct 5, 2023

, the Barcelona-based fashion company, has been steadily advancing its digitalization efforts. The firm has already incorporated over 15 artificial intelligence platforms across its entire value chain. Among these is 'Inspire', which focuses on generating images, particularly for the design department. The latest addition to this digital transformation journey is 'Lisa', a cutting-edge generative AI tool for content creation and conversation.







The 'Lisa' platform aims to assist employees and partners - Mango



The primary objective of Lisa is to streamline processes, spanning from the development of fashion collections to post-sales service. Its conversational interface, reminiscent of Chat GPT, leverages a variety of models, including private ones tailored specifically for Mango, as well as open-source models.



""Generative artificial intelligence is an extended form of intelligence—a technology that acts as a co-pilot, enhancing the capabilities of our employees and stakeholders. It ensures technology makes us more humane in our interactions or it's not worth pursuing,"" said Jordi Álex, Mango's director of technology, data, privacy, and security.

Lisa's integration into Mango's digitalization strategy aligns with the company's history of introducing machine learning platforms (MLE) since 2018. In addition to the aforementioned 'Inspire', the group has launched initiatives such as Gaudí, aimed at product recommendations for customers, and Iris, operating in 60 countries and available in over 20 languages, primarily focused on improving customer service.



Founded by in 1984, Mango marked an impressive 20.3% increase in revenue during its 2022 fiscal year, achieving a total of €2.688 billion. By the fiscal year's end, Mango had established a robust international presence, with operations in 115 markets through an extensive network of owned stores, franchises, collaborations with major retailers, and a thriving online channel, which currently accounts for 36% of its total revenue."
Databricks improves support for generative AI models - TechTarget,https://www.techtarget.com/searchdatamanagement/news/366554414/Databricks-improves-support-for-generative-AI-models,"Wed, 04 Oct 2023 20:10:38 GMT",TechTarget,"Databricks unveiled new large language model and GPU optimization capabilities in Model Serving in a move designed to enable customers to improve generative AI outcomes.

Databricks launched Model Serving in March. Model Serving is a service that enables Databricks customers to deploy AI and machine learning (ML) models as REST APIs to a single environment for model management, at which point Databricks takes over the management, including refreshing the model with updated data and fixing any bugs.

Before Model Serving, users often had to manage complex AI and ML infrastructures that required them to use batch files to move data into a cache in a data warehouse. There, users could train a model before moving it to another application where the model could ultimately be consumed for analysis. Refreshing models with updated data and tweaking models to fix problems also required copious amounts of work.

REST APIs, however, let users train and deploy models directly on the Databricks Lakehouse Platform, eliminating the need to manage complex infrastructures made up of multiple tools.

In addition, the Model Serving environment comes with pre-built integrations with Databricks tools -- including MLflow Model Registry for deployment, Unity Catalog for governance and vector search for accuracy -- that help customers manage their AI and ML models.

On Sept. 28, Model Serving was updated to include Optimized LLM Serving, a tool that enables users to deploy privately developed generative AI models on the service as well as traditional AI and machine learning models. In addition, new GPU optimization capabilities in Model Serving aim to provide the requisite power for running and managing large generative AI models.

Both are in public preview.

New capabilities The initial promise of generative AI is increased efficiency. Natural language processing (NLP) capabilities that enable users to interact with data without having to write code can help data experts work more quickly. NLP can also enable more business users to work with data by lowering barriers to entry, such as the need to know code and data literacy expertise. It can also allow for increased automation of repetitive processes and certain customer interactions. Integrating with public large language models (LLMs) such as ChatGPT and Google Bard to train generative AI models, however, can be risky for organizations that want to keep their data private. When organizations push data out into those models to build and train generative AI models, they risk their data getting exposed. Even when they import public LLM data into their own environment rather than push data out to the LLM, they risk data leaks by connecting to the public LLM. There are security measures organizations can take to attempt to ensure they can safely import LLM technology without exposing their own data, but those attempts are not foolproof. In addition, generative AI models trained on public data don't always deliver accurate results. LLMs are trained to fill in gaps -- essentially, to make things up -- when they don't have the data to answer a question. Sometimes those made-up answers, called AI hallucinations, seem plausible. And that can lead to serious consequences for organizations basing key decisions on model outcomes. As a result, many organizations are now developing their own language models by using technology from generative AI vendors, but training the models using their own domain-specific data. Databricks is simplifying matters for customers seeking to develop and deploy generative AI capabilities by eliminating the complexities of infrastructure selection and deployment and model optimization. Doug HenschenAnalyst, Constellation Research Optimized LLM Serving aims to help Databricks customers easily deploy those privately trained generative AI models as well as optimize their performance. According to Databricks, users simply have to provide the model and the open source or other structure used in its development, and Optimized LLM Serving will take over its management from there. The intended results include saving customers the time it takes to improve a model's performance and reducing the cost of managing a generative AI model by eliminating manual workloads. Saving time and effort is significant because it enables customers to target end results, according to Doug Henschen, an analyst at Constellation Research. ""Databricks is simplifying matters for customers seeking to develop and deploy generative AI capabilities by eliminating the complexities of infrastructure selection and deployment and model optimization,"" he said. ""This helps customers focus on the business use case instead of decisions around underlying technology."" Databricks' management of generative AI models, meanwhile, is enabled by GPU optimization. Initially designed to process images and visual data, GPUs can also be used to speed up computational processes that are too much for traditional CPUs. In the case of Model Serving, GPUs provide the compute power for managing generative AI models as a service, according to Prem Prakash, Databricks' principal product marketing manager of AI and machine learning. Customers simply have to log their model with MLflow, at which point Databricks will take over the model's management. The vendor's platform will automatically prepare a container with GPU libraries and then deploy that container to serverless GPUs where the model will be managed. ""LLMs are much more complex and compute-intensive than a document with words on it,"" Prakash said. ""Trying to run it on a CPU could break [the CPU]. That's where GPUs come in."" Databricks' impetus for adding LLM hosting capabilities to Model Serving, meanwhile, was partially driven by customers looking to ease not only the burdens, but also the expenses of managing language models, Prakash continued. He noted that by optimizing GPUs and automating management of LLMs, Databricks is able to provide management as a service at a lower cost than what organizations would otherwise pay to manage models on their own. ""Once they build [the models] in their own environment, they don't want to do all the work of managing GPUs,"" Prakash said. ""These models are so big that they can be expensive to manage, so they asked if there was something we could do to make [management] more cost-effective."" Databricks is far from the only data management vendor to prioritize generative AI over the past year. For example, rival Snowflake is building an environment for developers to build generative AI applications and in May acquired Neeva to add generative AI capabilities. But because Databricks was one of the pioneers of the lakehouse architecture that could be most optimal for generative AI model development and has added other features aimed at helping users build and deploy generative AI models, the vendor has been able to quickly develop tools such as Model Serving and now its enhancements. As a result, its generative AI enablement capabilities are among the most advanced to date, according to Henschen. ""Databricks was in a better position than many of its competitors to help customers take advantage of generative AI,"" he said. ""It has seized the moment by quickly adding capabilities to help customers use their data to tweak and tune LLMs and bring generative capabilities into production."""
NextGen Food Robotics Corp. Announces Completion of Beta ... - Marketscreener.com,https://www.marketscreener.com/quote/stock/NEXTGEN-FOOD-ROBOTICS-COR-134953167/news/NextGen-Food-Robotics-Corp-Announces-Completion-of-Beta-Version-of-Generative-AI-Powered-Food-Deliv-44989971/,"Thu, 05 Oct 2023 07:30:00 GMT",Marketscreener.com,"NextGen Food Robotics Corp. announced the completion of the beta version of its generative AI-powered food delivery and chatbot application, ?Lily,?. Nextgen is now actively submitting its application to the IOS app store and strives to have ?lily on the app store by year end.

This milestone represents a significant step forward in the development of the innovative application, which aims to transform the food ordering and delivery experience through advanced generative artificial intelligence powered by OpenAI?s GPT-4.0 large language model (?LLM?) Key features of Lily include intelligent food recommendations, conversational ordering, customization based on dietary preferences, seamless integration with food delivery platforms, and real-time order tracking. NextGen Food Robotics Corp. intends to process the initial iOS application of Lily on the Apple App Store in the coming weeks, marking the initial step towards wider accessibility and enable commercial use of the app.

The company is committed to ensuring a user-friendly experience for iOS users and looks forward to expanding its user base."
Google unveils Pixel 8 built for ‘the generative AI era’ - CNN,https://edition.cnn.com/2023/10/04/tech/pixel-8-google-ai/index.html,"Wed, 04 Oct 2023 20:52:00 GMT",CNN,
Generative AI Has Ushered In the Next Phase of Digital Spirituality - WIRED,https://www.wired.com/story/artificial-intelligence-spirituality-tarot/,"Thu, 05 Oct 2023 13:00:00 GMT",WIRED,
SugarCRM Unveils Generative AI for Midmarket CRM ... - Business Wire,https://www.businesswire.com/news/home/20231005462331/en/SugarCRM-Unveils-Generative-AI-for-Midmarket-CRM-Supercharging-Sales-Marketing-and-Customer-Service,"Thu, 05 Oct 2023 12:30:00 GMT",Business Wire,"LONDON--(BUSINESS WIRE)--SugarCRM, provider of the award-winning AI-driven CRM platform, today announced it is harnessing the power of generative AI to bring newfound out-of-the-box value and productivity gains to its thousands of midmarket customers worldwide, advancing the customer relationship management platform for sales representatives, marketers and customer service professionals.

Sugar executives showcased the new capabilities today at the company’s 2023 Industry Analyst Summit.

Sugar has been at the forefront of harnessing AI, machine learning, and predictive analytics to automate anything, accelerate everything, and anticipate what’s next. And now, it is incorporating generative AI into its platform that does the work to make the hard things easier for employees tasked with delivering exceptional experiences for customers and prospects.

Generative AI can act as a digital assistant, freeing up time and resources, enabling employees to focus on higher-value activities. According to a recent report by McKinsey Digital, about 52 percent of the value that generative AI could deliver applies to customer operations, marketing, and sales. The researchers indicate that generative AI has the potential to revolutionize the way organizations use and interact with their CRM by automating work activities that absorb 60 to 70 percent of employees’ time today.

SugarCRM’s new AI advancements are designed to help sales, marketing and service teams work faster and smarter in the following ways:

Generative AI for Sales dramatically enhances sales productivity and effectiveness by composing personalized and compelling emails and sales copy, data-driven and persuasive ready-made call scripts, and sales proposals infused with real-time customer intelligence.

Generative AI for Marketing takes marketing automation and personalization to the next level, maximizing impact through creation of ultra-relevant, personalized marketing campaigns, landing pages and emails, automatic translation, and smarter segmentation.

Generative AI for Customer Service accelerates knowledge and value exchange by summarizing case history and service tickets, creates personalized user guides and product documentation, and enables agents and customers to quickly find answers and resolve issues.

Sugar’s embedded generative AI capabilities give organizations confidence to leverage the transformative effects of the technology while ensuring responsible usage, providing administrators with tools that audit, control, and filter the flow of data that gets passed to large language models. This offers best-practice business data and intellectual property protection.

“Most businesses are looking to AI to transform experiences and drive greater productivity. Today’s generative AI announcement is the latest evidence of our commitment to make AI accessible to all and to maximize usability for a next-level CRM user experience,” said SugarCRM CEO Craig Charlton.

“The generative AI revolution is here, and midmarket sales, marketers and customer service pros can’t afford to be left out of the equation,” he said. “With Sugar, organizations can unleash the potential of generative AI to automate, accelerate and optimize marketing, sales and customer service.”

Sugar’s new generative AI capabilities are currently available to customers participating in a closed pilot program.

About SugarCRM

SugarCRM is a CRM software that helps marketing, sales, and service teams reach peak efficiency through better automation, data, and intelligence so they can achieve a real-time, reliable view of each customer. Sugar’s platform provides leading technology in the sales automation, marketing automation, and customer service fields with one goal in mind: to make the hard things easier.

Thousands of companies in over 120 countries rely on Sugar by letting the platform do the work. Headquartered in the San Francisco Bay Area, Sugar is backed by Accel-KKR.

For more information about SugarCRM, visit: www.sugarcrm.com."
"YouTube Expands Access to Content Monetization, Adds New ... - Social Media Today",https://www.socialmediatoday.com/news/youtube-expands-access-content-monetization-adds-new-generative-ai-effects-shorts/695680/,"Thu, 05 Oct 2023 02:03:24 GMT",Social Media Today,"YouTube is expanding access to its Partner Program, enabling more people in more regions to qualify for monetization of their YouTube clips, while it’s also rolling out a new generative AI feature for Shorts that’ll make you look like a statue that’s been under the sea for 500 years.

It’ll make more sense when I explain it.

First off, YouTube recently reduced the entry thresholds for its YPP program, enabling creators with 500 subscribers (down from 1,000), and far fewer video or Shorts views to monetize their content with YouTube ads.

Initially, the lower entry thresholds were only available to creators in selected regions, but now, creators in 23 more countries will have the opportunity to monetize, at lower entry rates.

That’ll help YouTube boost its appeal to creators in many more markets. And with every other app now also trying to sweeten the deal for creative talent, that could give YouTube a key leg up on the competition.

On another front, YouTube’s now rolling out its first generative AI feature for YouTube Shorts, with an interesting effect called “Bloom” which “turns people into a vibrant topiary structure”.

So a plant, it turns you into a plant, so you end up looking like the remnants of the people left behind in Area X in “Annihilation”.

It’s a bit weird, but also kind of cool, and it’ll likely draw some interest among YouTube creators and users alike.

Which is the real aim. YouTube will be hoping that this is the type of thing that people share with their friends, which then gets more people checking out Shorts, and sharing their own content. YouTube’s also working on a range of other generative AI options, which may include more strange transformation effects in future.

You can learn more about YouTube’s latest updates here."
Meet Appy Pie: The no-code development platform powered by AI - VentureBeat,https://venturebeat.com/business/meet-appy-pie-the-no-code-development-platform-powered-by-ai/,"Wed, 04 Oct 2023 19:11:46 GMT",VentureBeat,"Appy Pie, founded in 2015 by a stalwart in the field of mobile app development, Abhinav Girdhar, is a no-code platform that leverages generative AI to provide a multitude of benefits. Among the most prominent advantages of the platform are faster speed-to-market, reduced cost of operations and enhanced data security. With expertise in mobile applications, web analytics, ecommerce, entrepreneurship and all things related to the DIY app-building process, Girdhar founded Appy Pie to bring affordable new-age technology to technological novices. His steadfast pledge to lead the organization while preserving the highest standards of veracity and accountability is responsible for the platform’s recent emergence as a leader among its peers.

As a no-code platform, Appy Pie allows users to build applications and software sans any need for complex coding skills. This no-code approach effectively accelerates the development process by eliminating the time-consuming traditional development cycle. This results in faster speed-to-market combined with generative AI, which assists in creating complex algorithms, code snippets and designs. The development process is significantly sped up as this generates code based on high-level instructions. With the incorporation of generative AI, the time required for quality custom development is reduced substantially.

When Girdhar conceptualized Appy Pie, however, he did not do so only to speed up the development process. While he envisioned a platform that would democratize technology, he wanted to prioritize accessibility and affordability above all. As a no-code platform, Appy Pie requires fewer IT sources and developers. This means that both labor costs and the need for specialized technical skills are greatly reduced while generative AI automates repetitive coding tasks, lessening the need for manual coding. The automation minimizes errors and the costs of maintenance and debugging.

Additionally, Appy Pie offers enhanced data security as it provides secure authentication and data encryption options. Generative AI helps by creating code that adheres to technical coding standards and security best practices. This diminishes the likelihood of security breaches and other vulnerabilities in applications.

Beyond speed, affordability and security, Appy Pie allows for rapidly scaling applications. Not only does Generative AI assist in creating scalable code optimized for peak performance and handling increased workloads, it also enables easy addition of functionality and new features without manual coding. As was envisioned by Girdhar, Appy Pie democratizes application development. This means that people across diverse departments can contribute to the development process in multiple ways, nurturing collaboration and encouraging innovation. Utilizing Generative AI, the gap between non-technical and technical teams is bridged by automating code and making it easily accessible to a wider range of users.

Both no-code and generative AI permit swift prototyping and iterative development. This allows for the prompt implementation of various changes and updates, granting users a more remarkable ability to respond to shifting market conditions and feedback with fascinating agility. The combination of generative AI technology and Appy Pie significantly benefits organizations by accelerating development with unprecedented speed, enhancing security, diminishing costs and refining overall efficiency in transporting new software solutions to the market. Appy Pie’s no-code platform and Generative AI allow developers to stay competitive in today’s incredibly fast-paced and ever-evolving technological landscape.

VentureBeat newsroom and editorial staff were not involved in the creation of this content."
Meta Expands its Roll Out of Generative AI Features for Ad Creation - Social Media Today,https://www.socialmediatoday.com/news/meta-expands-roll-out-generative-ai-features-ad-creation/695652/,"Wed, 04 Oct 2023 18:44:28 GMT",Social Media Today,"After testing them out with selected brand partners over the past five months, Meta has today announced an expanded launch of its new generative AI elements for ad creation, including text variations, background generation, and image expansion tools.

As the titles suggest, each of these new elements will use generative AI to provide more creative options, either through suggested post captions, alternative image backgrounds, or generated visuals to use in different ad formats.

Which could provide significant benefit in your ad creation process, with Meta’s initial test pool finding that the new options saved them significant time, and helped them maximize their campaigns.

As per Meta:

“According to a survey of advertisers that participated in early testing, half of them estimate that generative AI will save them five or more hours a week - the equivalent of one month per year - noting they’ll be able to create multiple asset variations with the click of a button, reducing time spent between creative and media teams on time-consuming editing tasks and allowing for more strategic work.”

In addition to this, test partners also indicated that Meta’s new AI ad tools helped them drive campaign performance, by enabling quicker development of more ad creative variations at scale.

There’s a range of ways in which these could be used, with background generation, in particular, looking like a valuable, and beneficial option to integrate into your process.

Meta’s also working on additional background generation options too:

“We plan to offer advertisers more ways to generate background images in minutes with tailored themes, like outdoor images for an athleisure brand.”

In addition to this, Meta’s also developing AI tools for business messaging, which has been a key area of growth of late:

“Businesses will soon be able to use AIs for business messaging on Messenger and WhatsApp to engage with customers – helping with commerce, engagement and support, unlocking instant conversational responses. We’re testing with a small number of businesses in Alpha and plan to scale it further next year.”

It’s a good way to utilize generative AI within the ad creation process, providing recommendations and alternatives, as opposed to trying to use AI to fully automate the entire process. I mean, Meta’s working on that as well, but right now at least, most generative AI tools seem to work best in a supplementary capacity, as assistive tools, as opposed to replacements for real human input.

Maybe, at some stage, AI bots become so advanced that they’ll actually be better than humans in this respect, but I do feel like genuine creativity will be hard to simulate. So if you want to create derivative content, which is similar to all that’s come before, AI systems might be able to do that (and it might perform quite well), but for next-level innovation and creativity, human input will still be required.

But used well, AI will extend the capacity of advertisers, and enable broader experimentation, personalization, and ideally, response.

Meta says that these new AI features are being rolled out in Meta’s Ads Manager from today, with a global rollout to be completed by next year."
Adobe teases a new ‘revolutionary’ AI photo editing tool - The Verge,https://www.theverge.com/2023/10/5/23904416/adobe-max-sneak-project-stardust-ai-photo-editing-tool,"Thu, 05 Oct 2023 11:02:43 GMT",The Verge,"Adobe is set to announce a new AI-powered photo editing tool at the Adobe Max event next week that makes it much easier to alter images without prior editing experience. According to a promotional video (seen via Techspot), the new “object-aware editing engine” — dubbed Project Stardust — automatically identifies individual objects in regular photographs, allowing them to be easily moved around and changed. It’s similar to Google’s Magic Editor announced yesterday for its new Pixel phones, but presumably more powerful.

A quick demonstration of the new software shows how objects in a photograph — such as the yellow suitcase and its shadow in the example image — are automatically identified and selected as if they had been separated using Photoshop’s lasso tool. The clip then demonstrates how objects can be moved, deleted, or otherwise manipulated as if they were stored on a separate layer, with the missing space behind them being automatically filled in to match the rest of their surroundings.

Project Stardust includes something simliar to the “Contextual Task Bar” that debuted in Photoshop earlier this year, which can automatically detect the next steps in your design process and allow you to make quick edits. In the demo video, selecting a crowd of blurred people in the background of the image prompts a “remove distractors” button to appear on the taskbar, which automatically deletes the crowd when clicked.

The new editing engine features some of the same generative AI capabilities as Adobe’s Firefly-powered Photoshop tools. Adobe’s project manager Aya Philémon can be seen selecting an area of the photograph and inputting text into a floating taskbar prompt to fill the selected space with AI-generated flowers. In another clip, the same feature is used to replace individual items of clothing on a model by selecting the item (for example, a jacket or sneakers) and then describing a new piece of clothing to drop in.

Project Stardust removes the need to manually separate objects onto a new layer. Image: Adobe And this taskbar recognizes what step you’re likely to take next and provides users with a one-click button to action it. Image: Adobe"
"Oracle Injects AI Into Database, Cloud Infrastructure and Applications - Insider Homepage Redirects",https://insider.govtech.com/california/sponsored/oracle-injects-ai-into-database-cloud-infrastructure-and-applications,"Wed, 04 Oct 2023 20:02:16 GMT",Insider Homepage Redirects,"Generative AI showed up about a year ago now, and it changes everything. It’s certainly changing everything at Oracle. Larry Ellison, Oracle Chairman and Chief Technology Officer

Assistance and analysis

AI Vector Search adds to Oracle Database 23c the ability to store semantic information about documents, images, and other unstructured files as vectors, or numerical representations of text that let large language models quickly find closely related terms. The collection of features also lets Oracle Database users perform retrieval-augmented generation (RAG), a technique that combines LLMs with private business data to deliver responses in specific fields of knowledge. AI Vector Search can also boost developers’ productivity by adding generative AI capabilities to Oracle Database development tools including APEX, so users can write applications and queries without coding.

adds to Oracle Database 23c the ability to store semantic information about documents, images, and other unstructured files as vectors, or numerical representations of text that let large language models quickly find closely related terms. The collection of features also lets Oracle Database users perform retrieval-augmented generation (RAG), a technique that combines LLMs with private business data to deliver responses in specific fields of knowledge. AI Vector Search can also boost developers’ productivity by adding generative AI capabilities to Oracle Database development tools including APEX, so users can write applications and queries without coding. OCI Generative AI , which lets businesses integrate LLMs built by Cohere with their applications via an API, then run those models on Oracle’s fast and cost-effective OCI Supercluster service. The service will be available on a test basis to customers; once it’s generally available it is expected to work in tandem with AI Vector Search to let customers create RAG applications that combine pretrained models with their own data. The generative AI service also underlies new features in Oracle Cloud Applications, NetSuite ERP, and healthcare applications.

, which lets businesses integrate LLMs built by Cohere with their applications via an API, then run those models on Oracle’s fast and cost-effective OCI Supercluster service. The service will be available on a test basis to customers; once it’s generally available it is expected to work in tandem with AI Vector Search to let customers create RAG applications that combine pretrained models with their own data. The generative AI service also underlies new features in Oracle Cloud Applications, NetSuite ERP, and healthcare applications. More AI computing power: Oracle plans to make NVIDIA’s latest H100 chips more widely available on their cloud infrastructure; the GPUs offer up to 30 times better inference performance when serving up answers from users’ prompts and four times better training performance compared with NVIDIA’s previous-generation A100 chips. For customers training AI models, OCI Supercluster lets them connect tens of thousands of H100 chips over a high performance, low-latency network, initially available in Oracle’s Chicago, Illinois, and London, England, data centers. OCI also plans to offer NVIDIA’s L40S GPU for training smaller models or for AI inferencing.

Oracle plans to make NVIDIA’s latest H100 chips more widely available on their cloud infrastructure; the GPUs offer up to 30 times better inference performance when serving up answers from users’ prompts and four times better training performance compared with NVIDIA’s previous-generation A100 chips. For customers training AI models, OCI Supercluster lets them connect tens of thousands of H100 chips over a high performance, low-latency network, initially available in Oracle’s Chicago, Illinois, and London, England, data centers. OCI also plans to offer NVIDIA’s L40S GPU for training smaller models or for AI inferencing. Oracle Clinical Digital Assistant , which works with the software company’s electronic health records, can cut down on paperwork by offering doctors a voice- and screen-powered user interface that automatically takes notes during conversations with patients and suggests actions, such as ordering medicines or lab tests and scheduling follow-up visits. Doctors will also be able to verbally call up MRI results or other elements from a patient’s EHR without typing. The software is expected to be available within the next year.

, which works with the software company’s electronic health records, can cut down on paperwork by offering doctors a voice- and screen-powered user interface that automatically takes notes during conversations with patients and suggests actions, such as ordering medicines or lab tests and scheduling follow-up visits. Doctors will also be able to verbally call up MRI results or other elements from a patient’s EHR without typing. The software is expected to be available within the next year. Oracle Advertising and Customer Experience , aimed at marketers and service agents, adds the ability to draft AI-generated customer responses, write and search help articles, and summarize key information from customer interactions. Marketing staff can draft campaigns that adhere to their companies’ brand guidelines by walking through a step-by-step AI-driven process.

, aimed at marketers and service agents, adds the ability to draft AI-generated customer responses, write and search help articles, and summarize key information from customer interactions. Marketing staff can draft campaigns that adhere to their companies’ brand guidelines by walking through a step-by-step AI-driven process. Oracle Analytics Cloud, a platform for visualizing data and collaborating on it, now lets analysts interact with data using plain language, seeing and hearing responses generated by AI. The software is also being designed to automatically read and pull key information from text and image files.

Generative AI: Is it the most important computer technology ever? Probably,” Ellison said. “One thing’s for certain: We’re about to find out. Larry Ellison, Oracle Chairman and Chief Technology Officer

In June, Oracle entered the generative AI market, striking a deal to provide large language models (LLMs) to their customers and announcing billions of dollars in cloud computing commitments from startups training the complex systems.Three months later, the software maker is delivering broad access to the powerful AI technology across their cloud infrastructure, electronic health record (EHR) software, data analysis tools, ERP, and customer service software. Signed business from AI developers has doubled to $4 billion.“Generative AI showed up about a year ago now, and it changes everything. It’s certainly changing everything at Oracle,” Chairman and Chief Technology Officer Larry Ellison said September 19 during his keynote address at the company’s CloudWorld conference in Las Vegas.During the conference, Oracle unveiled a generative AI cloud service, artificial intelligence enhancements to their software for healthcare practitioners, and new database capabilities for storing and rapidly retrieving the unstructured and semi-structured data used in AI systems. Oracle also announced customer management software enhancements that let marketers create campaigns or service agents summarize conversations, and a generative AI-powered assistant for business data analysts debuted.Generative AI systems, which learn from patterns gleaned from the internet and private data sets and then help users arrive at new insights, have set off a flurry of development and funding—and a scramble for the computing power needed to train and run large language models. These models can aid in medical diagnoses, summarize market analysis, analyze conversations, create text and images, and write code. But LLMs need vast amounts of parallel processing power and fast data communication that exceeds the conventional computing capability found in most businesses’ data centers. That’s driving developers to run more of this work in public clouds, where the networks and specialized chips they need are more readily available.To put generative AI tools in businesses’ hands, Oracle is expanding the use of chipmaker NVIDIA’s most powerful H100 AI processors in their cloud, touting the networking speed and price advantages the advanced chips bring to the Oracle cloud computing service. Customers are responding: AI development companies have signed contracts to purchase more than $4 billion of training capacity on Oracle Cloud Infrastructure (OCI), double the amount at the end of Oracle’s fiscal fourth quarter on May 31.Oracle offers a unique cloud computing infrastructure that quickly moves data to where it’s needed for processing, then shuttles it rapidly among processors while AI models get trained, Ellison said.Oracle is also catering to companies’ desire to quickly and affordably fine-tune standard models by adding their own data to improve predictive capabilities in specific fields. “They want to use their own training data,” he said. “The best way to do that is to put that supplemental training data into an Oracle vector database.”“We are much faster and many times less expensive than the other clouds for training AI models,” Ellison said.Businesses that turn generative AI to their advantage could reap big benefits. Generative AI could lift global GDP by 7% —or nearly $7 trillion—over the next decade by increasing office workers’ productivity, hastening drug discovery, and speeding software development, according to Goldman Sachs. Consultancy McKinsey & Co. estimates generative AI and related technologies could add up to $4.4 trillion to global GDP as half of today’s work in areas including sales, marketing, coding, and R&D becomes automated between 2030 and 2060.Oracle is delivering AI-powered tools on several fronts. In June, Oracle teamed up with Toronto, Canada-based large language model developer Cohere to offer OCI customers AI capabilities based on Cohere’s technology and took an investment in the startup. The first offerings based on the collaboration are coming to market now."
Experts consider the impact burgeoning AI may have on the legal ... - NYU Law,https://www.law.nyu.edu/news/nyu-artificial-intelligence-law-legal-profession,"Wed, 04 Oct 2023 19:19:25 GMT",NYU Law,"At a September 13 conference hosted by NYU Law’s Center on Civil Justice, scientists, lawyers, researchers, regulators, and technology experts convened to consider how artificial intelligence (AI) may affect the future of the legal profession.

Selected remarks from a panel discussion on the AI regulatory and enforcement landscape:

Eerie Meyer, chief technologist at the Consumer Financial Protection Bureau: “If a firm is using advanced automated systems that they themselves don't understand, how can they possibly comply with the law?...We work with regulators across the country at the state level, the federal level, and the city level to help share how we're interpreting existing law in a technical context.... For the law students in the crowd, consider coming to work at a regulatory agency because we are untangling these puzzles right now.”

Neema Guliani, deputy assistant secretary for services at the US Department of Commerce: “We’re throwing around [terms] like generative AI…. How do we utilize common definitions and create harmonization to the extent possible around those definitions internationally, so that when we are talking about frameworks or regulation, we’re all speaking in a way that companies who want to be good actors can understand and know the law?...So that as we're developing this work, we're doing so in a way that maximizes our ability and the ability of US businesses to compete globally.”

Posted on October 4, 2023"
ContractPod AI enhances generative AI CoPilot Leah - - Enterprise Times,https://www.enterprisetimes.co.uk/2023/10/05/contractpod-ai-enhances-generative-ai-copilot-leah/,"Thu, 05 Oct 2023 07:04:47 GMT",Enterprise Times,"ContractPodAI has announced new features to Leah Legal CoPilot it declared earlier this year. It means that CoPilot now has new capabilities to support legal teams. These will improve productivity across a range of legal tasks. The original capabilities include Leah One Drop, adding new contract applications, and Leah Assist to help with redlining. It has now added Leah Discovery for multi-level gale analysis, Lead Redline, further improving redlining, and Leah Assist, offering guidance across a range of subjects. There is also Leah Impact, a reporting tool and a new add-in for Microsoft Word.

Anurag Malik, President and Chief Technology Officer at ContractPodAi, commented, “Through a combination of our internal expertise and best-of-breed large language models, we’re excited to release these new modules to help customers further harness the power of generative AI to streamline their day-to-day work and see unprecedented productivity gains. With the rapid pace of the legal technology industry, it’s important for vendors to quickly and securely bring unique innovations to market to help legal professionals navigate both current and future challenges. Our continued innovation is a testament to our ability to quickly bring a generational shift to how customers use technology.”

What are the new features?

Leah Discover will perform comprehensive discovery across multiple documents without any limitations on the size or number of documents. Documents can include any legal transactions from M&A, litigations, contracts and legal to regulatory compliance use cases.

Leah possesses an expanded token capacity. Allowing for in-depth legal analysis and responses for large-scale projects where comprehensive coverage is essential. With Leah, there are no restrictions on response size.

The CoPilot provides detailed and complete analysis, delivering all the necessary insights and data to make informed decisions. It will also provide cross-file sourcing and citations and a description of the method incorporated to drive results and conclusions. This feature enables lawyers to quickly verify the insights provided and confirm the accuracy of the response. This human-in-the-loop is imperative for users to build trust in Leah and also to validate that the results are accurate.

Leah Redline helps legal teams create comprehensive risk and remediation reports. These provide a meticulous examination of the document to evaluate risk. The CoPilot can also redraft contracts, including relevant, accurate and concise redline documents. The new documents will comply with the organisation’s standard terms and redline others to ensure they are not unfavourable. This ability is based on the Leah framework, which helps identify risk in language and will annotate any changes with reasons and references for doing so. This further simplifies the validation by lawyers when reviewing Leah’s work.

Leah Guidance provides an interactive and conversational concierge that can automatically offer legal guidance across multiple legal matters by understanding your policies, negotiation strategies, playbooks and other reference materials stored in your knowledge base. Thisoffers full transparency to the source material and the rationale of the guidance, giving hours back to legal professionals.

Leah Impact provides comprehensive insights about the use of Leah CoPilot across the organisation. The solution provides information about user activity, usage data, real-time ROI and productivity. It enables managers to see how the ContractPodAI generative AI is being used across the organisation, or not used.

Leah Copilot Microsoft Word add-in. A new add-in that gives access to the Leah capabilities while using Word. It means that Leah can assist lawyers in reviewing and editing Word documents themselves to give a co-pilot experience in the word processor.

Enterprise Times: What does this mean?

ContractPodAI has continued to invest in generative AI to benefit its customers. Those organisations using ContractPodAI and Leah to its fullest should see productivity gains. However, there are caveats to the solution; users must retain the human in the loop. The addition of Leah Impact also helps organisations to ensure that the solution is used correctly.

Legal firms should be aware that it is still the human lawyer who bears the responsibility for the work done. With the verification and cross-referencing that ContractPodAI has embedded into the Leah functionality being vital. The caveat is always: does the generative AI have access to all the relevant legal documents and case law around a subject? Even the most recent ones?

What ContractPodAI appears to have achieved, though, is a real balance between usability, compliance and expertise. What it needs to do next is publish a case study of how it has genuinely helped a legal firm deliver on the efficiency and productivity gains it promises and the difference in profitability and revenue it has delivered."
Learning Pool Launches AI Conversations to Bring the Power of ... - PR Newswire,https://www.prnewswire.com/news-releases/learning-pool-launches-ai-conversations-to-bring-the-power-of-generative-ai-to-workplace-learning-301948277.html,"Thu, 05 Oct 2023 12:30:00 GMT",PR Newswire,"Powered by OpenAI's GPT4, capability improves manager soft skills and workplace communication

NEW YORK and DERRY, Northern Ireland, Oct. 5, 2023 /PRNewswire/ -- Learning Pool, the leading global provider of workplace learning solutions, today announced the launch of AI Conversations, a generative AI offering that allows employees to practice challenging workplace conversations with an AI-generated character. AI Conversations leverages OpenAI's GPT4 to provide users with convincing, conversational responses, but also detailed, personalized feedback to help them improve their communication and management skills. It's a breakthrough way for companies in any industry to ensure productive workplace conversations.

Only 21% of employees today feel that they received meaningful feedback in the last week, according to Gallup. It's up to team leaders to coach and develop their people, but they are often left on their own to learn to do so. The fear and anxiety of a difficult conversation leads many to avoid the discussion altogether – a disservice to employees and the greater business. Organizations must equip employees with the resources to feel confident in all kinds of conversations, like salary negotiations, poor performance, and goal setting. Intelligent eLearning tools like AI Conversations can help bridge the communication gaps for managers and their teams.

""Workplace conversations are delicate and often high stakes. With AI Conversations, our team has set a new standard for what's possible in intelligent eLearning,"" said Ben Betts, CEO of Learning Pool. ""This first-of-its-kind capability introduces the power of generative AI to workplace learning and better enables the kind of workplace where we all want to work – one with managers that offer clear and productive feedback.""

Human interaction is incredibly difficult to simulate and scale. AI Conversations changes this by using GPT4 to generate limitless responses to user inputs. These responses can be tailored to fit any combination of character attributes, from their mood – frustrated, happy, etc. – to their role and tenure at an organization. With both two-way audio and text-based options, scenarios are simple to deploy on any learning platform, and organizations can pull from Learning Pool's off-the-shelf scenarios or create custom scenarios tailored to meet individual needs.

Learning Pool has partnered with Mind Tools, a celebrated provider of business skills, personal development, and leadership and management content, to produce the first off-the-shelf AI Conversations collection. This collection focuses on managing the performance of a direct report. Mind Tools applied its expertise to the authoring and assessment framework of each scenario.

""When it comes to incorporating generative AI into workplace learning, organizations will be looking for authoring that is trusted and credible,"" explained Nahdia Khan, Chief Impact Officer at Mind Tools. ""We're able to deliver on that expectation with AI Conversations – building on our proven 25 years of content provenance equipping leaders and their teams. Pilot participants validated our approach, reporting that AI Conversations provided clear, realistic, and personalized feedback, and the conversation with the AI tool felt natural.""

For more on AI Conversations, click here.

About Learning Pool

Learning Pool creates learning experiences that deliver extraordinary outcomes for workplaces investing in the performance and skills of their people. Supporting thousands of businesses investing in learning experiences for their global learners, Learning Pool's innovative AI learning platforms and skills solutions combine integrated technology and adaptive content to produce actionable insight on every learner's performance. Its world-class customer experience ensures clients can harness its unique ability to produce a highly skilled workforce, new competitive advantages, and an organization prepared for whatever the future might bring. Wherever you find ambitious workplaces investing in their people, you'll find Learning Pool .

About Mind Tools

Mind Tools brings accessible, on-demand performance tools and resources focused on leadership, management and personal effectiveness that empower people to perform in today's progressive workplaces. These solutions help build happy and successful careers and contribute positively to the success of organizations, the world over. At Mind Tools, empowering people to thrive at work has been our passion for 25 years.

Logo - https://mma.prnewswire.com/media/2239234/Learning_Pool_Logo.jpg

SOURCE Learning Pool"
UST Highlights AI Innovation at Global D3 Expo India - English - PR Newswire,https://www.prnewswire.com/in/news-releases/ust-highlights-ai-innovation-at-global-d3-expo-301948043.html,"Thu, 05 Oct 2023 07:00:00 GMT",PR Newswire,"Elite research affiliations, innovative applications and practical accelerators combine to deliver dynamic, forward-looking AI solutions

BENGALURU, India and ALISO VIEJO, Calif., Oct. 5, 2023 /PRNewswire/ -- UST, a leading digital transformation solutions company, is building upon its long history of artificial intelligence (AI) innovation and leadership, highlighting its ability to meet emerging demands in a rapidly growing market. The future of generative AI and UST's contributions to the rapidly emerging field were the focus of the D3 expo at UST's state-of-the-art campus in Thiruvananthapuram, India.

Generative AI has truly taken off this year, showcasing the technology's remarkable capabilities and gaining widespread acceptance as a transformative technology. UST has helped lay the groundwork for AI's recent rise, having been at the forefront of developing AI solutions for over a decade and prioritizing sustained future growth in this critical sector.

UST has repeatedly facilitated notable operational improvements for its clients and partners by deploying advanced AI solutions across various industries. Examples include:

Predictive analytics for an Asian airline that reduced food waste by 28%.

UST AI solutions for an international convenience store chain that achieved a 45% reduction in customer checkout time.

UST's natural language processing (NLP) and a deep learning-driven document retrieval system leveraged by a global financial institution, significantly enhancing the productivity of its marketing and content creation teams.

UST's leadership position in AI is further enhanced through its professional research affiliations with the Stanford University Artificial Intelligence Laboratory and the MIT Computer Science and Artificial Intelligence Laboratory. These collaborations ensure UST clients receive state-of-the-art AI solutions that enhance operational efficiency, deliver innovation and competitive advantage.

UST emphasizes rapid and pragmatic generative AI implementation, helping clients realistically and safely harness the power of generative AI. UST's accelerator development further bolsters this commitment. For example, the UST Responsible Rails framework ensures ethical AI deployments, and the UST Code Crafter large language model (LLM) provides tools for streamlined software development, including automated refactoring, application migration, and code conversion.

Additionally, UST's hyperscaler accelerators offer an ecosystem of products and services with major cloud providers such as Microsoft, AWS, and Google. These accelerators reduce operational overhead, ensure accelerated time-to-value, substantial cost savings, and offer a distinct competitive advantage for clients. In one successful case, UST delivered a bespoke Generative AI chatbot to its client in less than 90 days.

""I've always believed in the power of artificial intelligence and its promise to improve human lives. At UST, we are already experiencing the enormous positive impact the technology is delivering for our clients, our employees and in our communities. I'm proud that UST has been a leader in developing sustainable, responsible, and pragmatic AI solutions that transform our clients' businesses and make our employees more innovative and efficient. We believe that our deep generative AI experience positions us for even more success as demand for AI increases,"" said Krishna Sudheendra, Chief Executive Officer, UST.

""As more and more businesses reach out to UST for generative AI solutions, I am honored to be at a company with an established track record of leading innovation, bridging academic insights with enterprise rigor, putting that knowledge into practice, and creating real benefits for clients and partners. UST has always worked to stay at the forefront of innovation, and the insights gained from our experience shaping the AI landscape have left us well positioned to respond to growing demand,"" said Dr. Adnan Masood, Chief AI Architect, UST.

Speakers at the D3 (Dream, Develop, and Disrupt) global technology conference on October 5th included a diverse range of renowned AI thought leaders from academia, leading tech companies, UST customers, and UST. The expo also provided the backdrop for the D3CODE hackathon, which this year encourages AI innovation and creativity among Indian college and university students, with competition winners receiving a conditional job offer from UST.

About UST

For more than 24 years, UST has worked side by side with the world's best companies to make a real impact through transformation. Powered by technology, inspired by people, and led by our purpose, we partner with our clients from design to operation. Through our nimble approach, we identify their core challenges, and craft disruptive solutions that bring their vision to life. With deep domain expertise and a future-proof philosophy, we embed innovation and agility into our clients' organizations—delivering measurable value and lasting change across industries, and around the world. Together, with over 30,000 employees in 30+ countries, we build for boundless impact—touching billions of lives in the process. Visit us at www.ust.com.

Media Contacts, UST:

Tinu Cherian Abraham

+1 (949) 415-9857

Merrick Laravea

+1 (949) 416-6212

Neha Misri

+91-9284726602



Roshni Das K

+91 7736795557

[email protected]

Media Contacts, U.S.:

S&C PR

+1-646.941.9139

[email protected]

Makovsky

[email protected]

Media Contacts, U.K.:

FTI Consulting

[email protected]

Logo: https://mma.prnewswire.com/media/1422658/UST_Logo.jpg

SOURCE UST"
Study Finds AI Tools Help but also Hurt Worker Performance - VOA Learning English,https://learningenglish.voanews.com/a/study-finds-ai-tools-help-but-also-hurt-worker-performance/7296498.html,"Wed, 04 Oct 2023 22:05:30 GMT",VOA Learning English,"An experiment involving hundreds of office workers has found that artificial intelligence (AI) tools can greatly help but also hurt worker performance.

AI tools designed to operate at human levels have greatly expanded in popularity over the past year. These include OpenAI’s ChatGPT, Google’s Bard and Microsoft’s AI-powered search engine Bing.

Such tools, also known as chatbots or “generative AI,” are computer-powered systems. They are designed to interact smoothly with humans and perform high-level writing and creative work.

In recent months, these tools have demonstrated an ability to produce high quality work. This has led some technology experts to warn that generative AI systems could end up replacing workers in many industries.

This year, researchers at Harvard Business School and other organizations carried out an experiment. It aimed to test how well AI tools could help workers perform their usual duties, or tasks. It involved more than 700 business advisors, called consultants, from Massachusetts-based Boston Consulting Group.

Harvard Business School recently published results from the experiment in a “working paper.” The main findings suggest that AI tools like ChatGPT can greatly improve worker performance.

For example, researchers found that, on average, workers who used OpenAI’s latest ChatGPT 4 tool completed 12 percent more tasks than non-ChatGPT users. Tasks carried out with help from the AI technology were completed 25 percent faster. And the team found the quality of work performed by consultants using ChatGPT 4 increased about 40 percent.

Work tasks used in the study covered four main areas: creativity, analytical thinking, writing and persuasiveness. The team gave examples of worker tasks in each of these areas.

One example for creativity was: “Propose at least 10 ideas for a new shoe targeting an underserved market or sport.” For writing, consultants were asked to “write a press release with marketing copy” for a new product. To show persuasiveness, workers were told to write a letter to employees that explained why a particular product would beat competitors.

Harvard Business School’s Fabrizio Dell’Acqua was the paper’s lead writer. He told technology website VentureBeat he thinks the results were especially important because they showed that AI tools can help even highly educated, experienced workers.

“The fact that we could boost the performance of these highly paid, highly skilled consultants, from top, elite MBA institutions…I would say that’s really impressive,” Dell’Acqua said.

However, the paper also noted areas where the performance of consultants using ChatGPT 4 dropped. The researchers said this was especially true with tasks the AI tool was not good at completing.

Of tasks the AI was good at, the experiment showed it “significantly improved human performance,” the paper said. But for tasks ChatGPT 4 was not right for, “humans relied too much on the AI, and were more likely to make mistakes.”

The researchers reported that consultants who used AI for tasks it was not well equipped for “were 19 percent less likely to produce correct solutions compared to those without AI.”

The experiment also showed how consultants used the AI tool differently to improve their work. The researchers said some workers purposely divided the tasks with some being completely carried out by the AI tool and others the workers themselves carried out completely. Other workers chose to use AI for all tasks, while “continually interacting with the technology.”

The team suggests one of the biggest barriers to companies effectively using AI is not knowing which tasks can be completed best with the technology. Finding this out will require businesses to carry out thoughtful research and training efforts in order to find the right mix of AI and human-level work.

I’m Bryan Lynn.

Bryan Lynn wrote this story for VOA Learning English, based on reports from Harvard Business School.

Quiz - Study Finds AI Tools Help but also Hurt Worker Performance Start the Quiz to find out Start Quiz

______________________________________________

Words in This Story

analytical – adj. examining the details of something carefully in order to understand or explain it

impressive – adj. making or attempting to make a marked impression

boost –v. to lift or increase something

elite – adj. the richest, most powerful or best educated groups in a society

rely – v. to depend on"
Betterworks Announces New Generative AI Capabilities to Help ... - StreetInsider.com,https://www.streetinsider.com/Business+Wire/Betterworks+Announces+New+Generative+AI+Capabilities+to+Help+Make+Managers+More+Effective/22242391.html,"Thu, 05 Oct 2023 12:03:35 GMT",StreetInsider.com,"The solution enables better, less biased employee feedback

MENLO PARK, Calif.--(BUSINESS WIRE)-- As the world grapples with the demands of an evolving workplace, Betterworks has taken a significant step in its mission to rethink performance management and help companies cultivate more productive employees and teams. Today, the company announces the next generation of its Intelligent Performance Management solution featuring three new generative AI capabilities that make creating clear goals, giving impactful employee feedback, and having meaningful and productive performance conversations easier than ever before.

“Generative AI accelerates the realization of our vision to make the performance process efficient, effective, and fair and enable everyone in an organization to work at their highest potential,” said Doug Dennerline, chief executive officer of Betterworks. “We’re completely revolutionizing the traditional approach to performance management and making it easier for managers to be the kind of exceptional coaches who produce top performers and strong business results — both by relieving an administrative burden and by turning employee performance data into accurate and actionable insight with AI. This next generation of our solution is transformative for businesses that want to cultivate a high-performing workforce and achieve their business goals.”

The first phase of generative AI capabilities Betterworks plans to bring to market includes three tools designed to improve the quality and specificity of communications while also reducing the time, stress, and complexity associated with performance management activities.

Goal Assist draws on an employee's performance data from Betterworks modules to help employees quickly write clear goals that are aligned with their team's and company's goals, saving time and effort and promoting achievement.

draws on an employee's performance data from Betterworks modules to help employees quickly write clear goals that are aligned with their team's and company's goals, saving time and effort and promoting achievement. Feedback Assist provides leaders with personalized, constructive, and unbiased feedback for employees, leading to greater trust, focused career planning, and better outcomes. The tool summarizes feedback over a selected period of time to provide a comprehensive view of an employee's accomplishments.

provides leaders with personalized, constructive, and unbiased feedback for employees, leading to greater trust, focused career planning, and better outcomes. The tool summarizes feedback over a selected period of time to provide a comprehensive view of an employee's accomplishments. Conversation Assist improves the quality and clarity of manager communications by drawing on employee goals, feedback, recognition, and other data to help managers clearly and confidently coach, express their expectations, and provide actionable takeaways for employees.

“We consulted with our customers and looked at the areas of performance management that created the biggest challenges for people leaders and asked, ‘How can we make this less painful and help managers be more effective at the same time?’” said Betterworks’ Chief Product Officer, Arnaud Grunwald when describing the approach to designing the feature set. “Time savings are important, and our new capabilities offer that — but even more critical is a manager’s ability to give constructive feedback that reduces the risk of bias and helps the employee achieve their goals. Our initial feature set zeroes in on how to best support the people doing the coaching. We’re excited to continue building on these and exploring how to maximize generative AI’s potential.”

Core to Betterworks’ strategy is its commitment to a ‘responsible AI’ approach grounded in transparency, human-centricity, privacy, and stringent governance. This includes enhancing user trust and understanding by marking all AI-generated outputs clearly and explaining the AI's recommendations. It also emphasizes a human-first design philosophy to preserve the critical role of human insight in decision-making while also helping reduce bias and increase accuracy. Betterworks prioritizes privacy through robust infrastructure, preventing the unauthorized disclosure of sensitive customer data, and maintaining clear communication about data practices. Users can activate AI capabilities at their own discretion, and the company plans to keep AI-assisted features in beta as long as necessary to refine reliability and performance.

The first of the features announced today will be available for customers this month. For more insight into the future of generative AI for HR and performance management, be sure to check out Betterworks’ recently launched podcast, People Fundamentals, available on Spotify and Apple Podcasts.

About Betterworks

Founded in 2013, Betterworks is the pioneer in intelligent performance management solutions that help workforces and organizations achieve their highest potential. Betterworks reimagines performance management for all with an enterprise-ready platform that fosters greater manager effectiveness and employee performance, leading to higher satisfaction and retention and better business outcomes. It combines generative AI and data analytics that enable organizations to make smart, data-based decisions with a comprehensive solution that incorporates conversations, check-ins, feedback, employee engagement, and recognition — all accessible in the applications employees use daily.

Our customers’ employees are proven more engaged and satisfied in their roles, which is why industry leaders like Colgate-Palmolive, Intuit, Udemy, Freddie Mac, Kroger, Vertiv, and the University of Phoenix rely on Betterworks to manage and enable excellent performance. Betterworks is backed by Kleiner Perkins, Emergence Capital, and John Doerr.

For more information, please visit www.betterworks.com.

View source version on businesswire.com: https://www.businesswire.com/news/home/20231005148829/en/

Carole Barrow, Bospar PR

[email protected]

Source: Betterworks"
asTech Introduces Generative AI Tool Offering Instant Collision ... - Collision Week,https://collisionweek.com/2023/10/05/astech-introduces-generative-ai-tool-offering-instant-collision-repair-recommendations-scan-results/,"Thu, 05 Oct 2023 15:59:41 GMT",Collision Week,"asTech, a Repairify company, announced asTech Insights, a generative artificial intelligence (AI) product that will immediately enhance its OEM-compatible scans.

Through the power of AI, asTech Insights uses the results from an asTech OEM-Compatible pre-scan to automatically generate custom collision repair recommendations that are specific to the vehicle and identified DTC codes. All within seconds after completing the pre-scan.

“asTech insights is not simply a database that looks up and matches a DTC code to a preset repair recommendation,” said Cris Hollingsworth, President of Repairify Global Holdings Inc. “It’s a true AI Large Language Model, trained with extensive data sets"
The battle at the heart of AI rulemaking - POLITICO Europe,https://www.politico.eu/newsletter/digital-bridge/the-battle-at-the-heart-of-ai-rulemaking/,"Thu, 05 Oct 2023 12:15:37 GMT",POLITICO Europe,"Press play to listen to this article Voiced by artificial intelligence.

POLITICO’s weekly transatlantic tech newsletter for global technology elites and political influencers.

By MARK SCOTT

Send tips here | Subscribe for free | View in your browser

HOWDY CAMPERS. This is Digital Bridge and I’m Mark Scott, POLITICO’s chief technology correspondent. If you, like me, struggle to keep up with the constant barrage of emails, texts, app notifications and other daily digital dross, I give you the perfect way to respond.

Time to turn our attention (again) to artificial intelligence:

— Separate AI negotiations in Brussels and Washington are the latest skirmish in the battle to prioritize short-term over long-term risks.

— No, artificial intelligence isn’t going to upend how disinformation is spread online. But it will fast-track existing (and entrenched) problems.

— The U.S. government just handed privacy campaigners a potential silver bullet to challenge the latest transatlantic data transfer pact.

WHITE HOUSE AI EXECUTIVE ORDER AND EUROPE’S AI ACT NEGOTIATIONS

CONTROVERSIAL STATEMENT: I’M NOT A BIG FAN of conspiracy theories. But ongoing horse-trading among European Union and United States officials on how to set safeguards around artificial intelligence really has got me donning a tin hat. Let me explain. EU officials finished up their latest round of negotiations this week on the bloc’s Artificial Intelligence Act which is expected to be finished by the end of the year. In Washington, the White House is similarly closing in on a new executive order that will somewhat codify voluntary commitments the likes of Amazon and OpenAI signed up to in July. The decree is expected to come in the second half of October.

Both negotiations are very different. Europe’s latest so-called trilogue (one of the worst words of all time, which describes dealmaking between the EU’s main institutions) primarily focused on which high-risk AI applications should require the most onerous oversight. Officials had suggested that some of these potentially harmful use cases may be exempt from regulation — so long as they are limited to very niche areas that may not be felt across society. Example: AI in law enforcement would be highly regulated. AI in aiding a doctor in specific medical treatments potentially would be exempt. After this week’s negotiations, those exemptions still stand, although how they will be defined is still unclear.

Over in the U.S., things are equally fuzzy. Details of the upcoming executive order are maddeningly difficult to find (you know where to find me, U.S. policymakers). But from conversations with those involved in that process in recent weeks, I’m slowly pulling a picture together. Three officials and industry representatives talked about how the upcoming announcement would provide a “bridge” between the recent voluntary commitments and binding obligations for companies — particularly on safety and cybersecurity and how these systems could be used for national security purposes. One of those individuals said Washington hoped to pitch its plan to allies during the United Kingdom’s upcoming AI Safety summit in early November.

That would potentially include outlining a pretty wide-ranging set of expectations for how the emerging technology would be harnessed in the coming years. Details are annoyingly scarce. But such a plan may involve helping American companies stay at the forefront, via additional money for research and development and/or a willingness to allow existing AI systems to develop, mostly unchecked from regulation. What’s becoming clear, though, is the White House has significantly pivoted away from its Blueprint for an AI Bill of Rights that focused on short-term issues like data protection, algorithmic bias and algorithmic accountability.

Both these examples — albeit under very different circumstances in Brussels and Washington, respectively — highlight the tensions that politicians and policymakers are now wading through. Everyone and their mother wants to be seen as both harnessing the potential economic value of AI and corralling the technology’s downsides. That means walking a fine balance between allowing these complex systems to develop without too much oversight and stopping the harmful effects of, say, an automated decision thwarting someone from receiving a legitimate government housing allowance.

As I explained last month, that pendulum is currently swinging toward a more industry-friendly approach. Companies’ lobbying around national security, geopolitical competition and short-term freedom to innovate is gaining ground over those calling for greater checks on how AI is used. You can see that in how potentially harmful use cases may be exempt from Europe’s AI Act. You can also see it in the White House’s shift toward AI competitiveness (mostly with China).

This won’t be the final round of negotiations between those who favor prioritizing short-term risks versus those eager to focus on long-term problems. But it’s a conversation that needs to be had — with the public — to guarantee any form of domestic or international AI governance regime ends up being fit for purpose. Personally, I favor the imminent real-world problems. But I also understand why politicians (often via industry lobbying) don’t want to avoid the potential existential risks — all while promoting AI as an engine for growth. It’s not an enviable position to be in. But we should at least acknowledge the fight is underway.

NO, AI IS NOT GOING TO SUPERCHARGE DISINFORMATION

I’VE BEEN AROUND LONG ENOUGH TO SPOT A FAD. And when it comes to digital policymaking, social media is on the way out, and artificial intelligence is on the way in. That’s not to say people don’t care about the harms associated with TikTok, YouTube and Instagram. It’s just that AI has become a shiny new toy that it’s now connected to problems that have been around for years. Disclaimer: I’ve upped my coverage of AI, too, so I’m also somewhat to blame.

Case in point: how disinformation and harmful content spreads online. It’s no longer about the complexities of multiple social media platforms using complex recommendation algorithms to serve up potentially malign content to an already polarized domestic audience who may (or may not) be susceptible to both domestic and foreign actors. Nope; that’s so 2020. Now, if you believe the digital policy zeitgeist, it’s all about how AI can hoodwink people on social networks into believing increasingly outlandish things. It’s about deepfake videos! It’s about weaponized AI-generated text and videos!

Here’s my public service announcement: Can we all calm down? “People ask me all the time: What are the major concerns of generative AI on misinformation?” Alex Engler, an AI expert at the Brookings Institution, told me. “And I respond that they’ll distract us from the fact that platforms have laid off their integrity teams.” His point is this: Can artificial intelligence make misinformation worse? Yes. But in the big scheme of things — especially when high-profile politicians with massive online followings can put out falsehoods, mostly unchecked — it’s a sideshow that has blinded officials to massive ongoing problems related to social media. More on that here.

This is a pretty nuanced argument. So stick with me. No one is saying that AI-generated falsehoods (be they videos, text or images) aren’t a problem. It’s just that, given the state of social media, they are fringe issues to the main event: a decade-long polarization that has left the online world segmented along party lines; increasingly fragmented between multiple social networks; and where politicians remain the main purveyors of falsehoods. Into that complex mix, artificial intelligence just isn’t going to move the needle beyond making existing problems worse.

“The use of generative AI can help lower the barrier to [creating] false and misleading information,” said Allie Funk, research director for technology and democracy at Freedom House, the Washington-based nonprofit. The organization just put out its annual report on Freedom of the Net, which focused on how AI was worsening an already dire situation in which global internet freedoms have declined for the 13th consecutive year. “Then all these networks that have existed for years can use that information, put it out and bombard it at scale,” she added.

It’s also worth remembering that AI isn’t exactly a new thing when it comes to social media. Those pesky recommendation systems from which content pops up into people’s feeds have been around for a while — and remain massively problematic in terms of the lack of transparency on how they work. As much as it’s easy to get overcome by the generative AI crazy (who doesn’t like a deepfake video, amirite?), a greater focus on how those complex recommendation algorithms work would do a lot more to quell potential harmful material than shifting everyone’s exclusive attention to a smattering of AI-generated falsehoods.

Don’t get me wrong; those things are now entering the wild. Republican presidential candidate Ron DeSantis used an AI-generated voice of Donald Trump in a recent attack ad. Donald Tusk, the opposition leader in the upcoming Polish parliamentary election, used the technology to mimic the voice of the country’s prime minister. In more authoritarian regimes like Venezuela’s, the government used off-the-shelf AI technology to put out fake news stories, relying on online avatars, to peddle propaganda.

These examples may grab people’s attention. But it’s not where the real action is ahead of next year’s motherlode of a global election cycle. “It’s less about a fundamental change in the information space,” said Freedom House’s Funk. “Here’s another tool that is going to make this problem so much worse.”

BY THE NUMBERS

IS FISA THE SOFT UNDERBELLY OF EU-US DATA TRANSFERS?

STAT OF THE DAY: Approximately 246,000 non-U.S. citizens/residents located outside of the country were targeted for surveillance under Section 702 of the U.S. Foreign Intelligence Surveillance Act (FISA), according to a report from the Privacy and Civil Liberties Oversight Board (PCLOB), a U.S. government agency. Over the last five years, the analysis added, the number of people captured by Section 702, which allows American national security agencies to collect information on non-U.S. individuals outside of the country, has nearly doubled. FWIW, PCLOB — despite an internal partisan fight — concluded FISA was instrumental in keeping the country safe.

Yet how extensive such surveillance practices remain — and what constitutes so-called bulk surveillance — may be key to upcoming legal appeals to the recently agreed E.U.-US Data Privacy Framework. Already, a French lawmaker has challenged the pact. Another claim from Max Schrems, the Austrian privacy campaigner, is expected later this month. Europe’s top court has already said it’s no fan of FISA-style bulk collection, even though almost all EU member countries carry out similar surveillance.

The latest PCLOB report, which mostly focused on issues related to how Americans’ data was potentially collected unlawfully, will make for uncomfortable reading for EU and U.S. officials eager to prove to the bloc’s judges that the new transatlantic privacy agreement upholds Europe’s fundamental rights. It also may give campaigners the much-needed reinforcement in their long-held beliefs that bulk collection under Section 702 is a clear breach of the EU’s data protection safeguards.

WONK OF THE WEEK

US SENATOR CHUCK SCHUMER has made himself the go-to dealmaker on AI, at least when it comes to some policymaking circles in Washington. So it feels only fitting to shine a light on Timothy Ryder, the senator’s legislative assistant who is nominally in charge of Schumer’s AI policymaking agenda (alongside disaster policy — read into that, what you will).

Ryder has worked in Schumer’s office for the last four years, primarily on climate change and energy issues. That’s not surprising, given he spent a previous four-year stint at the Climate Reality Project, an Al Gore-founded nonprofit organization working on climate change advocacy.

This may sound unkind, but Ryder is on a steep learning curve when it comes to AI policymaking. Luckily, Michael Kuiken, Schumer’s national security adviser, and Jon Cardinal, the senator’s director of economic development, have also been central to Schumer’s ongoing so-called AI Insight Fora.

**Are you a Pro Connect customer? Grab one of the last seats to join us on October 16 from 5:30 p.m. CEST in Brussels to hear from POLITICO’s Chief Brussels Correspondent Suzanne Lynch and Professor Anu Bradford, the Finnish author of “The Brussels Effect”, on the rivalry between the three dominant digital powers — the United States, China, and Europe — and how this will impact the future of the digital economy. Request your seat today.**

THEY SAID WHAT, NOW?

“The leaders will review the strong cooperation between the United States and the European Union,” according to a joint statement that confirmed the upcoming transatlantic summit on October 20. That meeting will almost exclusively focus on trade disputes, though there is an outside chance it could also double up as the U.S.-held Trade and Technology Council meeting, which had been planned for late 2023. They will “continue cooperation in critical and emerging technologies, including on digital infrastructure and artificial intelligence.”

WHAT I’M READING

— Confused about what’s going on in the U.S. vs. Google competition lawsuit? John Villaseñor has a primer for the Brookings Institute that has you covered.

— The use of AI-generated advertising that was personalized to individuals’ locations, tastes and online habits led to higher levels of vaccination rates when applied to COVID-19 issues, based on a study overseen by Rex Briggs, Stefanie Friedoff and Erik Lundberg published in the Management and Business Review.

— Beijing-linked groups are increasingly the covert disinformation campaigns or other online influence operations in ways that are more sophisticated, harder to detect and may be more effective than ever before, argues Sarah Cook for Freedom House.

— The U.S. Supreme Court will hear two cases related to whether First Amendment rights are violated via a new push to regulate social media. More details here and here.

— France has created a committee to advise on generative AI. Here’s who’s on that panel, what their remit will be, and what to expect in the months to come.

— Here’s another primer on how all the major platforms already approach content that has either been manipulated or generated by artificial intelligence. H/t Raquel Miguel for the EU Disinfo Lab.

**Unraveling the latest developments in defense policy, POLITICO Pro Defense goes live on October 10. Don’t miss a heartbeat on weapons technology, NATO, cyber and space or defense budgets. Receive its morning newsletter temporarily for free.**"
KPMG CEO Outlook: Hybrid working debate and ethics of gen AI - Technology Magazine,https://technologymagazine.com/articles/kpmg-ceo-outlook-hybrid-working-debate-and-ethics-of-gen-ai,"Thu, 05 Oct 2023 09:08:08 GMT",Technology Magazine,"Almost two-thirds of business leaders predict a full return to in-office working by 2026, according to KPMG’s annual survey of more than 1,300 CEOs of the world’s largest businesses.

The KPMG 2023 CEO Outlook survey, conducted in August and September of this year, also revealed that geopolitics and broader political uncertainty are the greatest risk to business growth today.

While confidence in the global economic outlook over the next three years remains broadly similar to last year (73% compared to 71% last year), there has been a shift across CEOs’ views on what constitutes a risk to their business.

“We know that what CEOs really want is certainty to support long term-business planning. And to stay ahead and build a stable business for the future, most are chasing that competitive edge for their firms and their clients, including better digitisation,” Jon Holt, Chief Executive of KPMG in the UK, said.

“Despite half of CEOs only expecting a return on investment in three to five years they are investing heavily in generative AI, while also sticking to their sustainability efforts and continually debating the return to office question.”

The debate over hybrid working and the return-to-office continues

CEOs are increasingly steadfast in their support of pre-pandemic ways of working, with 64% predicting a full return to in-office work within the next three years. And 87% of CEOs surveyed express a likelihood of linking financial reward and promotion opportunities to a return to in-office working practices.

“This isn’t a one-size fits all approach,” Holt commented. “And issuing an “all hands on deck” edict is a simple response to a complex issue – it won’t work for all businesses. Some sort of hybrid working is likely to remain a useful way to attract and retain the good people the CEOs know their business needs. Having the right employee value proposition to attract and retain talent is near the top of the priority list for CEOs in our survey.

“The wellbeing of younger colleagues is a particular issue here. They’re a generation whose early work experience has been defined by Covid and the cost-of-living squeeze. As leaders, we have a duty to nurture and support their careers and wellbeing. And spending at least some of their time in the office is likely to be good for those younger colleagues.

“There’s no denying that remote working v back to the office can create tensions between leaders and employees. These are big issues with big impacts on our lives. But CEOs hoping to return to an all-office world will have to work collaboratively and carefully with colleagues to get it right.”

CEOs continue to prioritise ESG despite polarising discourse

Despite a year of polarising debate surrounding the term ESG, CEOs recognise that delivering against the environmental, social and governance issues remains an integral part of their business operations and long-term corporate strategies. This is supported by 69% of CEOs who have embedded ESG into their business as a means of value creation.

Reflecting a shift in awareness and dialogue on ESG, 35% of CEOs have changed the language they use to refer to ESG both internally and externally. This signals a trend towards CEOs getting more specific about each aspect of the acronym and prioritising their efforts where they can have the most impact.

However, globally CEOs believe that they are still a few years away from seeing a return on their ESG investment. Those surveyed believe that ESG will have the greatest impact over the next three years on their customer relationships, brand reputation and M&A strategy."
"Bacardi, Boi-1da Embrace AI for 'Music Liberates Music' Project - Digital Music News",https://www.digitalmusicnews.com/2023/10/04/bacardi-and-producer-boi-1da-embrace-generative-ai-for-latest-music-liberates-music-project-we-can-revolutionize-the-music-industry-for-good/,"Wed, 04 Oct 2023 19:27:33 GMT",Digital Music News,"Bacardi and Producer Boi-1da Embrace Generative AI for Latest ‘Music Liberates Music’ Project: ‘We Can Revolutionize the Music Industry for Good’

Save

Bacardi has officially teed up the November release of The Concept A.I.bum, an EP that will attempt to demonstrate “how A.I. can be positively leveraged to provide emerging talent unprecedented opportunities.”

Bacardi rum, the namesake parent company of which also owns Grey Goose vodka, Patrón tequila, and a number of other brands, just recently announced the upcoming artificial intelligence effort. Of course, all manner of artists, among them Post Malone, Ellie Goulding, Halsey, Metro Boomin, and Jay-Z (who’s litigating against Bacardi), have inked sponsorship deals involving adult beverages and/or debuted alcoholic-drink companies of their own.

But Bacardi appears poised to become the first spirits company to incorporate AI into its music initiatives, with the much-publicized technology specifically set to drive an “evolution” of the Music Liberates Music program.

Now in its fifth year, the latter is described by Bacardi as a campaign “to champion underrepresented voices in the music industry.” Last year, Music Liberates Music rolled out “The Wearable Album,” billed as the “first QR-powered fashion capsule that rewards fans for promoting rising music artists.”

Back to the program’s newest project, the initially mentioned Concept A.I.bum centers on an ongoing partnership with Grammy-winning producer Boi-1da, who’s made available “a selection of beats from” his “unreleased catalogue” to train a generative-AI system.

Five acts, Adultsville artist Bellah, Position Music-signed rapper Blackway, U.S.-based R&B singers Floyd Fuji and Kyle Dion, and Canadian vocalist Savannah Ré, are expected to collaborate and ultimately release music with Boi-1da’s AI counterpart.

“Over several weeks,” Bacardi explained of the creative process, “each artist will feed their tracks into a state-of-the-art generative A.I. tool, which has been trained on a selection of beats from Boi-1da’s unreleased catalogue and will learn the sounds and cadence of his unique musical style.

“After submitting their demos to Boi-1da, each artist will work alongside him to refine their works, resulting in the EP’s final set of songs to be released this November,” continued the company.

On the compensation and rights fronts, “all proceeds from the project” – including streaming revenue and income from a limited-edition vinyl – “will directly benefit the participating artists,” who, along with Boi-1da, will retain “all copyright and subsequent revenue from the tracks,” per Bacardi.

Addressing the AI release in a statement, Bacardi rum marketing exec Laila Mignoni emphasized that “approaching this project with the utmost respect and protection for the artist was key in developing this new tool.” And Boi-1da, for his part, highlighted an ambitious vision for AI’s industry role so long as authorization and human contributions are prioritized.

“One of the most fulfilling responsibilities I have as a producer is to work with up-and-coming talent,” Boi-1da relayed in part. “Through the Concept A.I.bum, we’ve provided unprecedented access to my personal production style. I’m able to work with an international collective of artists simultaneously, while still honoring their creative autonomy.

“Music as an art has continually grown thanks to innovative technology, and with AI, I believe we can revolutionize the music industry for good if we view it as a way to provide opportunities that enhance music’s human element, rather than replace it,” he concluded.

Earlier this year, Grimes invited fans to create and release music with her AI soundalike, and the resulting Spotify artist page currently boasts over 105,000 monthly listeners. Meanwhile, logic and evidence suggest that the industry prevalence of artificial intelligence will spike dramatically during the remainder of 2023 and especially throughout 2024."
Fake Amazon calls and the use of generative AI highlight new ... - GeekWire,https://www.geekwire.com/2023/fake-amazon-calls-and-the-use-of-generative-ai-highlight-startups-phone-scam-report/,"Thu, 05 Oct 2023 13:00:00 GMT",GeekWire,"Worldwide, the average mobile phone user receives approximately 14 spam calls per month. (BigStock Photo)

Generative AI is playing an increasing role in phone scams, and fake calls related to Amazon accounts or purchases are among the leading scams in 2023. Those are two of the takeaways from the latest study on phone fraud and spam by Seattle startup Hiya.

Spam is defined as unwanted calls from non-contacts, and includes both fraud calls and nuisance calls.

In its report Thursday, Hiya said that in the first half of 2023, the phone security startup observed more than 98 billion incoming calls worldwide. Twenty percent of unidentified calls were flagged as spam, 5% as fraud, and 75% were not flagged. Worldwide, the average mobile phone user receives approximately 14 spam calls per month.

For the first time, Hiya’s study includes a list of the most common phone scams of the year, with calls related to Seattle-based e-commerce giant Amazon leading the way.

“Amazon impersonators may say they suspect an unauthorized purchase, or that the credit card linked to the account needs to be updated,” Hiya said in its report. “Often the scammers start with a robocall, and if the recipient falls for the scam and presses a number, a live operator will come on and try to get the victim to reveal their Amazon login information or a credit card number.”

(Hiya Graphic)

Other top phone scams, as tracked by Hiya, include those related to insurance, Medicare, credit cards, cryptocurrency, loved ones, payment apps, and auto warranties.

The rise of artificial intelligence and generative AI is also being noticed in phone scams worldwide, with voice clones being used to fool victims, Hiya reported.

AI-powered voice scams can take various forms, such as impersonating government officials, medical professionals, or service providers. By leveraging AI-generated voices, scammers can manipulate emotions, tone, and intonation, making it difficult for victims to detect the illegitimacy of the call.

Axios previously reported that “generative AI has lowered the bar for cybercriminals looking to clone someone’s voice and use it in their schemes. Cybercriminals now need as little as three seconds of someone’s voice to successfully clone it and make it usable in a scam call.”

Hiya said scammers can easily obtain a voice clip with audio from a person’s YouTube or other social media site, or even from a recorded greeting on a person’s voicemail. Often these voices are used in conjunction with scams directed at loved ones.

Earlier this year the King County Prosecuting Attorney’s Office warned residents in the Seattle area about a phone scam in which callers claimed to be law enforcement officers or King County Sheriff’s Office deputies."
It's a Three-Peat: Everest Group Names Amelia a Leader in ... - PR Newswire,https://www.prnewswire.com/apac/news-releases/its-a-three-peat-everest-group-names-amelia-a-leader-in-conversational-ai-three-years-in-a-row-301947307.html,"Wed, 04 Oct 2023 22:00:00 GMT",PR Newswire,"Amelia continues to pull away from the pack with its innovative and proven platform.

NEW YORK, Oct. 5, 2023 /PRNewswire/ -- Amelia, the world's largest privately held AI software company and a global leader in Enterprise Conversational AI, today announced that Amelia has been recognized as a Leader in Everest Group's Conversational AI Products PEAK Matrix® Assessment 2023. This marks the third consecutive year that Everest Group has recognized Amelia as a Leader, reinforcing Amelia's ongoing commitment to developing AI solutions that go beyond the hype and deliver true enterprise value. Organizations including Telefónica and BNP Paribas rely on Amelia's AI solutions for critical internal and customer-facing tasks, and today's news closely follows the announcement that global airline Aeromexico has selected Amelia to manage its customer service channels.

This PEAK Matrix assessment is based on Everest Group's evaluation of the Vision & Capability and Market Impact of more than two dozen global Conversational AI technology vendors. The results of the evaluation inform the classification of each vendor into one of three categories: Leaders, Major Contenders and Aspirants. Based on these criteria, Amelia has been named a Leader in Conversational AI and holds the highest overall position in the PEAK Matrix across both axes.

Among the 25 vendors evaluated, Amelia is one of only two vendors recognized as a top provider across all major industries, including Banking, Healthcare, Telecom, Insurance, Technology and Retail. Amelia is also a top provider across several major business functions, such as IT Helpdesk, Customer Support, Sales, and Finance and Accounting.

Everest Group also recognized several key strengths of Amelia's Conversational AI platform, such as its use of Generative AI:

The platform automatically suggests modifications and creates new workflows based on real-time conversations, call transcripts and interactions with Generative AI Models to create fully functional prototypes and more, all without human intervention. Buyers regularly recognize Amelia's focus on innovation as a key strength.

The platform offers a low-code experience for clients to build functional, multi-channel solutions that are tailored to their specific industry requirements.

The platform digitally orchestrates and executes end-to-end processes across IT systems and applications.

With each annual assessment, Amelia pulls further ahead of other providers in the Conversational AI vendor landscape. Notable in this report is Amelia's leap forward in Vision & Capability, which evaluates a vendor's ability to successfully deliver products to market.

Amelia prides itself on taking AI from experimental to exceptional for enterprises, driving measurable business outcomes. For example, Resorts World Las Vegas fully automated more than 2,500 guest check-outs in one month using Amelia's Conversational AI platform, helping to increase guest satisfaction and offload administrative work from resort employees.

""It's an honor to be recognized by research powerhouse Everest Group as a Leader in Conversational AI,"" said Lanham Napier, President and Chairman of Amelia. ""Day in and day out, our global team puts in a huge effort to better serve our customers with a powerful, intuitive platform that delivers incredible outcomes, as evidenced by improved NPS scores, increased employee and customer retention, and cost savings. This recognition of our efforts is one that we are extremely proud of, and it pushes us to continue advancing our cutting-edge platform and keep moving towards our ambitious goals.""

To download the Everest Group report, click here.

About Amelia

Amelia is one of the world's largest privately held AI software companies and a global leader in Enterprise Conversational AI. The company's technology is trusted by organizations across an array of industries to automate operations, improve customer experience and optimize business outcomes. Amelia's platform develops and deploys AI tools that manage critical tasks and processes, enabling employees to be more productive and deliver better results while reducing operational costs. Consistently recognized by third-party analyst firms including Gartner's Magic Quadrant 2023 as a market leader, Amelia has powered the voice operations of global Fortune 500 leaders including Telefónica, BBVa and BNP Paribas. Backed by strategic investments from the Build Group and Monroe Capital, Amelia is headquartered in New York City and serves customers globally through offices throughout the US, Europe and Asia Pacific.

Media Contact:

[email protected]

Logo - https://mma.prnewswire.com/media/2038301/Amelia_Logo_B_Logo.jpg

SOURCE Amelia"
AWS Announces Powerful New Offerings to Accelerate Generative ... - Datanami,https://www.datanami.com/2023/10/04/aws-announces-powerful-new-offerings-to-accelerate-generative-ai-innovation/,"Wed, 04 Oct 2023 20:02:38 GMT",Datanami,"While the seeds for the machine learning paradigm shift have existed for several decades, it is only recent advancements in ML technologies that have allowed organizations to transform their business. ML technologies help power generative AI applications, which have captured everyone’s imagination and organizations are looking for innovative ways to use this technology to reimagine how they solve problems and create new user experiences.

Amazon Web Services (AWS), one of the world’s leading cloud platforms, announced generative AI innovations to help organizations build new AI applications, enhance employee productivity, and transform their business. It will also help simplify development while maintaining security.

A key component of the announcement is the general availability of Amazon Bedrock, which was introduced in April 2023. Amazon Bedrock is designed to be a fully managed service that makes pre-trained foundation models from leading AI companies accessible through a single API. It offers serverless integration with AWS capabilities, allowing organizations to find the right tools and customer them according to their needs.

Swami Sivasubramanian, vice president of Data and AI at AWS, shared his views on the announcements, “With enterprise-grade security and privacy, a choice of leading FMs, a data-first approach, and our high-performance, cost-effective infrastructure, organizations trust AWS to power their businesses with generative AI solutions at every layer of the stack. Today’s announcement is a major milestone that puts generative AI at the fingertips of every business, from startups to enterprises, and every employee, from developers to data analysts. With powerful, new innovations, AWS is bringing greater security, choice, and performance to customers, while also helping them to tightly align their data strategy across their organization, so they can make the most of the transformative potential of generative AI.”

AWS also announced that Amazon Tital embedding models are now generally available and that Meta’s Llama 2 will also be available as a new model. This makes Amazon Bedrock the first platform to offer a fully managed service to access Llama 2 through an API. The Titan foundation models include a large natural language model for text generation tasks and an embedding model to help with personalized recommendations. The combination of other leading foundation models will further enhance the capabilities.

The goal of having multiple foundation models available is to allow customers to discover what works best for them. Amazon Bedrock will include foundation models from Cohere, Meta, AI21 Labs, Stability AI, and Anthropic, all via a single API.

In the announcement, AWS also introduced a new capability for Amazon CodeWhisperer. This is AWS’s AI-power coding companion. Developers can customize the CodeWhisperer suggestions based on their existing codeback. This will help boost developer productivity. There is a professional tier for the CodeWhisperer for business users that need advanced features such as access management integration and single sign-on (SSO) with AWS identity.

AWS is also releasing a preview of Generic Business Intelligence (BI) to help boost business analytics productivity. This new feature will offer authoring capabilities for Amazon QuickSight, which is a cloud-powered business analytics service that can create visuals and perform calculations by simply describing what is needed in natural language.

With the announcement of several powerful new offerings to accelerate AI innovation, AWS further reinforces its position as one of the leading platforms to host generation AI apps. Amazon has already invested heavily in creating generation AI solutions. Earlier this year, it announced a $100 million program called the AWS Generative AI Innovation Center to build and deploy AI solutions. With the generative AI market expected to continue growing, there are endless possibilities for what this technology can do.

Related Items

Amazon Bedrock: New Suite of Generative AI Tools Unveiled by AWS

Salesforce and AWS Deepen Generative AI Partnership with Harmonized Customer Profile Offerings

Amazon to Invest Up to $4B in Anthropic to Advance Generative AI"
Zapata AI and Mila Partner to Elevate Generative Modeling ... - Business Wire,https://www.businesswire.com/news/home/20231005260317/en/Zapata-AI-and-Mila-Partner-to-Elevate-Generative-Modeling-Research-for-Industrial-Use-Cases,"Thu, 05 Oct 2023 12:00:00 GMT",Business Wire,"BOSTON--(BUSINESS WIRE)--Zapata AI, the Industrial Generative AI company, today announced its partnership with Mila – Quebec AI Institute, the world’s largest academic deep learning research center. This collaboration will contribute to the development of advancements in various areas of machine learning and quantum algorithms and bolster the value that can come from these innovative technologies.

“We’re thrilled to partner with an institute with such a longstanding reputation for innovation in the field,” said Yudong Cao, CTO and co-founder at Zapata AI. “Quantum algorithms running on classical computers can deliver tangible value for generative AI applications today, particularly those that are time consuming and expensive to run. We’re looking forward to working with Mila researchers to refine these algorithms and help our enterprise customers run their generative AI models faster, cheaper, and at a wider scale — both for language-based applications and those involving numerical or time-series data.”

Together, Zapata AI and Professor Guillaume Rabusseau, Assistant Professor at Université de Montréal and Canada CIFAR AI Chair, alongside other members of the Mila community, will vastly broaden their resources and deep research capabilities that support the development of generative AI applications for industries such as life sciences, financial services, discrete manufacturing, and heavy machinery. With these combined efforts, the teams are aiming to discover new potential AI applications and mathematical formulations that could help enterprises solve complex business problems.

“This partnership with Zapata AI allows some of our researchers to combine emerging quantum and quantum-inspired techniques with state-of-the-art classical methods,” said Stéphane Létourneau, Executive Vice-President of Mila. “With our overlapping interests in core areas including health, environment and climate change, and AI ethics, our collaboration was a natural fit.”

In the coming weeks, Zapata AI and Mila will publish the first research paper born from their collaboration, which builds on Zapata AI’s previous research on quantum-inspired generative models. The research enables these models to learn from data on continuous variables, which include images, time-series data, and real-world sensor data. These variables are common in industrial problems and this research could be applied to generate new and improved solutions to these problems.

About Mila:

Founded by Professor Yoshua Bengio of the University of Montreal, Mila is an artificial intelligence research institute that brings together over 1,200 researchers specializing in machine learning. Based in Montreal, Mila’s mission is to be a global hub for scientific advances that inspire innovation and development of AI for the benefit of all. Mila is a non-profit organization recognized worldwide for its significant contributions to the field of deep learning, particularly in language modeling, machine translation, object recognition, and generative models. For more information, visit mila.quebec.

About Zapata AI:

Zapata AI is the Industrial Generative AI company, revolutionizing how enterprises solve their hardest problems with its powerful suite of Generative AI software. By combining numerical and text-based solutions, Zapata AI empowers enterprises to leverage large language models and numerical generative models better, faster, and more efficiently—delivering solutions to drive growth, savings and unprecedented insight. With proprietary science and engineering techniques and the Orquestra® platform, Zapata AI is accelerating Generative AI’s impact in Industry. The Company was founded in 2017 and is headquartered in Boston, Massachusetts. On September 6, 2023, Zapata AI entered into a definitive business combination agreement with Andretti Acquisition Corp. (NYSE: WNNR), the consummation of which, subject to customary closing conditions, will result in Zapata AI becoming a publicly listed company on the New York Stock Exchange. To learn more, visit: https://www.zapata.ai

Forward-Looking Statements

Certain statements made herein are not historical facts but are forward-looking statements for purposes of the safe harbor provisions under The Private Securities Litigation Reform Act of 1995. Forward-looking statements generally are accompanied by words such as “believe,” “may,” “will,” “estimate,” “continue,” “anticipate,” “intend,” “expect,” “should,” “would,” “plan,” “predict,” “potential,” “seem,” “seek,” “future,” “outlook,” and similar expressions that predict or indicate future events or trends or that are not statements of historical matters. These forward-looking statements include, but are not limited to, statements regarding future events, the transaction, the estimated or anticipated future results and benefits of the combined company following the transaction, including the likelihood and ability of the parties to successfully consummate the transaction, future opportunities for the combined company, and other statements that are not historical facts. These statements are based on the current expectations of Andretti Acquisition Corp.’s and Zapata AI’s management and are not predictions of actual performance. These forward-looking statements are provided for illustrative purposes only and are not intended to serve as, and must not be relied on, by any investor as a guarantee, an assurance, a prediction, or a definitive statement of fact or probability. Actual events and circumstances are difficult or impossible to predict and will differ from assumptions. Many actual events and circumstances are beyond the control of Andretti Acquisition Corp. and Zapata AI. These statements are subject to a number of risks and uncertainties regarding Zapata AI’s businesses and the transaction, and actual results may differ materially. These risks and uncertainties include, but are not limited to, ability to meet the closing conditions to the transaction, including approval by stockholders of Andretti Acquisition Corp. on the expected terms and schedule and the risk that regulatory approvals required for the transaction are not obtained or are obtained subject to conditions that are not anticipated; delay in closing the transaction or failure to close the transaction within the period permitted under its governing documents; failure to realize the benefits expected from the proposed transaction; a decline in the price of Andretti Acquisition Corp’s securities following the transaction if it fails to meet the expectations of investors or securities analysts; the amount of redemption requests made by Andretti Acquisition Corp.’s public stockholders; the ability of Andretti Acquisition Corp. or the combined company to issue equity or equity-linked securities in connection with the transaction or in the future; the effects of pending and future legislation; risks related to disruption of management time from ongoing business operations due to the proposed transaction; business disruption following the transaction; risks related to Andretti Acquisition Corp.’s and Zapata AI’s indebtedness; other consequences associated with mergers, acquisitions, and divestitures and legislative and regulatory actions and reforms; Zapata’s ability to maintain its current rate of growth; maintenance and renewal of customer contracts and subscriptions; competition in Zapata AI’s industries; Zapata AI’s ability to raise additional capital; the successful integration of potential targets, products, or technologies; Zapata AI’s ability to improve its operational, financial, and management controls; Zapata AI’s failure to maintain and enhance awareness of its brand; increased costs associated with being a public company; cybersecurity incidents; ability to prevent fraudulent activities by Zapata AI’s customers, employees, or other third parties; potential interruptions or delays in third-party services; protection of proprietary rights; intellectual property infringement, data protection, and other losses; compliance with federal, state, and local laws as well as statutory and regulatory requirements; risks of implementing controls and procedures required for public companies following the transaction; and the ability of Zapata AI’s or the combined company to issue equity or equity-linked securities with the proposed business combination or in the future; and those factors discussed in Andretti Acquisition Corp.’s Form 10-K for the year ended December 31, 2022, under Risk Factors in Part I, Item 1A and other documents of Andretti Acquisition Corp. filed, or to be filed, with the SEC.

If any of these risks materialize or if assumptions prove incorrect, actual results could differ materially from the results implied by these forward-looking statements. There may be additional risks that Andretti Acquisition Corp. or Zapata AI presently do not know or that Andretti Acquisition Corp. or Zapata currently believe are immaterial that could also cause actual results to differ from those contained in the forward-looking statements. In addition, forward-looking statements provide Andretti Acquisition Corp.’s or Zapata AI’s expectations, plans, or forecasts of future events and views as of the date of this communication. Andretti Acquisition Corp. or Zapata AI anticipate that subsequent events and developments will cause their assessments to change. However, while Andretti Acquisition Corp. or Zapata AI may elect to update these forward-looking statements at some point in the future, Andretti Acquisition Corp. or Zapata AI specifically disclaim any obligation to do so. These forward-looking statements should not be relied upon as representing Andretti Acquisition Corp.’s or Zapata AI’s assessments as of any date subsequent to the date of this communication. Accordingly, undue reliance should not be placed upon the forward-looking statements."
AI Startup Anthropic in Early Talks With Investors to Raise $2 Billion - Yahoo Finance UK,https://uk.finance.yahoo.com/news/ai-startup-anthropic-early-talks-183458512.html,"Wed, 04 Oct 2023 20:14:57 GMT",Yahoo Finance UK,"(Bloomberg) -- Artificial intelligence startup Anthropic is in early talks to raise $2 billion, shortly after Amazon.com Inc. agreed to invest up to $4 billion in the company, people familiar with the matter said.

Most Read from Bloomberg

The deal, which has not yet been finalized, represents an industrywide rush to claim a piece of Silicon Valley’s AI boom.

The valuation for Anthropic has not yet been set, said the people, who asked to remain anonymous discussing private conversations. Tech news site the Information earlier reported on the company’s fundraising efforts, and said that a deal could value Anthropic at as much as $30 billion.

If the funding round closes, it would be the latest huge financing for a startup building so-called foundation models, which take in large amounts of data to provide the basis of many AI tools. The models are extremely expensive to operate, meaning startups like Anthropic and its competitor OpenAI need ample resources to keep the technology running.

The talks also represent a scramble by large tech companies to get a stake in the future of artificial intelligence. Earlier this year, Alphabet Inc.’s Google participated in a $450 million funding round for Anthropic. And in September, Amazon said that in addition to funding the startup, it would be Anthropic’s primary cloud computing provider and would supply chips. Meanwhile Microsoft Corp. has agreed to put more than $10 billion into OpenAI, a rival to Anthropic in generative AI.

Read More: Amazon to Invest Up to $4 Billion in AI Startup Anthropic

Anthropic’s corporate investors are eager to continue backing the startup, one person familiar with the talks said, but it’s possible the deal won’t close until a financial investor, such as a Wall Street firm or large venture capital investor, agrees to participate. That investor could be called on to determine the company’s valuation and lead the round.

Story continues

Founded in 2021 by former employees of OpenAI, Anthropic has positioned itself as being especially focused on responsible and safe technology. Its chatbot, Claude, is meant to be a kinder and gentler kind of AI, and can perform written tasks like summarizing, searching, answering questions and coding.

(Updates with context starting in the third paragraph.)

Most Read from Bloomberg Businessweek

©2023 Bloomberg L.P."
Atropos unveils generative AI to accelerate clinical insights - FierceHealthcare,https://www.fiercehealthcare.com/health-tech/real-world-data-startup-atropos-health-unveils-generative-ai-accelerate-clinical,"Thu, 05 Oct 2023 17:10:00 GMT",FierceHealthcare,
Why Microsoft won't be the company to mainstream generative A.I. - Windows Central,https://www.windowscentral.com/microsoft/why-microsoft-wont-be-the-company-to-mainstream-generative-ai,"Thu, 05 Oct 2023 12:00:16 GMT",Windows Central,"Microsoft's all in on AI, just like it was all in on the metaverse last year, and Windows Phone a few years earlier.

I feel like we've been here before. Microsoft has a huge opportunity with something truly innovative, something potentially pivotal for how humans interact with computers, and I already see the pattern emerging before my eyes.

Humans are hard-wired to recognize patterns. If you follow Microsoft as long as we all have here, as well as you guys reading this — you might be right to have a bit of skepticism over how Microsoft's OpenAI partnership might play out.

Microsoft has been in court this week, summoned by the FTC to discuss Google's search monopoly. Some of the comments made there had me wondering exactly just how far Microsoft aims to go with its OpenAI partnership. Is this just another flash-in-the-pan attempt, in vain, to take on Google's search dominance? Does Microsoft really expect that it can change user behavior with only Windows as its sole consumer destination?

Here are some reasons why I don't think it will be Microsoft (but more likely Google or Apple) who mainstreams generative AI with consumers.

No vision for AI in hardware

The Harman/Kardon Invoke would've been great for Bing Chat and Windows Copilot. (Image credit: Future)

The first thing I thought when I saw Windows Copilot launching was, ""oh wow, I wish this was on my Cortana Invoke."" You'd be forgiven for not knowing wtf the Cortana Invoke is.

The Cortana Invoke from Harman Kardon was an ill-fated partnership between Microsoft and the audio company to build a premium competitor to Amazon's Echo smart speakers, powered by Cortana. Cortana was Microsoft's virtual assistant app baked into Windows Phone 8.1 and later other platforms, and was eventually abandoned along with Windows Phone later on. Cortana was essentially an endpoint for Bing with a fun interface, and it was cool when it launched, and there was a clear vision that one day it could be similar in power to the current iterations of ChatGPT. However, of course, it was not meant to be.

Right now, the only way to access Microsoft's version of ChatGPT is via Bing, a website that only has 3% of global search market share per Microsoft's own admissions. Bing's search queries make my Amazon Echo speaker seem like a Stone Age tool by comparison, and it's almost insulting how dumb Alexa is compared to Bing. But ... I don't always have my laptop on. Hell, I don't always have access to my phone either. How seamless would it be to just ask questions to a handy nearby assistant who listens when prompted?

Unfortunately, Microsoft no longer has access to this kind of endpoint. Amazon is developing its own generative AI systems, and most likely wouldn't be interested in allowing Microsoft to further entrench itself.

There are rumors that Jonny Ive of Apple fame is potentially exploring hardware ventures with OpenAI, too. Why isn't Microsoft exploring this? Why has Microsoft given up its top hardware innovator in Panos Panay to Amazon just last week?

It's the devices we carry around with us all day, every day, that would've been best for Bing Chat AI adoption. Alas, Microsoft has little chance of making gains there either.

Limited control over the ""defaults""

Microsoft has a long history of failure on Android, owing to Google setting its services as the ""default."" (Image credit: Daniel Rubino)

Google is currently being hammered by the U.S. Federal Trade Commission over its ""monopoly"" in search. Google enjoys a whopping 92.47% market share globally, challenged (and I use that word loosely) only by state-backed alternatives, and Microsoft's Bing.

Google's search platform is objectively superior to Bing. For general queries, Bing can come close to Google, but the lack of data (from users, you know, not using it) has backed Bing into an endless loop of ""low users means low quality means low users."" During the hearings with the FTC, Microsoft CEO Satya Nadella described how difficult it has been for Microsoft to put a dent in Google's market share, owing to how Google buys up exclusive and lucrative ""default"" positions on major smartphone platforms, including Apple's iOS, Samsung Galaxy, and others.

The rise of Google Chrome also allowed Google to entrench its position further, since Google is naturally the ""default"" search engine on that web browser. The vast, vast majority of users do not change the defaults, even if they are able to do so, because ""why bother?"" The untrue rumor that Samsung was considering dropping Google for Bing earlier this year hit Google's share price, which is a reflection of how crucial these default positions are.

I use Bing begrudgingly for the rather generous Microsoft Rewards points that let me grab free Overwatch 2 battle passes. And honestly, Bing seems to know me well enough to offer good results for basic queries. However, if you stray into more complex queries, granular queries, historical questions, or crucially, local searches — Bing completely falls apart. Bing simply doesn't have access to the necessary data.

Apple, Samsung, and others don't want to compromise their user experiences by going with an objectively inferior product, regardless of how much money Microsoft offers. Microsoft, however, does control one endpoint, obviously, and that's on Windows 11.

I'm not confident that the data set Microsoft can absorb from user behavior on PC will help it mainstream its platform with consumers before Google potentially could, or Apple potentially could, owing to their control of mobile computing. There's an air of assumption here, but my gut tells me user habits on PC are simply very different from that of mobile. Despite baking Copilot (Microsoft's disguised Bing AI assistant) directly into the Windows shell, people still default their search engines to Google, at the end of the day. Features like Live Tiles, Microsoft Edge, or even Cortana herself prove that simply baking something into the shell doesn't guarantee interaction. Google has been very adept at changing user behavior through Android, though, with features like Google Discover.

Google in particular is far too dominant over the analysis of web data, and as publishers and other creators seek to close down access to their data for generative AI models, how exactly does Microsoft hope to compete with Google for access?

No leverage with creators, or publishers

MSN is tiny compared to Google News. Why would publishers want to work with Microsoft over Google? (Image credit: Kevin Okemwa)

During the FTC hearings, CEO Satya Nadella also remarked that he's already heard of platforms exploring charging Google, Microsoft, and other generative AI platforms for access to their data sets. Certain commentators and platforms have already kicked up a stink over how OpenAI and others simply ""took"" data en masse across sites like Reddit and Twitter. Even here, we've had internal discussions off the cuff about how our content across our company has been adopted and ""borrowed"" by Bing and others, to produce its results. Bing doesn't compensate us for this, although Microsoft's Yusuf Mehdi previously discussed a vague ""plan"" to do so ... someday. Maybe.

Disregarding the fact that ChatGPT etc. will get dumber if sites like ours get put out of business by their actions, bigger players like Reddit may simply opt out of giving these platforms access to the data they use to train their models. The EU is aggressive at defending user privacy, and may also eventually give users the ability to opt-out of having their interactions used in this way.

Either way, in a world where major platforms close themselves off to generative AI models and their web crawlers, Google is far better placed to get access to these platforms again. Google has more leverage over publishers owing to its search monopolies across both Google Search, Google News, and YouTube. Microsoft bailed on Mixer before it could get going, and MSN's (Microsoft News) user base is minuscule compared to Google News. Google has a far bigger advertising platform, and thus perhaps has far better means to compensate creators than Microsoft, should it ever come to that.

Even if ChatGPT-powered Bing has superior technology, there's a huge question mark over whether Microsoft has the leverage, or search volume, to maintain dataset quality long-term.

Microsoft will succeed with B2B use cases, but lack of foresight has already cost it consumers

(Image credit: Windows Central)

Microsoft will find success in AI, and already has. GitHub and Visual Studio's code assistance scenarios are already helping programmers, and generative AI has uses in corporate scenarios for creating meeting notes, summarizing email chains, and the like. Perhaps business-to-business scenarios are more lucrative than consumer-oriented ones, too, anyway. Amazon's Alexa business has notoriously been a multi-billion dollar black hole, and that's without having an electricity-intensive AI backing up the queries. But I think the chips are heavily stacked against Microsoft when it comes to consumers.

Nobody is using Bing, despite the fact you can generate dumb images with its DALL-E access. Accessing Bing for even the most basic ChatGPT-enabled stuff requires changing a change in an individual user's behavior. As soon as Google starts baking this stuff into its phones while forcing it on Android OEMs, I feel like Microsoft will have immediately lost the entire consumer market.

""The distribution advantage Google has today doesn’t go away; in fact, if anything, I worry a lot that – even in spite of my enthusiasm that there is a new angle with A.I., this vicious cycle that I’m trapped in could get even more vicious."" Microsoft CEO, Satya Nadella, to the FTC

AI is still early days, and Microsoft clearly saw it as a key way to differentiate itself from Google. Google pivoted hard, though, and is catching up quickly to offer the same features. Beyond this, though, is a question of how exactly this will function as a business. ChatGPT and DALL-E cost hundreds of thousands of dollars per day to run, and with scale comes cascading costs. How exactly does Microsoft aim to monetize these features, to pay for them? It's far beyond Amazon's Echo conundrum, and Bing doesn't have the mammoth-esque Google Ads business to speak of.

When Microsoft gave up on Windows Phone, it effectively gave up its future in this space. These new paradigms demand changes in user behavior, and furthermore, changes in user behavior for users Microsoft doesn't even have. Outside a few examples, Microsoft has proven repeatedly over the years that it's largely incapable of committing the resources necessary to see these kinds of things through. I expect Bing Chat and Copilot to have a similar trajectory to many other familiar Microsoft efforts — incredible innovations that lack the vision and commitment to find their true potential while being adapted and mainstreamed more quickly by their more passionate, consumer-savvy competitors.

For the sake of breaking Google's monopoly, I sure hope I'm wrong."
Thought Industries Expands AI Capabilities to Power the Business of ... - AiThority,https://aithority.com/machine-learning/thought-industries-expands-ai-capabilities-to-power-the-business-of-learning/,"Thu, 05 Oct 2023 08:41:34 GMT",AiThority,"The Use of Generative AI in the Ti Platform Builds on Years of Company Experience Using Machine Learning to Create Personalized, Differentiated Learning Experiences.

Thought Industries, the leading external enterprise learning platform for customer, partner and professional training announced a range of powerful new and enhanced AI capabilities during its Product Keynote at COGNITION23, designed to harness the power of generative AI within the Ti Enterprise Learning Cloud.

Thought Industries, which recently celebrated its 10th anniversary and surpassed 21 million active learners, demonstrated these new products to complement its existing approach to AI and machine learning, further enabling its customers to create modern experiences for admins and learners alike.

Recommended: AiThority Interview with Matthew Tillman, Co-Founder and CEO at OpenEnvoy

“Our customers have enjoyed the benefits of machine learning within the Thought Industries platform for some time now,” said Barry Kelly, Thought Industries CEO. “With generative AI, we see the opportunity to give our customers some new super powers, including time saved creating content and designing courses, the ability to offer near real-time, personalized feedback and content recommendations that will help set a new standard in the creation and delivery of modern, exceptional learning experiences.”

Thought Industries sees the game-changing opportunity of generative AI being incorporated into its platform in four main ways:

Accelerating Content Generation: Adding a generative and prompt-based element to make content creation even easier in the Ti platform, accelerating content production timelines for training materials & assessments.



Decreasing Operational Friction: AI-powered site design and building is designed to deliver engaging and compelling learner experiences, and will change the game when it comes to reducing development and production time. This no-code building functionality means customers can easily optimize web and mobile experiences solely through an AI-powered prompt interface.



Personalizing Coaching at Scale: With AI-powered video assessment, all learners can receive speedy feedback and coaching that are truly helpful (including notes on soft skills), while experts and instructors spend their time only in the areas where they will have the most impact.



Serving Highly Relevant Content: A key component of the Thought Industries technology has always been the ability to make learning as relevant, personalized and close to the moment of need as possible. Ti’s recommendation engine and machine learning algorithms are a critical part of its vision of AI in learning technology.

AiThority Interview Insights : AiThority Interview with Kelly Eliyahu, Senior Director of Product Marketing at Salesforce

Data privacy and security are paramount concerns for customers, and Thought Industries’ generative AI features are engineered with the utmost consideration for data protection. The company prioritizes privacy and ensures that customer data remains confidential and secure. No customer data will be used to train AI models, safeguarding customer information and intellectual property.

“We are incredibly excited to share what’s next in the Thought industries product at Cognition 2023,” said Chief Product Officer, Todd Boes. “The promise and opportunity of generative AI builds on the solid foundation of machine learning currently available in the Ti platform. We think we’re in a unique position to partner with our customers to help them make good use of these new innovations, while keeping their data and security top of mind.”

Recommended: Balancing AI and Human Insight in Content Marketing

[To share your insights with us, please write to sghosh@martechseries.com]"
AI bias must move to accountability to address inequity - Policy Options,https://policyoptions.irpp.org/magazines/october-2023/ai-bias-accountability/,"Wed, 04 Oct 2023 18:08:03 GMT",Policy Options,
Amazon planning major revamp that will change search experience - Search Engine Land,https://searchengineland.com/amazon-revamp-change-search-experience-432913,"Wed, 04 Oct 2023 21:09:00 GMT",Search Engine Land,"Amazon is gearing up for a significant overhaul that will transform the search experience across both its website and app.

The retail giant is set to roll out upgraded generative AI capabilities that offer a more conversational, detailed, and personalized user experience in the US from January.

Shoppers will be able to use this new technology for real-time product comparisons and to seek additional details, reviews, and recommendations tailored to their search context, reports Business Insider.

Why we care. Advertisers should closely monitor these developments to gauge their impact on ad visibility. Should the changes prove to be as substantial as claimed, digital marketers may need to reassess their campaign strategies accordingly.

A new world. The decision to revamp Amazon, which has been codenamed Project Nile, reportedly comes from new VP Joseph Sirosh, a former Microsoft AI executive. During a company-wide presentation, he told his team:

“We have a big task ahead of us. We need to orient everyone towards this new world.”

The new Amazon is allegedly already being tested internally with plans for a US roll out in the New Year, however, an insider confirmed these plans could change. The project is a top priority for the company and is being supported by Amazon CEO Andy Jassy.

Why now? Amazon bosses are hoping that building an AI-powered conversational shopping agent will help improve the user experience, helping shoppers to find the products they’re looking for more easily by providing search results, expert answers and product suggestions. The company is hoping this will lead to more sales and a higher ROI – particularly on mobile.

How it works. Amazon’s new generative AI tool will be developed using human AI trainers, who will continuously review the quality of answers the bot provides. Additionally, the tool will have access to proprietary shopping data sourced from Amazon’s extensive product catalog, complemented by user behavior data, and purchase and review information.

Get the daily newsletter search marketers rely on. Processing…Please wait. SUBSCRIBE See terms.

What has Amazon said? During a company-wide town hall meeting, Sirosh told Amazon staff that the website's new AI feature should be seen as a deeply knowledgable in-store salesperson. He said:

""Before e-commerce, the salesperson in the store was your search engine. And that individual knew everything about the products…they would look at you and know what you might want because customers like you have been to that store before.""

""They may have known you in person, so may know your preferences, and then they can synthesize all of that information together in natural language conversation with you and help you in your shopping mission. And if you can scale that up to everything in Amazon, that would be the future mission we want to aspire to.""

""If we can increase the conversion on mobile, because we provide great experiences, great expert answers, then that could be a potentially significant lift to Amazon.""

Deep dive. Read the Amazon Ads blog to catch up on the company's latest news."
CommerceIQ Launches Generative AI Powered Google Chrome Extension in time for Amazon’s Prime Big Deal Days 2023 - Yahoo Finance,https://finance.yahoo.com/news/commerceiq-launches-generative-ai-powered-130000459.html,"Thu, 05 Oct 2023 13:00:00 GMT",Yahoo Finance,"CommerceIQ

Free Browser Extension Helps Brands Boost Search Visibility on Amazon and Improve Customer Satisfaction Through AI-driven Content Suggestions and Sentiment Analysis

PALO ALTO, Calif., Oct. 05, 2023 (GLOBE NEWSWIRE) -- CommerceIQ, the leading retail ecommerce management (“REM”) platform, today announced it has opened public access to its Google Chrome browser extension CommerceIQ Insights, which allows brands to understand their metrics while browsing Amazon and harnesses the power of generative AI to recommend content suggestions and analyze customer sentiment for any Amazon product.



Previously available on a waitlist basis, but now available for free to the entire ecommerce community, the CommerceIQ Insights Chrome extension enables Amazon sellers to elevate their online strategy, make data-driven decisions, and stay ahead of the competition leading into key tentpole events like Prime Big Deals Day and Black Friday Cyber Monday.

""Our new Chrome extension is not just a tool, it's a core component to a modern operators toolset on Amazon, and we're thrilled to bring the power of generative AI to the entire ecommerce community,"" said Guru Hariharan, CEO of CommerceIQ. ""Our customers have been using this to A/B test content strategies and quickly bring product feedback to their org. By making it freely available, we're further empowering brands to thrive in the dynamic world of retail ecommerce management.""

“Cultivating customer insights through CIQ’s Amazon review sentiment analysis is like peering through a window into the hearts of your buyers,” said Caleb Harley, director of marketplace services at Booyah Advertising. “With this invaluable tool, you can not only tailor your product content to address all feedback but also strategically position your product to define the perfect market fit, ensuring your journey to success is paved with informed decisions.”

“The Chrome plugin is the most-used tool in our portfolio,” said Jameson Lee, national account manager at Funrise. “By providing real-time metrics for any ASIN in our catalog, we can quickly validate, review, and then act without having to compare multiple inputs or dashboards. It generates efficiencies and significantly streamlines our daily workflow.”

Story continues

Key features and benefits of the CommerceIQ Insights Chrome extension include:

GenAI-Powered Optimization: Harnessing the power of generative AI, the extension provides suggestions to enhance product titles and descriptions on Amazon, ensuring optimal search visibility and higher conversion rates.

Deep Customer Sentiment Analysis: Brands can now dive deep into ratings and reviews, extracting key themes of positive and negative sentiment, enabling a more tailored approach to product offerings and marketing strategies.

SKU-Level Performance Insights: With Vendor Central access, brands can also get a comprehensive view of key metrics including sales, fill rate, and ad spend, ensuring strategic decision-making to maximize revenue and profitability.



The CommerceIQ Insights Chrome extension works on any product being sold on Amazon, whether yours or a competitor’s. Its sentiment analysis engine has been fully refreshed, giving users insights across various product dimensions, including features, price, packaging, competitors and shipping. These insights are based on the latest reviews posted on Amazon, giving users a 360-degree view of shopper feedback.

For more information and to get started with CommerceIQ Insights, visit the Chrome Web Store .

About CommerceIQ

CommerceIQ is the leading retail ecommerce management (REM) platform for consumer brands to plan, monitor and execute their businesses and profitably grow market share across 850+ global online retailers. CommerceIQ’s unified REM platform brings together every aspect of a brand’s retail ecommerce business: sales and operations, retail media management, content management, and digital shelf optimization, to create a single source of truth. CommerceIQ’s machine learning and automation enable brands to connect organizational silos, power team efficiencies, and drive measurable sales impact. More than 2,200 brands globally, including Nestle, Colgate, and Whirlpool, trust CommerceIQ to manage and grow their retail ecommerce businesses across global retailers including Amazon, Walmart, and Instacart. For more information, visit https://www.commerceiq.ai .

BOCA Communications for CommerceIQ

CommerceIQ@bocacommunications.com



"
Generative AI's Intersection With the Metaverse: Tech Disruptors - Bloomberg,https://www.bloomberg.com/tosv2.html?vid=&uuid=b4d52a55-63a4-11ee-a15f-7264b95b3cf8&url=L25ld3MvYXVkaW8vMjAyMy0xMC0wNS9nZW5lcmF0aXZlLWFpLXMtaW50ZXJzZWN0aW9uLXdpdGgtdGhlLW1ldGF2ZXJzZS10ZWNoLWRpc3J1cHRvcnM=,"Thu, 05 Oct 2023 12:40:08 GMT",Bloomberg,"Why did this happen?

Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy."
Cairns Oneil Launches Generative AI Product 'nova' | LBBOnline - Little Black Book - LBBonline,https://www.lbbonline.com/news/cairns-oneil-launches-generative-ai-product-nova,"Thu, 05 Oct 2023 08:26:43 GMT",Little Black Book - LBBonline,"Cairns Oneil has announced the full launch of it’s Generative AI product, nova. Following the successful beta launch in the Spring of 2023 with their work for Rakuten Kobo, Cairns Oneil has enhanced and productised the tool, and branded it nova.

“While our agility and speed let us bring innovations to market quickly. It’s our expertise and amazing partners that allow us to also go deep and create products like nova.” said Devon MacDonald, president of Cairns Oneil “We know that relevance is key for consumers is advertising. Nova is finally realising the promise of 1:1 in digital for marketers.”

The beta launch used an instance of ChatGPT to create ad copy for display units that were optimised by audience and performance through the dynamic creative optimisation module of Cairns Oneil’s trade desk, CO2. To do this Cairns Oneil and their ad tech partner Adform coded the ChatGPT API into their DCO module, briefed it on the campaign and set up a control campaign. The display units generated by ChatGPT and optimised by CO2 outperformed the control by 2x.

The new product launch includes several new features. Primarily it will be able to determine the exact creative message most relevant to a specific user based on data signals. This is done by taking the exact set of data signals by user, feeding it through to ChatGPT and generating a custom ad unit in real time for each user. The user will have a seamless experience as the load time for the ad remains unchanged. The ChatGPT instance will be briefed on the campaign objectives, messaging, tone and brand safety parameters in advance. Nova will generate ad copy, headlines and colours that will be optimised through the DCO module in CO2.

Nova will also be used for SEM and SEO. Working from the same brief on the client, it will generate search ad copy recommendations and SEO keyword recommendations."
Generative AI’s supercharging goes beyond just text to images - Hindustan Times,https://www.hindustantimes.com/business/generative-ai-s-supercharging-goes-beyond-just-text-to-images-101696479380861.html,"Thu, 05 Oct 2023 04:16:20 GMT",Hindustan Times,"A sequence of events, set in motion in July last year when Stability AI’s Stable Diffusion, Midjourney and OpenAI’s Dall-E text-to-image models were unlocked for users to try out, shows no signs of slowing down. A few months later, OpenAI opening up the large language model (LLM) chatbot ChatGPT triggered the conversation AI battles that have since seen Microsoft, Google and Amazon push for a response. Canva’s newly updated AI suite includes nifty tools such as Magic Expand.

As we dissect the generative artificial intelligence (AI) space a year later, its theme is unambiguous. Imaging AI tools have developed significantly greater competence and can do a lot more, beyond generating images. Videos too, with tools such as Runway AI and Synthesia needing simple text inputs for video generation. Chatbots are smarter than ever, as the likes of Google Bard challenge the incumbents.

Alongside, more AI productivity focused models are leading to a unification of capabilities, and more relevant use cases. AI is certainly getting better at what it does.

Case in point, an AI generated version of actor Tom Hanks was seen in a social media advertisement promoting a dental plan. Much to Hanks’ annoyance, as he clarified in an Instagram post this week to 9.5 million followers. The actor is no stranger to AI versions of himself in the 2004 movie ‘The Polar Express’, and artificially de-aged in parts of the 2022 film ‘A Man Called Otto’.

Canva, a popular multi-platform designing suite which completes 10 years, is widening the scope of utility for users with a generative AI Magic Studio update. New tools are incoming for video edits, a text to image generator, ability to transform a presentation into a document or email, translate a presentation or document into more than 100 languages including Hindi and a powerful image editor.

“We are seeing with AI today, there are different products for photos, videos, text and all other components. With Canva we’ve been able to integrate that all into one simple platform and make it accessible,” Melanie Perkins, co-founder and CEO of Canva, tells HT.

Globalisation is a developing theme for chatbots and AI tools, in search of a wider user base. Google’s Bard chatbot can understand and reply in 40 languages, with Indian language support including Hindi, Tamil, Telugu, Bengali, Kannada, Malayalam, Marathi, Gujarati and Urdu.

Adobe’s popular Creative Cloud suite allows the company to leverage apps including Photoshop, Lightroom and Express, to integrate its Firefly generative AI tool. Firefly can work with 100 languages, including Gujarati, Hindi, Malayalam, Marathi, Nepali, Punjabi, Tamil and Telugu.

The need for safety mechanisms with image generators is becoming clear. There are enough examples of realistic looking, but AI generated images public figures doing rounds on social media, including Elon Musk’s robot wife and the Pope in a puffer jacket.

Getty Images’ new Generative AI commercial art tool will compete with Midjourney and Stable Diffusion. What stands out are claims that it is “commercially safer” than its rival platform – by that, they mean the tool won’t allow a user to generate images that may be classified as misinformation.

“We’ve listened to customers about the swift growth of generative AI – and have heard both excitement and hesitation – and tried to be intentional around how we developed our own tool,” said Grant Farhall, Chief Product Officer at Getty Images. This is powered by an AI model provided by tech company Nvidia.

It may not be the only tool taking this approach. With Dall-E 3 update, OpenAI promises more accurate and realistic images, as well as the ability to tweak an image further with a few words. There are important safety mechanisms in place, such as blocking the generation of images resembling public figures or any images that include hateful content.

OpenAI recently updated the GPT-4 LLM to receive images of something a user may see and decipher in detail. That’s a functionality third-party app developer Be My Eyes latched on to, developing an AI assistant called Be My AI. The app is gradually rolling out for iPhones and Android phones. Users with vision difficulties can take a photo of something around them, and the assistant will likely provide a detailed description.

“We are entering the next wave of innovation for accessibility technology powered by AI. We believe this new tool will provide people who are blind or have low vision with a better way to address everyday needs and acquire tools and visual descriptions never before possible,” says Mike Buckley, CEO of Be My Eyes.

Some of the use-cases Be My AI is already proficient with includes decoding difficult to read buttons and keys on gadgets or appliances, reading instruction manuals, describing outfits or patterns including colours, restaurant menus, bus numbers, images and posts on social media as well as detailing outdoor environments.

The need for an AI marketplace

While there are examples of companies developing tools using another’s AI models, such as Microsoft’s use of OpenAI’s GPT language model for the Bing chatbot, users still do not have an option of wider choice. Once that happens, utility will increase.

Canva’s Perkins talks about a three-pronged approach, which begins with significant investment in AI research, followed by integration of the best tools available and building an app ecosystem. That makes Canva an early mover in the marketplace format, with generative AI apps including Dall-E, Imagen by Google, MurfAI and Soundraw, now available to users.

This is something Microsoft is attempting to achieve too, with a wide spectrum of apps. Just days after making the Copilot assistant for Windows 11 available to millions of PC users globally, the image generator residing with the Bing AI chatbot has been updated to use OpenAI’s Dall-E 3 model.

A unique development nonetheless, since OpenAI’s own ChatGPT chatbot will get the model update later this month, but only for premium subscribers at first.

With a long term view on AI, the tech giant hopes adoption of the open plugin standard which OpenAI introduced for ChatGPT plugins, will make it easier to bolt more capabilities to Copilot. Developers will utilise one platform to build add-ons that work across consumer and business apps, including ChatGPT, Bing, Dynamics 365 Copilot and Microsoft 365 Copilot.

“We are entering a new era of AI, one that is fundamentally changing how we relate to and benefit from technology. With the convergence of chat interfaces and large language models you can now ask for what you want in natural language and the technology is smart enough to answer, create it or take action,” says Yusuf Mehdi, Corporate Vice President and Consumer Chief Marketing Officer at Microsoft.

Microsoft’s vision of an AI layer is outlined by how the Copilot implementation unfolds. AI in productivity apps including Word, PowerPoint and Excel apps will add tools for generating drafts, context, summarising and replying to emails or analysing data.

Big numbers accompany a generative AI space that is has caught everyone’s attention. Data released earlier this year by Next Move Strategy Consulting suggests that the global AI marketplace will be worth around $207 billion in 2023, and register a twentyfold increase to almost $1.8 trillion by 2030.

It should come as no surprise. Millions have since had their first tryst with a broad umbrella called generative artificial intelligence, or AI. Dall-E, for example, unlocked a million strong waitlist for its first beta version, last year. Within a month after ChatGPT went online for consumers in late November, 100 million had tried it already. That user base has widened significantly since.

Subscribe today by clicking the link and stay updated with the latest news!"" ""Exciting news! Hindustan Times is now on WhatsApp ChannelsSubscribe today by clicking the link and stay updated with the latest news!"" Click here!

SHARE THIS ARTICLE ON"
H1 Boosts Flagship Clinical Trial Intelligence Platform with ... - GlobeNewswire,https://www.globenewswire.com/news-release/2023/10/05/2755454/0/en/H1-Boosts-Flagship-Clinical-Trial-Intelligence-Platform-with-Generative-AI-to-Accelerate-Clinical-Trials.html,"Thu, 05 Oct 2023 13:00:00 GMT",GlobeNewswire,"NEW YORK, Oct. 05, 2023 (GLOBE NEWSWIRE) -- H1 , the leading source of truth for global Healthcare Professional, clinical, scientific, and research information, today announced the launch of GenosAI, a new generative AI tool seamlessly embedded into its clinical trial intelligence platform, Trial Landscape , to analyze and respond to all types of complex inquiries.



Trial Landscape allows sponsors to identify new sites, centers of excellence, and investigators with diverse patients; evaluate site and PI patient recruitment strategies; and gauge competition across trials. GenosAI is a significant leap forward in enhancing efficiency, diversity, and innovation in the pharmaceutical industry. According to Deloitte , AI has the potential to reduce drug discovery costs by as much as 70%. GenosAI’s advanced data analysis capabilities empower clinical researchers to make informed decisions more swiftly and accurately than ever before. With GenosAI, clinical operations, feasibility, and medical teams can easily access deep insights, speed up workflows, explore new types of data, improve efficiencies and reduce costs, and accelerate time to market.

Trial Landscape contains the richest underlying data available for clinical trials, pulling insights from more than 490,000 trials, 25 million publications, 10 million healthcare providers (including those with diversity data), 240 million patients, and 11 billion global claims. Clients can also integrate their own data, such as historical trial performance and feasibility questionnaire responses. GenosAI pulls from this data and, using the power of natural language processing (NLP), deciphers and responds to advanced analytical queries in a ChatGPT-like experience. Users can pose questions like “Which sponsors are running the most promising trials in small cell prostate cancer?” or “What are the best sites for my phase 3 prostate cancer study?” and receive high-confidence, actionable responses in seconds.

“GenosAI has the power to be a pharma company’s most impactful Large Language Model (LLM) tool,” said Ariel Katz, CEO and co-founder, H1. “With GenosAI, we’ve combined the power of conversational AI with our unmatched breadth of healthcare data to give sponsors access to the best data and technology possible. We hope this will have a profound impact on clinical trial diversity and efficacy.”

GenosAI improves clinical research in the following ways:

Competitive Intelligence & Trial Design: GenosAI surfaces critical insights into competitive trials, optimizing trial design strategies. Site Selection & Feasibility: By rapidly assessing site performance and feasibility, GenosAI aids in identifying the most suitable locations for clinical trials. Diversity & Inclusion: GenosAI supports the pursuit of diversity and inclusion goals in clinical trials, ensuring that minority populations are adequately represented. Clinical Trial Design: Through the analysis of vast amounts of medical literature and trial data, GenosAI identifies sites and PIs with the right patient cohorts based on specific inclusion and exclusion criteria. Unlocking Internal Clinical Trial Data Silos: GenosAI can also run on client data sources to unlock historically siloed data sources and insights.



GenosAI sits on H1’s global data platform that uses state-of-the-art technologies ranging from machine learning (ML) to NLP to create a unified single source of truth for healthcare data. Data privacy and security is ensured through Microsoft Azure Enterprise GPT-4, Guardrails reduce hallucinations common in healthcare language models, and the Retrieval Augmented Generation (RAG) approach enriches the model with H1-specific data and knowledge.

For more information about how H1 is deploying Generative AI to pharma visit our AI Content Hub here .

About H1

H1 connects the world to the right doctors and is the leading source of truth for global HCP, clinical, scientific, and research information. Leveraging next-gen analytics and AI, H1’s enterprise solutions democratize access to HCP data, diversity insights and groundbreaking research for life sciences, academic medical institutions, health systems, and payers. The H1 platform fuels a robust product suite that helps support the advancement of innovative and inclusive medicine. Today, more than 250 customers trust H1 to keep them current with the latest information on HCPs everywhere including their clinical and scholarly work and spheres of influence, connect them with the right thought and treatment leaders digitally and face-to-face, guide their strategies to increase adherence to evidence-based medicine, inform inclusive clinical trial design, provide access to groundbreaking science, and accelerate time to market. Learn more at https://www.h1.co ."
The U.S. Isn't Ready for AI-Fueled Disinformation—But China Is - TIME,https://time.com/6320638/ai-disinformation-china/,"Thu, 05 Oct 2023 08:00:00 GMT",TIME,"In 2019, a Chinese researcher named Li Bicheng laid out his ideas about manipulating public opinion using AI. A network of “intelligent agents”—an army of fake online personae, controlled by AI—could act just realistically enough to shape consensus on issues of concern to the Chinese Communist Party, such as its handling of the COVID-19 pandemic. Just a few years earlier, Li had written in other articles that China should improve its ability to conduct “online information deception” and “online public opinion guidance.”

Li is no outlier. In fact, he is the ultimate insider, with a long research career at the People’s Liberation Army’s top information warfare research institute. His vision of using AI to manipulate social media was published in one of the Chinese military’s top academic journals. He is connected to the PLA’s only known information warfare unit, Base 311. His articles, therefore, should be viewed as a harbinger of a coming AI-assisted flood of Chinese influence operations across the web.

As Meta recently disclosed in its quarterly adversarial threat report, Western internet platforms are already drowning in pro-Beijing content posted by groups linked to the Chinese government. According to the Meta report, more than half a million Facebook users followed at least one of these fake accounts in the broader Chinese network—which relied on click farms based in Vietnam and Brazil to boost its reach. The report also states that the Chinese network has bought about $3,000 worth of advertisements to further promote its posts. This effort, however, appears to still be ultimately run by humans and had marginal real-world results. A recent State Department report on China’s influence operations reinforces this point.

But generative AI offers the potential to transform such efforts into something far more effective, and thus far more dangerous to the U.S. and other global democracies. And our research shows that China is primed to adopt this new technology. Last month, Microsoft reported some China-affiliated actors who it tracks began using AI-generated images in March. This validates our concerns, and we expect more of this to come.

Now, thanks to generative AI, the impact of China’s social media manipulation will be both greater in sheer volume and much cheaper, and will likely have better, more believable content. While the traditional approach requires hiring humans to work in content farms to create or otherwise post content and then spending money to boost and promote it across social media, with generative AI, the cost is relatively fixed, and the scope is highly scalable: build it once, and let it populate the web with content.

The cost of building such a model is already incredibly cheap and—as with so much of technology—will only get cheaper. As Wired recently reported, a researcher going by the alias Nea Paw was able to create a fully autonomous account that posted across the internet, with links to articles and news outlets, even citing specific journalists—except that all of it was fake, created entirely using AI. Paw did this with publicly available, off-the-shelf AI tools. It cost him just $400.

This sort of generative AI, which acts much more like people, and not like bots, offers the CCP—and plenty of other bad actors, such as Russia and Iran—the potential to fulfill longstanding desires to shape the global conversation.

In May 2021, Chinese General Secretary Xi Jinping reiterated his party’s focus on this lofty goal, during his remarks at the CCP Politburo’s monthly Collective Study Session. There, he said that China should “create a favorable external public opinion environment for China’s reform, development and stability,” in part by developing more-compelling propaganda narratives and better tailoring content to specific audiences. Xi also emphasized that since he came to power, in 2012, Beijing has improved the “guiding power of our international public opinion efforts.” In other words, Xi is pleased with how much China is already influencing global public opinion but he thinks the CCP has more work to do.

Xi has also for years now been talking about technology as a way to achieve his desires. In an earlier Politburo Collective Study Session, in 2019, Xi said that it was necessary to study the application of AI in news collection, production, distribution, and feedback, in order to improve the ability to guide public opinion. The broader Party-state apparatus has already moved to realize Xi’s vision, including establishing “AI editorial departments.”

Chinese military researchers have been working to create what they sometimes call “synthetic information” since at least 2005. Such information can be used for many purposes, including generating “explosive political news” about adversaries. For example, China was accused in 2017 of a disinformation campaign that claimed Taiwan’s government was going to strictly regulate religious services, which created a political firestorm on the island.

Chinese military researchers have routinely complained the PLA lacks the necessary amount of staff with adequate foreign-language skills and cross-cultural understanding. Now, however, generative AI offers the PLA tools to do something it could never do before, which is to manipulate social media with at-or-near-human-quality content, at scale.

There are steps both social media platforms and the U.S. government can and should be taking to begin to mitigate this threat. But all such strategies must start from the reality that generative AI is already ubiquitous and unlikely to ever be universally regulated.

Still, social media platforms should intensify their efforts to crack down on existing inauthentic accounts spreading disinformation and make it harder for malign actors—foreign or domestic—to open new ones. The U.S. government, meanwhile, should consider whether the recent export controls for advanced hardware implemented against China and Russia can be improved during forthcoming revisions to better capture hardware required to train the large language models at the heart of AI. Once they are developed, the models get much harder to regulate.

It is vital that the U.S. government and social media platforms recognize this threat and work together to address it immediately, particularly before the 2024 elections.

Contact us at letters@time.com."
Zoom chucks generative AI everywhere in product blitz - diginomica,https://diginomica.com/zoom-chucks-generative-ai-everywhere-product-blitz,"Thu, 05 Oct 2023 10:36:59 GMT",diginomica,"(Pixabay)

Can generative AI get Zoom back to its pandemic heights of good fortune? If not, it won’t be for want of trying. The firm kicked off its Zoomtopia conference with a flurry of AI-related announcements of enhancements to its portfolio of offerings.

These included:

Zoom Docs, a modular workspace for documentation, project and data management that can also be used to create tables, wikis, tasks and other content.

Users will also be able to populate documents with content from live meetings and chat sessions as well as create new content using Zoom AI Companion, the firm’s generative AI assistant. Launched last month, Zoom AI Companion allows users to quickly watch meeting recordings via highlights and smart chapters, review summaries and next steps, and provide automated meeting summaries that can be shared once a call has ended.

Also getting generative AI capabilities is the Zoom Contact Center offering released last year. There have been 600 features added to this in the past 18 months, according to Mahesh Ram, Zoom’s Head of AI Applications with more to come:

In addition to AI Companion, which is included in the Contact Center paid license, we're also introducing later this year Expert Assist, AI Expert Assist for the Contact Center with the agent side, which is going to provide agents with real-time guidance, ability to look up information and knowledge automatically with AI, be able to make suggestions and so on.

He added:

What you see is the solution forming around the needs of the customer, which I think is obviously always Zoom's forte. But if you think about it from a customer perspective, which is how we think about it, they're not looking for a virtual agent to replace human agents all the time. They're not looking for human agents to do things that AI could do well. And so what we're starting, what we're really understanding is how do we create a seamless customer experience journey? When we start with that mentality, then when you have virtual agents, you can make sure that you cover a wide swath of issues that customers don't need. We ourselves use our own virtual agent for our own support. I think we self-serve over 85% of our own issues, and we get millions. So we're living proof of drinking our own champagne, so to speak.

But there are moments when consumers want to talk to a live agent, he noted:

I think the power that we're seeing is it's not always about self-service. It's about capturing the right information, getting the intent right, determining whether I can self-serve you and getting out of the way and getting to the agent in the most appropriate way, when possible…So I think we've come a long way from having a solution that did one thing, which is agent-facing contact center to now having the full spectrum of the customer experience, the supervisor experience and the agent experience and AI across all of it.

As for AI Companion, which is included with all paid licences, there are more and more use cases it can drive, said Ram:

We're creating AI Companion capabilities across the entire platform. So you see it in Whiteboard, you see it in Meetings, you see it in Team Chat.

To date, almost 30,000 Zoom customers have enabled AI Companion, he went on:

Obviously, Meetings, Chat and Whiteboard have led the way in the first phase. But we think two things I want to just mention about that. One is when we made the very clear pronouncement about data use, it unlocked a bunch of opportunities. Companies that are like ‘What are you going to do with our data?’, all the questions all went away. They just said, ‘OK, you made it clear. You made a definitive statement’ and that was one. And then I think the other thing is that it's just like Zoom - it just works. You just press a button, it works. You don't have to think about some fancy back-end thing enable. It's just click a button and it works.

As for why Zoom isn’t charging additional cost for AI companion unlike some rivals who charge a premium pricing, Ram said this is a “Zoom tradition”:

When you listen to the customers intently, you hear what they're saying and I think what we were hearing from customers was, if you make AI a premium offering, then I have to choose between the haves and the have-nots. We see generative AI as being something that's just part and parcel of everyday work and collaboration. If you have a 20,000, 50,000 employee workforce company and you're having to think about $30 a month, you're making decisions that are probably not in the best interest of your business. From our perspective, we said we want to make Zoom the platform of choice. We want to make it as valuable to every employee as possible in every business…As you start talking to customers, there's a collective sigh of relief.

There’s a vendor consolidation angle here, he added:

We have an opportunity to drive some of this. A lot of these companies are getting pitched with vendors, 20, 25 vendors who do point solutions, and there's a lot of overhead and a lot of cost. I think we have an opportunity to go in and say, ‘Hey, we can cover more of your needs across the business’. So I think that's the rationale and I think that it really is helping with customer adoption as well.

Obviously in the current climate, it’s compulsory for all vendors to have a generative AI message, which raises the question of how those ‘over-pitched’ customers should make buying decisions. Ram argues:

I think, ultimately, customers make the decision about what's best. I think our focus is - and honestly, this is not just lip service - we really, really listen to what customers are telling us and we're iterating so fast on it…Almost 30,000 [customers] have implemented, so we have a lot of group feedback. They really like the fact that it's easy to use, that it's included with the paid license. The data concerns go away. They don't have to get their legal team involved for extensive conversations because they know they've taken that out. That's the reason for us to be there. But the real reason they keep it is quality. We had people to tell us this week that ‘I missed a meeting and the meeting summary was so good that I felt like I was in the meeting. Or I joined the meeting late and I asked the question, what did Kelly say about that and it gave me the right answer, so I could catch up’. I think we focus on how do we make that the highest quality, number one.

He concluded:

That’s what Zoom does well. It just works. It's easy. It's easy to implement, it's easy to use. And I think as long as we stay focused on that, the quality is high, the ease of use is very good and we're listening constantly and improving, I think to me, that's the best way we can compete and win is focusing on those three things. But we do benchmark. We benchmark everything and we're always testing every feature, everything, every day.

My take

A strong fleshing out of the core Zoom offerings, riding the generative AI wave with a series of enhancements that expand the platform’s capabilities. The decision not to charge premium pricing for AI Companion is a bold move, but one with a lot of potential to pay off in terms of adoption."
Meta rolls out generative AI powered features for ad creatives - The Economic Times,https://economictimes.indiatimes.com/tech/technology/meta-rolls-out-generative-ai-powered-features-for-ad-creatives/articleshow/104178931.cms?from=mdr,"Thu, 05 Oct 2023 06:13:00 GMT",The Economic Times,"Ending months of negotiations, JSW Group chairman Sajjan Jindal and Shanghai-based SAIC Motor Corp have finalized the terms of their agreement for a grand alliance involving MG Motor India, the wholly owned arm of the Chinese auto major that owns the British automotive marque Morris Garages, people aware of the cross-border deal told ET.

The Cricket World Cup will add to the festive cheer in the economy this quarter, lifting growth by about 10 basis points as cricket lovers get set to spend big on select goods and a host of services, economists said."
AI for communicators: What's new and what matters - Ragan Communications,https://www.ragan.com/ai-for-communicators-whats-new-and-what-matters-5/,"Thu, 05 Oct 2023 10:02:23 GMT",Ragan Communications,"It was the best of times, it was the worst of times for AI.

New tools are being rolled out to make life easier for us all. It could be so great, we could get down to a 3.5 day workweek!

But this week also brings us serious concerns about AI’s role in creating deepfakes, perpetrating colorism and more.

Read on.

Deepfakes, impersonation and skin hue take center stage

Some of the dystopian fears that AI represents are beginning to come to fruition.

Impersonation and deepfakes are emerging as a critical problem.

Multiple actors have found that their likenesses are being used to endorse products without their consent. From beloved actor Tom Hanks (“Beware!! There’s a video out there promoting some dental plan with an AI version of me. I have nothing to do with it.”) to “CBS Mornings” host Gayle King (“I’ve never heard of this product or used it! Please don’t be fooled by these AI videos.”), celebrities are speaking out with alarm, the New York Times reported.

The reputational risks for these entertainers are real, but it’s not hard to imagine more dire deepfakes causing major harm: the CEO of an airline “announcing” a crash, for instance, or a president “threatening” nuclear war. The technology is here, it’s real and it’s frightening.

But there is criticism of AI being used to mimic entertainers extending even beyond deepfakes. Zelda Williams, daughter of late comedian Robin Williams, strongly condemned attempts by studios and others to recreate her father’s voice using AI. “These recreations are, at their very best, a poor facsimile of greater people, but at their worst, a horrendous Frankensteinian monster, cobbled together from the worst bits of everything this industry is, instead of what it should stand for,” she wrote on Instagram. She strongly voiced her support for the actors currently on strike, where one of the issues at stake is the use of AI in entertainment.

Outside of entertainment, it’s becoming clear how easy it is for bad actors to evade mandatory watermarks placed on AI-generated images, according to University of Maryland Computer Science Professor Soheil Feizi. Feizi’s research shows not only how easy it is to remove or “wash out” watermarks, but also how simple it is to add fake watermarks to non-AI images to generate false positives.

Many tech giants have looked to watermarks as a way to distinguish AI images from the real, but it appears that strategy won’t work, sending everyone back to the drawing board.

“We don’t have any reliable watermarking at this point,” Feizi said. “We broke all of them.”

The people who make AI work are also struggling to ensure it is inclusive for people of all races. While it’s more common to test AI for bias in skin tone, The Verge reports that skin hue is often overlooked. In other words, researchers are currently controlling for the lightness and darkness of skin, but not redness and yellowness.

“East Asians, South Asians, Hispanics, Middle Eastern individuals, and others who might not neatly fit along the light-to-dark spectrum” can be underrepresented because of this, Sony researchers wrote.

But it isn’t all gloom and doom in the world of AI. There are positive elements coming, too.

Recent data and insights on AI and the future of work

Q4 arrives with mere weeks leading up to Ragan’s Future of Communications Conference, and AI news around the future of work is plentiful.

A recent study from Morgan Stanley forecasts that over 40% of the labor force will be impacted by AI in the next three years.

CNBC reports:

Analyst Brian Nowak estimates that the AI technology will have a $4.1 trillion economic effect on the labor force — or affect about 44% of labor — over the next few years by changing input costs, automating tasks and shifting the ways companies obtain, process and analyze information. Today, Morgan Stanley pegs the AI effect at $2.1 trillion, affecting 25% of labor.

Nowak identifies falling “input costs” for companies getting on board, which may inform why job posts mentioning AI have more than doubled over the past two years, according to LinkedIn’s Global Talent Trends report.

Big investments in automation abound, with Visa earmarking $100 million to invest in generative AI companies “that will impact the future of commerce and payments,” reports TechCrunch.

Meanwhile, IBM announced a partnership with the U.S. Chamber of Commerce Foundation to explore AI’s potential application for better skills-based hiring practices.

The Chamber created a test case for job seekers by examining if AI models can help workers identify and recognize their skills, then present them in the form of digital credentials.

“If proven possible, then future use cases of AI models could be explored, like matching users to potential employment and education opportunities based on their skill profiles,” explains IBM.

“They discovered that AI models could in fact take someone’s past experiences—in different data formats—and convert them into digital credentials that could then be validated by the job seeker and shared with potential employers.”

What’s the endgame of all this? In a recent Bloomberg interview, JPMorgan Chase CEO Jamie Dimon offered some utopian ideas for how AI will positively impact the workplace, eventually leading to a 3.5-day workweek. Sounds nice, right?

Dinon’s comments aren’t that far removed from other CEOs who believe AI will streamline repetitive tasks and help parse data more efficiently, but this optimism must be tempered with the reality that leaders–and their willingness to approve training and upskilling for their workforces on operationalizing AI applications now– will largely inform which roles are eliminated and what new ones are created.

Bing’s ChatGPT levels up in a big way

One of the major drawbacks to using ChatGPT only “knew” things that happened up to September 2021. But now, it’s able to search the entire internet up to the current day to inform its responses, Yahoo Finance reported. The feature is currently available to paid users on ChatGPT 4 and people using ChatGPT’s integration with Bing, now known as Browse with Bing.

Bing also added another helpful feature: You can now use OpenAI’s DALL-E 3 from directly within its ChatGPT integration, making it easier to create generative AI images without the need to open another browser tab.

All of these changes continue to position Bing as a major player in the generative AI space (even if it’s getting most of its smarts from OpenAI) and open new possibilities for AI use.

WGA protections may set a precedent for federal regulations

Last week saw the end of the Writer’s Guild of America’s (WGA) 148-day strike. Amid the terms of the agreement were substantial regulations that protect against AI encroaching on the writing process.

The WGA regulations say:

AI can’t write or rewrite literary material, and AI-generated material will not be considered source material under the MBA, meaning that AI-generated material can’t be used to undermine a writer’s credit or separated rights.

A writer can choose to use AI when performing writing services, if the company consents and provided that the writer follows applicable company policies, but the company can’t require the writer to use AI software (e.g., ChatGPT) when performing writing services.

The Company must disclose to the writer if any materials given to the writer have been generated by AI or incorporate AI-generated material.

The WGA reserves the right to assert that exploitation of writers’ material to train AI is prohibited by MBA or other law.

While these regulations aren’t federal, they do set an interesting precedent. Over the past few weeks, this column has explored how The District Court of D.C. ruled that AI images are not subject to copyright, while the U.S. Copyright Office held an open public comment period to determine how it will advise on federal AI regulations going forward.

In a recent visit to Washington, even Musk and Zuck told the Senate that they want federal regulation on AI. The risks and liability of leaving this work to be self-regulated are simply too great.

Those risks are underscored by recent court cases, including a recent filing wherein authors including Sarah Silverman sued OpenAI for using their words in its learning models. Reuters reported on the filing, which alleges that “OpenAI violated U.S. law by copying their works to train an artificial intelligence system that will ‘replace the very writings it copied.’”

Add to that a chorus of state and local governments that are either taking AI for a test run or imposing a temporary ban, and the likelihood of federal regulation seems all the more assured.

Keep watching this column for future updates as they evolve, or join us for our AI Certificate Course for Communicators and Marketers. Don’t wait, classes start next week!

What trends and news are you tracking in the AI space? What would you like to see covered in our biweekly AI roundups, which are 100% written by humans? Let us know in the comments!

Justin Joffe is the editor-in-chief at Ragan Communications. Before joining Ragan, Joffe worked as a freelance journalist and communications writer specializing in the arts and culture, media and technology, PR and ad tech beats. His writing has appeared in several publications including Vulture, Newsweek, Vice, Relix, Flaunt, and many more.

Allison Carter is executive editor of PR Daily. Follow her on Twitter or LinkedIn."
Margaret Atwood Reviews a “Margaret Atwood” Story by AI - The Walrus,https://thewalrus.ca/margaret-atwood-ai/,"Thu, 05 Oct 2023 10:30:39 GMT",The Walrus,"Much handwringing is going on among writers about the impending terrors of generative AI and their potentially predatory behaviour. They’re being trained on our pirated books, say the writers, and they don’t chew their food. How can they, since they’re being force-fed every last bit of verbiage their proprietors can filch? Will they just gobble us up like great white sharks, burping out an endless stream of teeth, bones, and ersatz fictions claiming to be by us? Will they infiltrate themselves into us like the emotionless pod people in Invasion of the Body Snatchers and eat us from the inside out, transforming us into fakes of ourselves and giving pink flowers a bad name?

Are they malevolent aliens, or are they more like human criminals? They certainly can’t be depended on to tell the truth, except maybe about things like airline schedules. But can they write convincing Harlequin Romance novels? Will the real Harlequin Romance writers be done out of their jobs?

AI chatbots cannot dress up in period costume. Or not yet. There’s that.

Will they write political speeches? That’s more than likely. Some of them are already hard at it. But will they ever be able to come up with new catchphrases, such as “I did nothing wrong” and “I alone can fix it”? Oh. Sorry. Not so new.

Take heart! Not all is gloom! So far, generative AI chatbots don’t seem able to reflect on what they’re saying, though that in itself wouldn’t differentiate them from some actual human beings. Also, they’re bad at verbal texture, and they have a poor grasp of metaphor and sometimes even of punctuation. Well, they’re learning from us, so why wouldn’t that be true?

You’re still worried, young author? You doubt my word? Here are a couple of recent literary attempts by AI chatbots that ought to reassure you.

The first is a poem, requested by one of the board members of the Pelee Island Bird Observatory—PIBO—which counts and evaluates the health of migratory species on an island in Lake Erie. The bird banders and volunteers often have to wade through knee-deep mud and contend with chiggers, mosquitoes, and biting flies. They don’t wear gloves—they need a fine and gentle touch to handle small birds—or insect repellant, as that could be toxic. Let’s just say they suffer so that you can continue to enjoy birdsong.

Here is the request made to the chatbot, followed by the result:

“Give me a poem using PIBO and the important work it does as the subject.” It took ten seconds. “And now . . . including mosquitoes, chiggers, stable flies and mud”:



There exists a sanctuary, a cherished home.

PIBO stands strong, in this nature’s canvas,

Guarding avian secrets, amidst the wilderness vast. Upon Pelee Island, where the migrators roam,There exists a sanctuary, a cherished home.PIBO stands strong, in this nature’s canvas,Guarding avian secrets, amidst the wilderness vast. Dawn lights up the skies, warblers sing their tune,

While mosquitoes buzz and chiggers commune.

Stable flies flutter, adding to the whirl,

In this muddy haven, life’s mysteries unfurl. With gentle hands, they band and observe,

Each bird, each flight path, each graceful curve.

Their research, a beacon through the migration night,

Guiding safely, each feathered flight. Tales of epic journeys, of tempests braved,

By our avian kin, by PIBO saved.

And amidst the insects’ dance and the fertile mud,

Echoes the rhythm of life’s ceaseless flood. Through the digital window, the world looks on,

As PIBO’s mission is daily drawn.

From this mud-rich base, to lands afar,

Spread the lessons of life, each under a star. Thus stands PIBO, on Pelee’s serene coast,

A sentinel of the skies, humanity’s boast.

Among mosquitoes, chiggers, and stable flies’ hum,

Sings the profound mission, of the noble PIBO’s drum.

You see what I mean about the punctuation? I might note as well that Pelee Island is not exactly a “wilderness vast”—see map, a thing the chatbot evidently did not do—and that the idea of chiggers communing in your armpits, though whimsical, is not observant of their social habits, which are nul. Nor do stable flies flutter, unless by happy chance you’ve smacked one of them and it’s not dead yet.

Yes, I know. You’ll say that these are minor quibbles, and your Uncle Roger writes doggerel verse like this by the yard and sends it out to you every Christmas. I point out that a chatbot replacing Uncle Roger might very well happen, but, dear published author, it is not yet very likely to replace you.

My second demonstration piece was instigated by The Walrus. Here is the ask, followed by the response:

Prompt: Can you write a dark and dystopian short story in the voice of Margaret Atwood that takes place in Canada?

The Weeping Willows of Winnipeg Every morning, as the rose-tinted dawn slices the stillness of night, I see the Weeping Willows of Winnipeg. They stand tall yet humbled, their drooping branches laden with the invisible weight of despair. The people here, they too carry an unseen burden. Their weary faces are etched with deep lines, their eyes holding echoes of stories they’re too afraid to tell. Winnipeg, once a thriving city, is now a desolate ghost town, crippled by the icy grip of the Northern Wastes that have extended their deadly reach. The permafrost that used to recede with the summer sun, now remains a permanent fixture, a chilling symbol of the loss we have borne. The world changed after the Last Oil Crisis. Our dependence on fossil fuels had been our downfall. Nature, which we had exploited for centuries, took its revenge. Global warming accelerated, the Arctic ice caps melted and the Jet Stream collapsed, plunging Canada into a never-ending winter. People adapted as best they could. We learned to survive in constant sub-zero temperatures, to huddle together for warmth, to forage for whatever we could eat. We learned to fear the silence, the vast, white stillness that swallowed the sounds of life. We learned to mourn the loss of the sun, the loss of hope. The government, which we thought was a sturdy lighthouse guiding us through tumultuous waves, collapsed under the weight of its lies and deceit. Anarchy ensued. Gangs roamed the icy streets of Winnipeg, their eyes hollow, hearts even more so. Survival was the only law that mattered now. I remember the days of warmth, the days of green trees, and blooming flowers. I remember the bubbling laughter of children, the bustling city streets, and the sweet scent of the bakery near our old house. Now, all that remains is the biting chill, the gnawing hunger, and the pervasive fear. But the Weeping Willows, they keep me going. These ancient trees, they are the last vestige of the world that was. Their slender, weeping branches whisper tales of past springs and hopeful summers. They symbolize resilience, endurance. They are a beacon of hope in a world dominated by despair. In their quiet lament, I hear a promise. A promise that nature will endure, that it will bounce back, reclaim its rightful place. Every morning, as I watch the dawn illuminate their snow-laden branches, I see a spark of life, a glimpse of the world that once was, and could be again. The Weeping Willows of Winnipeg stand tall, not in defiance, but in acceptance of the harsh reality, and yet with a quiet assurance of a spring that may return. We must weather this winter of our discontent, like the willows, bending but never breaking. After all, hope is a stubborn thing; it survives even in the darkest of times, it thrives in the coldest of hearts.

When you return from the bathroom, having recovered from your bout of faux norovirus, give yourself a pat on the back. You, dear author, would never write anything so gawd-awful, and neither—unless my brain leaves for another planet—would I. Of course, some of you will make waggish jokes, such as “Sounds like Margaret Atwood to me,” and yes, maybe the bot is onto something with the weary-faced Winnipeggers and their secret stories of terror, no doubt concerning Pierre Poilievre.

But apart from that, gimme a break! If it’s a desolate, perma-frosted ghost town, why haven’t those folks just, you know, moved? And it got cold, but the sun is no longer shining? Really?

As for the weird title, the bot was evidently fed my alliterative children’s stories, such as Princess Prunella and the Purple Peanut. It mixes modes, and cannot seem to distinguish between kid’s lit and the grown-up stuff. Ask it to write a children’s story by Anaïs Nin and see what you get.

So sleep well tonight, dear authors. Your vocation is safe from the pod people. At least for now.

The fee for this article has been donated to PIBO, in honour of the partying chiggers and the fluttering stable flies that plague the bird banders. It will buy them some coffee. Since they get up at 5 a.m. to wade through the mud, they always need it."
"5 things about AI you may have missed today: AI-related jobs surge, skin colour in AI bias, and more - HT Tech",https://tech.hindustantimes.com/tech/news/5-things-about-ai-you-may-have-missed-today-ai-related-jobs-surge-skin-colour-in-ai-bias-and-more-71696441660632.html,"Wed, 04 Oct 2023 17:59:36 GMT",HT Tech,"LinkedIn data has revealed a dramatic two-year surge in AI-related job postings; Sony research has revealed an overlooked aspect of skin colour in AI bias testing; Vyzer has secured $6.3 million seed funding for AI-driven wealth management platform; Google Pixel 8 series touts abundance of innovative generative AI features- this and more in our daily roundup. Let us take a look.

1. LinkedIn data reveals dramatic two-year surge in AI-related job postings

LinkedIn data reveals that job postings mentioning AI or generative AI have more than doubled globally between July 2021 and July 2023. Some countries, such as the U.K., Germany, and France, saw even larger increases. This trend spans various industries, with demand for AI skills emerging across diverse roles, from AI engineers to digital product managers and cybersecurity consultants, signalling a significant impact on the labour market, CNBC reported.

2. Sony research reveals overlooked aspect of skin colour in AI bias testing

Sony researchers argue that AI bias tests need to consider red and yellow skin hues, not just lightness or darkness. They propose a ""multidimensional"" approach to measuring skin colour for more diverse and representative AI systems. Previous studies have highlighted biases, especially against darker-skinned females. Companies like Google and Meta have introduced skin tone scales to improve accuracy in AI systems, according to a report by the Verge.

3. Vyzer secures $6.3 million seed funding for AI-driven wealth management platform

Vyzer, a digital wealth management platform, has secured $6.3 million in a Seed round from VCs, angel investors, and family offices like iAngels, MonetaVC, and more. The platform offers financial analysis, advanced planning, automation, and analytics, powered by AI. Vyzer aims to democratise wealth management by eliminating the need for traditional high-cost models and financial advisors, making it accessible and comprehensible to everyday investors. The funds will be used to enhance AI capabilities and expand market presence. Co-founded by Litan Yahav, Tomer Salvi, and Guy Gamzu, Vyzer has offices in Israel and New York, the Calcalist reported.

4. Google's Pixel 8 series boasts an abundance of innovative generative AI features

Google's Pixel 8 series has been launched and the phones feature generative AI enhancements, including on-demand summaries, translations, and read-aloud capabilities for articles and web pages through the Google Assistant. The Assistant can swiftly summarise web content and offer related follow-up prompts. It also translates text into multiple languages and reads it aloud in supported languages, providing playback controls and skip options for improved user experience on the Pixel 8 and Pixel 8 Pro.

5. Google's vision: Empowering virtual assistants with generative AI for enhanced task support

Google is planning to integrate generative AI capabilities into its virtual assistant, allowing it to assist with tasks like trip planning and email management. The company aims to incorporate features from its Bard chatbot into the virtual assistant, offering personalised service and reasoning on mobile devices. Google is in a competitive race with other tech companies, including Meta Platforms, Amazon.com, and Microsoft, to integrate generative AI into its products.

One more thing! We are now on WhatsApp Channels! Follow us there so you never miss any update from the world of technology. ‎To follow the HT Tech channel on WhatsApp, click here to join now!"
Brands turn to generative AI to improve customer experience amidst ... - Singapore Business Review,https://sbr.com.sg/information-technology/news/brands-turn-generative-ai-improve-customer-experience-amidst-reduced-budgets,"Thu, 05 Oct 2023 03:05:28 GMT",Singapore Business Review,"Three in five firms plan to cut their customer experience budgets in the next 12 months.

More than half of brands (59%) in Singapore are planning to implement generative AI (59%) to improve customer experiences amidst reduced budgets, an Adobe report revealed.

According to the report, a majority of employees in Singapore (94%) are already using generative AI in marketing and customer experience campaigns.

Employees specifically use text-to-image generators to create promotional brand materials and content (58%) and develop concepts and mockups for campaigns (55%).

Where conversational AI is concerned, half of employees (50%) use the tool for copy generation, as well as research and insights.

Whilst many employees use generative AI, the technology is only formally rolled out in three in 10 brands in Singapore.

“The research suggests that formal business rollouts of generative AI among Singapore brands lag well behind consumer demand and employee usage,” Adobe said."
Six keys to generative AI success - Research & Development World - Research & Development World,https://www.rdworldonline.com/six-keys-to-generative-ai-success/,"Thu, 05 Oct 2023 12:49:56 GMT",Research & Development World,"As someone who has spent my entire adult life studying materials science, this is a very exciting time.

Generative artificial intelligence is upending our previous assumptions about how — and how quickly — new materials can be designed, with algorithms already helping companies and researchers to automate performance forecasting, improve existing materials, and even generate arrays of potential designs for new materials that meet specific criteria.

Understandably, companies in this space are racing each other to adopt and implement AI solutions that will give them a competitive edge. This is, doubtlessly, the right move, but organizations need to be thoughtful about how they build out their AI ecosystems — cutting through the hype and creating an environment that will result in real value.

Here are six important considerations.

Data Sources — Carefully think through what data will be used to train your generative AI systems. Publicly available data is easily accessible and available at a low cost (or even for free). It is also often expansive, covering more breadth than most companies’ internal data. For these reasons, it is typically an excellent starting point for AI training. However, competitors will also have access to this data, potentially limiting its upside value. Additionally, there can be a risk of inconsistencies or errors if the data isn’t well-curated, and it may lack the specificity necessary for niche applications. Proprietary data, by contrast, can be expensive to produce and may be limited in volume, but it will typically be a better fit to help solve an organization’s specific problems.

Intellectual Property — This is still an evolving area, but it’s an important one. If a company creates a new material using a combination of AI and publicly available data, it’s not entirely clear that the company will own the rights to the design. And in many cases, it won’t even be obvious when AI programs have used existing, patented ideas in the creation of a new design, since these tools typically lack transparency. Getting a grasp on this issue may require IT and business leaders to work closely with legal departments — and to keep an eye on this area of the law as it continues to mature.

Infrastructure — Advanced AI models rely heavily on the robust computational power provided by graphics processing units (GPUs). But as the demand for AI systems grows, we’ve seen a shortage of GPUs, with even the largest AI players fiercely competing with one another to get their hands on these essential resources. And even when organizations are able to procure the technology they need, the new infrastructure can create additional management and maintenance burdens. Business and IT leaders should carefully consider whether it makes the most sense, long-term, to buy and maintain their own infrastructure, or to partner with public cloud providers or specialized AI infrastructure vendors.

Talent — It’s difficult enough right now to find specialists with experience in AI. The demand is enormous, and since the field is relatively young, the supply of trained professionals is limited. Combine this with the challenge of finding people who not only possess AI skills but are also trained in materials science, and you’re going to be fishing in a very shallow talent pool. Rather than seeking out external expertise, organizations might consider training up their existing employees — particularly engineers with the sort of domain knowledge that will be necessary in setting up AI systems to answer the burning questions in the field.

Business Model — We don’t yet know what AI’s capabilities will look like five or 10 years from now. But just looking at the progress that’s been made over the past 12 to 18 months, it’s a safe bet that tomorrow’s applications will make today’s look pedestrian by comparison. This may mean that innovation essentially becomes commoditized. That’s a startling and, if we’re being honest, likely scary thing for people to hear. But that’s why it’s so important for business leaders to keep their companies at the forefront of technology, and to be bold enough to proactively adjust their business models rather than being disrupted by startups.

Tangible versus Hype — At the same time, businesses shouldn’t be placing all-in bets on AI applications that aren’t fully validated. Let me be clear: Generative AI is not a fad, and it’s not unsubstantiated hype. But there will be false starts and dead ends, and some seemingly promising applications are certain to end up in the graveyard of failed technologies. By exercising care along with their quickness, organizations can ensure that a single unsuccessful AI project won’t lead to a disaster — and can instead set themselves up to reap the rewards that surely await those who safely navigate the next few years."
Will AI replace journalists? | Waterloo News - The Iron Warrior,https://uwaterloo.ca/news/media/will-ai-replace-journalists,"Wed, 04 Oct 2023 19:42:00 GMT",The Iron Warrior,"The University of Waterloo hosted a global network of national news agency leaders on campus this week to share the expertise of our AI researchers.

During their visit to Waterloo, over 70 news agency business executives explored AI in action. They were treated to displays by representatives from Waterloo's startup incubator, Velocity, RoboHub - the home of robotics at Waterloo, and the Critical Media Lab (CML) – a cross-disciplinary, research-creation initiative which fosters the development of new media projects that explore the impact of technology on society and the human condition.

The group, which included leaders from national news agencies such as L'Agence France-Presse (AFP), The Associated Press (AP), Reuters and The Canadian Press (CP), are members of the Media Innovation Network (MINDS). MINDS is a non-profit organization in which news agencies work together on new concepts for the media industry. They came to Waterloo to learn about how AI may disrupt their industry and how they can use tools like ChatGPT to their advantage.

""Such an illustrious group of media leaders deciding to visit the University of Waterloo to seek insight on how AI will impact their industry is a testament to the reputation our faculty and students have built as innovators in the field,"" said Vivek Goel, president and vice-chancellor of Waterloo, who delivered opening remarks. ""Our researchers are committed to sharing their knowledge and expertise for the benefit of society.""

Twice a year, MINDS organizes conferences for its members. Participants are senior managers from all relevant areas of the news agency business – board, editorial, strategy, technology, products, and sales. MINDS Conferences provide a great opportunity for networking with news agencies' decision-makers. They are intended for an exchange of thoughts and experiences, for getting impulses for new business, as well as the chance to explore collaboration in many ways.

The 35th MINDS conference, which The Canadian Press is hosting, is totally dedicated to artificial intelligence-related topics.

""We approached the University of Waterloo to be a stop for this three-day conference because of the range of faculty and researchers currently working in AI at the institution,"" said Malcolm Kirk, The Canadian Press president. ""The University of Waterloo has positioned itself as one of the leading institutions in Canada when it comes to research and investment in artificial intelligence. We were immensely fortunate to learn from the institution's incredible expertise.""

Professors Joel Blit and Jimmy Lin presented to the attendees on the meteoric rise of large language models (LLMs), such as ChatGPT, and how business executives can unlock its transformative potential.

Dr. Lin, a professor and the David R. Cheriton Chair in the David R. Cheriton School of Computer Science, took a closer look at why LLMs are special and what is generative AI.

""Unlike traditional AI models that are primarily used for tasks like classification or prediction, generative AI models are designed to generate new data that resembles the training data they were exposed to,"" Lin said.

Dr. Blit, professor in the Faculty of Arts, discussed the three phases all general-purpose technologies go through.

""The first phase is 'replace', when a new technology displaces old technology or humans,"" Blit said. ""The second is 'reimagine', when processes and business models fundamentally change to leverage the new technology. The third phase is 'recombine', when the technology is combined with other new or existing technologies to create a completely new use case or application.""

The third aspect of the afternoon's activities was a panel discussion moderated by Andrea Baillie, editor-in-chief at The Canadian Press. The panel comprised Dr. Lennart Nacke, professor and associate director, Stratford School of Interaction Design and Business, Dr. Marcel O'Gorman, professor and university research chair and founding director of the CML, Dr. Sirisha Rambhatla, professor in the Management Science and Engineering Department where she leads the Critical ML Lab and Dr. Will Zhao, professor of organization and human behaviour at Waterloo's Stratford School.

The panel fielded questions about how media outlets can protect their role as disseminators of trusted information and the challenges and opportunities generative AI presents to news organizations.

""The role of media organizations is definitely going to expand,"" Rambhatla said. ""These generative AI models can help speed up writing, but they are still, what I call, 'fancy regurgitators' of language and in no way arbitrators of facts. This means the focus of personnel will shift to performing in-depth analysis and research.""

The afternoon activities concluded with attendees engaging in small group discussions with Waterloo's researchers."
Meet Silicon Valley's Generative AI Darling - Analytics India Magazine,https://analyticsindiamag.com/meet-silicon-valleys-generative-ai-darling/,"Thu, 05 Oct 2023 05:12:40 GMT",Analytics India Magazine,
Karnov Group launches its first generative AI legal assistant at ... - Marketscreener.com,https://www.marketscreener.com/quote/stock/KARNOV-GROUP-AB-PUBL-57086027/news/Karnov-Group-launches-its-first-generative-AI-legal-assistant-at-today-s-Capital-Markets-Day-44987622/,"Thu, 05 Oct 2023 05:47:03 GMT",Marketscreener.com,"Karnov Group (publ) is pleased to announce the launch of its first generative AI legal assistant. Management will present this solution, and its ambitious AI pipeline among other things, at the 2023 Capital Markets Day, held today in Stockholm and broadcasted live.

Karnov Group today launches its first generative AI solution for legal professionals, K+ Smart Chat. The solution will be integrated on the legal information platform in Region South. The solution has been tested by selected customers in Spain and is currently in beta. Karnov Group will launch a similar generative AI solution in Region North.

""Generative AI is a great opportunity for Karnov Group to enhance our value proposition and support our customers in making better decisions, faster. We have a long experience of AI innovation and an ambitious pipeline of future AI innovations"" says Pontus Bodelsson, President and CEO of Karnov Group .

"" Karnov Group has worked with Artificial Intelligence for many years. Generative AI adds a new dimension to content interaction. Our generative AI solution is anchored in our premium proprietary content, which ensures certainty"" supplements Anne Nørvang Hansen, Group Head of Content Strategy of Karnov Group .

The generative AI solution will be presented today at Karnov Group's 2023 Capital Markets Day. The event will be webcasted live from 12:00 pm CEST at https://ir.financialhearings.com/karnov-group-cmd-2023 .

For more information, please contact:

Erik Berggren , Head of Investor Relations

Telephone: +46 707 597 668

Email: erik.berggren@karnovgroup.com

This information was submitted for publication on 5 October 2023 at 07:46 CEST .



Karnov Group clears the path to justice, providing mission critical knowledge and workflow solutions to European professionals in the areas of legal, tax and accounting, and environmental, health and safety. With content provided by over 7,000 well-renowned authors and experts, Karnov Group delivers knowledge and insights, enabling more than 500,000 users to make better decisions, faster - every day. With offices in Sweden , Denmark , Norway , France , Spain and Portugal , Karnov Group employs around 1,300 people. The Karnov share is listed on Nasdaq Stockholm, Mid Cap segment under the ticker ""KAR"". For more information, please visit www.karnovgroup.com .

https://news.cision.com/karnov-group/r/karnov-group-launches-its-first-generative-ai-legal-assistant-at-today-s-capital-markets-day,c3848197

https://mb.cision.com/Main/4658/3848197/2340372.pdf"
A Smarter Slice: Domino's and MSFT in GenAI Hookup - Datanami,https://www.datanami.com/2023/10/04/a-smarter-slice-dominos-and-msft-in-genai-hookup/,"Wed, 04 Oct 2023 19:57:38 GMT",Datanami,"Don’t look now, but your next pie could come with a tasty slice of generative AI.

Microsoft and Domino’s Pizza yesterday unveiled a partnership that will see the new artificial intelligence technology incorporated into the pizza giant’s operations. The plan hinges around the development of a GenAI-powered assistant that will help Dominos store managers and staffers keep the pizza operation flowing smoothly.

Powered by Microsoft’s Azure OpenAI Service, the pizza bot will not only help store managers keep track of inventory and streamline staff scheduling, but will also help streamline pizza prep and quality control.

As part of the five-year partnership, Microsoft and Dominos will fund an Innovation Lab where engineers will fine-tune the development of the “smart store and ordering innovations” using GenAI technology. Customers will begin to taste the fruits of this GenAI labor within six months, the companies say.

“”We are thrilled to co-innovate with Microsoft using Azure AI technology to advance the future of pizza ordering and store technology powered by secure, connected data and simplified processes,” Kelly Garcia, Domino’s executive vice president and chief technology officer, said in a press release.

This is not the first time that fast food operators have dipped into the technological fryer to improve operational efficiency. Wendy’s, the purveyor of the square burger, has been at the vanguard of fast-food adoption of GenAI.

Earlier this year, Wendy’s announced a partnership with Google to develop new tech for its drive-thrus. Dubbed Wendy’s FreshAI, the system features a chatbot that will talk to customers and take their orders. The system was slated to be tested at a restaurant in Ohio over the summer.

But Wendy’s can’t take credit for the world’s first burger bot. That delicious title likely goes to Denver’s Good Times Burgers and Frozen Custard, which adopted AI technology to take drive-thru orders, as we reported back in 2019.

McDonalds has also been at the forefront of big data tech, including with self-service kiosks as well as back-office automation. In 2019, the burger giant spent $300 million to buy an Israeli software company that specializes in personalization and decision logic. The goal was to customize the contents of drive-thru menu based on variables like time of day, weather, current restaurant traffic, and trending menu items.

And of course we’d be remiss if we didn’t mention the DOM Pizza Checker, in which Domino’s Pizza franchises in New Zealand and Australia adopted computer vision AI technology to automatically detect flaws with pizzas as they’re coming out of the oven. Over the past couple of years, the DOM has expanded to US stores.

The fast food business would seem to be primed for all forms of automation, including the type provided by GenAI. In January 2024, a new law will go into effect in the state of California requiring fast-food workers to make a minimum of $20 per hour, up 29% from the current $15.50 per hour minimum.

Restaurant owners that oversee 38,000 stores in the state say the new law will force them to reduce jobs through automation, and to close some restaurants. The timing with the maturity of GenAI tech may help to minimize store closures, but only time will tell how the state’s 550,000 fast food workers will fare.

Related Items:

How AI Is Revolutionizing Fast Food

GenAI and the Future of Work: ‘Magic and Mayhem’

Gen AI Is Doing What?!"
5 Key Risks of Generative AI in the Workplace - Lexology,https://www.lexology.com/library/detail.aspx?g=54c18c2e-4780-4253-af81-de0a6fc44261,"Thu, 05 Oct 2023 11:16:41 GMT",Lexology,"Generative Artificial Intelligence is making headlines at the moment. Whilst AI as a technology has been around since the 1950s, new technological breakthroughs and the public launch of ChatGPT in November 2022 have put Generative AI at the forefront of public consciousness. It's clear that this technology has the power to transform the world…and the workplace.

Generative AI describes a form of machine learning whereby a computer system is trained on large datasets and, when prompted, is able to learn from these datasets and produce novel content.

It's not hard to think of the use cases for such technology in the workplace.

Whilst automation of tasks previously undertaken by humans is hardly new to the workplace, Generative AI is capable of levels of intelligence and cognitive understanding reminiscent of humans. This significantly expands the scope of tasks that it will ultimately be able to automate.

But before we all go and hang up our tools, it's important to bear in mind that there are still limitations on the capability of Generative AI. Whilst that is likely to change over time as the technology advances, for the moment it will need to be slowly integrated into businesses, rather than being adopted at the exclusion of all previous ways of working.

In this article, we are taking a brief look at the 5 key workplace risks to keep in mind when adopting any form of Generative AI in your business.

1. Redundancy

An inevitable result of the development of Generative AI is that as the technology develops and Generative AI is able to undertake tasks and produce content previously undertaken and produced by humans, the roles undertaken by those humans will no longer be necessary.

In the UK, dismissal of an employee will potentially be fair where it is on the grounds of redundancy. It is likely that automation of roles due to Generative AI would meet the definition of redundancy, as the new technology will result in a diminished need for employees to carry out their work.

In considering making redundancies, employers should be conscious of:

Their legal obligations during the redundancy process including (in the case of a redundancies involving more than 20 employees) their obligation to inform and consult with affected employees; Succession planning and the risk involved with making junior employees redundant and therefore not adequately training anyone to replace more senior roles that can't be automated; and Push-back from trade unions, works councils and employee representative bodies. The automation of jobs is likely to be met with chagrin by these bodies. Whilst pushback is inevitable, careful handling of the business' relationship with employees will be necessary to reduce the extent of the damage that could be inflicted by employee action.

2. Changes to Employee Terms & Conditions

In the short-term, rather than replacing roles entirely, Generative AI is likely to be adopted by businesses as a tool to be used alongside an employee's normal work in order to improve productivity.

Most good employment contracts will be drafted to allow for some flexibility in the types of duties that can be assigned to an employee. This will allow businesses to assign employees new tasks related to the use of Generative AI systems. Provided the change in employees' day-to-day work is only moderate, the business can likely make the change without requiring employee consent.

However, if the Generative AI tool is going to entirely change the employee's day-to-day work (for example, where their role goes from content generation to quality control of the content generated by a Generative AI tool), then the business will likely need to consult with the employee and seek their consent to that change.

Where the change is fundamental and consent is required, a failure to obtain consent could leave the business vulnerable to claims of breach of contract and constructive dismissal.

3. Discrimination

Businesses must ensure that there is no bias in the data being used to train their Generative AI systems which could result in discriminatory outcomes for employees.

In particular, where Generative AI is used to support decision-making on HR topics such as performance and recruitment, there is a risk that if the AI produces a discriminatory outcome, the employee could bring a claim for discrimination against the business, liability for which is uncapped.

In order to mitigate against this risk, businesses should think carefully about what data is used to train the Generative AI system, and should ensure appropriate checks and balances are in place to be able to reverse-engineer the outcome, identify and rectify any bias which does become evident.

4. Policies and Procedures

Businesses should consider if their policies and procedures are adapted for the ways in which Generative AI tools will be used in the workplace. For example, if the ability to use and quality check the output of Generative AI systems is going to become a fundamental part of an employee's role, consider whether that should be reflected in their performance expectations.

Businesses will also need to introduce new policies in relation to how employees should interact with Generative AI systems. In particular, if employees will be required to input data into the AI systems, the business should have policies in place to dictate appropriate use of data. Businesses should be particularly cautious to avoid employees inputting personal, copyrighted or biased data.

5. Training

The productivity gains that have been much lauded in relation to the adoption of Generative AI in the workplace are dependent on employees' ability to use the AI system correctly. Businesses should therefore take proactive steps to ensure that employees are trained on how to use the new technology. Failure to do so could make it difficult for businesses to performance manage employees down the line if they fail to fully adapt to the new systems.

Where employees will be required to input data into the AI systems, training should also cover the importance of data input to mitigating legal liability. As well as enabling the business to realise an increase in productivity, where training is fulsome enough, this should mitigate against the risk of various data protection, IP and employment claims."
"Governor Shapiro's Visit to CMU, Birthplace of AI, Marks Signing of Executive Order on Generative AI - India Education Diary",https://indiaeducationdiary.in/governor-shapiros-visit-to-cmu-birthplace-of-ai-marks-signing-of-executive-order-on-generative-ai/,"Thu, 05 Oct 2023 03:42:55 GMT",India Education Diary,"Carnegie Mellon University President Farnam Jahanian(opens in new window) welcomed Pennsylvania Gov. Josh Shapiro to campus on Sept. 20 to sign an executive order to establish responsible standards and a governance framework for generative artificial intelligence (AI) used by commonwealth agencies. The occasion also marked a new collaborative agreement between the Shapiro administration and CMU dedicated to promoting the responsible use of AI tools.

“When the people we serve in state government use these new technologies in their daily lives, well, they expect government to adapt and improve so we can better serve them. They expect that government will understand new technology. They expect that government will also set realistic and responsible guard rails so they can use that technology more effectively in their lives,” said Shapiro. “As a government leader, I’ve learned over the years that we need to lean in on innovation and learn to adapt to the changing tech environment in a responsible way … We don’t want to let AI happen to us, we want to be part of helping develop AI here in the commonwealth for the betterment of our citizenry.”

The governor was joined by Jahanian, Pennsylvania Secretary of Administration Neil Weaver and Chief Information Officer Amaya Capellán; Rayid Ghani(opens in new window), CMU Distinguished Career Professor in the Machine Learning Department(opens in new window) and the Heinz College of Information Systems and Public Policy(opens in new window); and Audrey Russo, president and CEO of the Pittsburgh Technology Council. The audience included elected officials, CMU trustees, student leaders, and local public and private sector leaders.

“I wanted CMU to be the backdrop for this incredibly important announcement on AI … because I know that you understand the power that technology has to transform people’s lives; transform the way we work; transform the way we get answers to our most pressing questions,” Shapiro said. “This university has long embraced the promise of new technology … And today, of course, CMU is on the frontlines of robotics and artificial intelligence research, exploring groundbreaking applications for rapidly evolving technology and also helping power our state’s economy.”"
Chinese regulators give AI firms a helping hand - 코리아타임스,https://www.koreatimes.co.kr/www/opinion/2023/10/197_360397.html,"Thu, 05 Oct 2023 06:50:00 GMT",코리아타임스,"By Angela Huyue Zhang

HONG KONG — If a Chinese tech firm wants to venture into generative artificial intelligence it is bound to face significant hurdles arising from stringent government control, at least according to popular perceptions. China was, after all, among the first countries to introduce legislation regulating the technology. But a closer look at the so-called interim measures on AI indicates that far from hampering the industry, China’s government is actively seeking to bolster it.

This should not be surprising. Already a global leader in AI (trailing only the United States), China has big ambitions in the sector — and the means to ensure that its legal and regulatory landscape encourages and facilitates indigenous innovation.

The interim measures on generative AI reflect this strategic motivation. To be sure, a preliminary draft of the legislation released by the Cyberspace Administration of China (CAC) included some encumbering provisions. For example, it would have required providers of AI services to ensure that the training data and the model outputs be “true and accurate,” and it gave firms just three months to recalibrate foundational models producing prohibited content.

But these rules were watered down significantly in the final legislation. The interim measures also significantly narrowed the scope of application, targeting only public-facing companies and mandating content-based security assessment solely for those wielding influence over public opinion.

While securing approval from the regulatory authorities does entail additional costs and a degree of uncertainty, there is no reason to think that Chinese tech giants — with their deep pockets and strong capacity for compliance — will be deterred. Nor is there reason to think that the CAC would seek to create unnecessary roadblocks: just two weeks after the interim measures went into effect, the agency gave the green light to eight companies, including Baidu and SenseTime, to launch their chatbots.

Overall, the interim measures advance a cautious and tolerant regulatory approach, which should assuage industry concerns over potential policy risks. The legislation even includes provisions explicitly encouraging collaboration among major stakeholders in the AI supply chain, reflecting a recognition that technological innovation depends on exchanges between government, industry, and academia.

So, while China was an early mover in regulating generative AI, it is also highly supportive of the technology and the companies developing it. Chinese AI firms might even have a competitive advantage over their American and European counterparts, which are facing strong regulatory headwinds and proliferating legal challenges.

In the European Union, the Digital Services Act, which entered into force last year, imposes a raft of transparency and due-diligence obligations on large online platforms, with massive penalties for violators. The General Data Protection Regulation — the world’s toughest data-privacy and security law — is also threatening to trip up AI firms. Already, OpenAI — the company behind ChatGPT — is under scrutiny in France, Ireland, Italy, Poland, and Spain for alleged breaches of GDPR provisions, with the Italian authorities earlier this year going so far as to halt the firm’s operations temporarily.

The EU’s AI Act, which is expected to be finalized by the end of 2023, is likely to saddle firms with a host of onerous pre-launch commitments for AI applications. For example, the latest draft endorsed by the European Parliament would require firms to provide a detailed summary of the copyrighted material used to train models — a requirement that could leave AI developers vulnerable to lawsuits.

American firms know firsthand how burdensome such legal proceedings can be. The U.S. federal government has yet to introduce comprehensive AI regulation, and existing state and sectoral regulation is patchy. But prominent AI companies such as OpenAI, Google, and Meta are grappling with private litigation related to everything from copyright infringement to data-privacy violations, defamation, and discrimination.

The potential costs of losing these legal battles are high. Beyond hefty fines, firms might have to adjust their operations to meet stringent remedies. In an effort to preempt further litigation, OpenAI is already seeking to negotiate content-licensing agreements with leading news outlets for AI training data.

Chinese firms, by contrast, can probably expect both regulatory agencies and courts — following official directives from the central government — to take a lenient approach to AI-related legal infringements. That is what happened when the consumer tech industry was starting out.

None of this is to say that China’s growth-centric regulatory approach is the right one. On the contrary, the government’s failure to protect the legitimate interests of Chinese citizens could have long-term consequences for productivity and growth, and shielding large tech firms from accountability threatens to entrench further their dominant market position, ultimately stifling innovation. Nonetheless, it appears clear that, at least in the short term, Chinese regulation will act as an enabler, rather than an impediment, for the country’s AI firms.

Angela Huyue Zhang, associate professor of law and director of the Center for Chinese Law at the University of Hong Kong, is the author of ""Chinese Antitrust Exceptionalism: How the Rise of China Challenges Global Regulation"" (Oxford University Press, 2021). This article was distributed by Project Syndicate (www.project-syndicate.org)."
Big Village commits to Harness the Power of Generative AI - Martechcube,https://www.martechcube.com/big-village-commits-to-harness-the-power-of-generative-ai/,"Thu, 05 Oct 2023 09:49:08 GMT",Martechcube,"Generative AI awareness is on the rise and Big Village plans to optimize AI opportunities to deliver to clients, investors, and shareholders.

Bright Mountain Media, Inc. (OTCQB: BMTM) (“Bright Mountain” or the “Company”), a global holding company with current investments in digital publishing, advertising technology, consumer insights, and creative media services, today announced that its wholly-owned subsidiary, Big Village Insights, a global research and analytics business uncovering not just the ‘what’ but the ‘why’ behind customer behavior, has been capitalizing on the benefits of Generative AI. This technology promises to reshape the marketing and advertising landscape by unlocking its transformative potential.

Matt Drinkwater, Chief Executive Officer of Bright Mountain Media, commented: “Generative AI is not just another buzzword; it’s a game-changer. With its potential yet to be fully realized, it’s an exciting time for brands and advertisers willing to harness its creative and transformative power. As we continue to explore and refine the applications of Generative AI, we’re sure to witness the dawn of a new era for digital advertising and media, one filled with innovation, creativity, and unprecedented engagement.”

Generative AI has emerged as one of the most promising and revolutionary technologies on the horizon, and Big Village Insights is diving into the opportunities. The Insights business has been utilizing AI tools since 2022 and has, since then:

Performed theming and sentiment analysis on 200k comments in the first 3 quarters of 2023

Implemented a variety of tools for summarizing and querying unstructured data

Leveraged AI for content creation and marketing collateral

Begun using an AI co-pilot for coding within engineering teams

Mr. Drinkwater continued: “As we delve deeper into the realm of Generative AI, it’s clear that this technology holds the key to a future where digital advertising and media are more engaging, personalized, and effective than ever. Brands and advertisers should embrace these exciting tools but with a mindful approach…The possibilities are vast, and we are only scratching the surface.”

For more such updates, follow us on Google News Martech News"
New ABI Research Webinar explores Generative AI in Manufacturing - Martechcube,https://www.martechcube.com/new-abi-research-webinar-explores-generative-ai/,"Thu, 05 Oct 2023 00:40:04 GMT",Martechcube,"The excitement around generative Artificial Intelligence (AI) in manufacturing comes from building out potential use cases, scaling from creating new designs to ultimately overhauling entire production processes. Global technology intelligence firm ABI Research is pleased to announce its upcoming webinar, Generative AI In Manufacturing: Transformative Technology or Potential Problem?, which will explore generative AI and its potentially transformative impact on the worldwide manufacturing ecosystem. This event is a must-attend for generative AI providers, manufacturing software providers, and manufacturers looking to understand which use cases fit their respective industry and company size.

Webinar Highlights:

ABI Research experts Senior Analyst Reece Hayden and Industry Analyst James Iverson will discuss impactful generative AI trends, anticipated manufacturing use cases, and potential pitfalls the sector will want to avoid. They will offer their unique perspective on the following critical questions:

Can open-source progress settle generative AI concerns?

Will generative AI be deployed at the edge?

What are generative AI’s manufacturing use cases, and which will be the big revenue creators?

What are the merits of an AI partnership vs. going alone for manufacturing software providers?

What strategies should underline generative AI deployment?

Date: October 11, 2023

Time: 11 AM, EST

Location: Virtual Webinar.

Save your spot: Register Now.

For more such updates, follow us on Google News Martech News"
Opsera Announces Series A Plus Round to Power New Generative ... - AiThority,https://aithority.com/machine-learning/opsera-announces-series-a-plus-round-to-power-new-generative-ai-initiatives/,"Thu, 05 Oct 2023 10:09:44 GMT",AiThority,"Opsera introduces Hummingbird AI engine to provide AI capabilities across the platform to help engineering teams ship products faster at leading global companies

Opsera, the Unified DevOps platform used by top Fortune 500 companies, announced a Series A Plus round of $12 million in funding. The latest round of funding will support Hummingbird AI, a new generative AI initiative, and accelerate the growth of Opsera – Hummingbird AI will introduce new and exciting features into the DevOps and DevSecOps categories. The latest funding round is led by Taiwania Capital with support from existing investors Felicis Ventures, Clear Ventures, and others.

Recommended: Understanding Artificial Intelligence’s Role in Accelerating Africa’s Healthcare Momentum

The Opsera Unified DevOps Platform, powered by Hummingbird AI, includes AI-driven unified insights to help improve developer experience and productivity, help identify bottlenecks and inefficiencies and provide remediations with the click of a button. Another feature within Hummingbird AI will empower enterprise developers to accelerate innovation by deploying large language models (LLM) across multiple clouds seamlessly using a templated approach. Hummingbird AI will bring compliance around security and quality assurance with bias scoring and cost management within LLMs.

“Today’s enterprise software organizations are constantly looking for ways to improve their time to value,” said Huang Lee, Managing Partner of Taiwania Capital. “The Opsera Unified DevOps Platform gives engineering teams the flexibility and control they need while assuring quality and security standards are strictly met. We are excited to support Opsera as it continues to scale quickly and leverage AI technology, including LLMs, to revolutionize the way software is developed and deployed.”

“Congratulations to the Opsera team on their latest funding round,” said Wesley Chan, co-founder and Managing Partner of FPV Ventures. “We recognized Opsera’s unwavering commitment to helping engineering teams work better and deliver value faster. We’re excited to see Hummingbird AI added to Opsera’s Unified DevOps Platform as it will continue to help increase cost-efficiency, free up valuable engineering time, and offer unparalleled insights into the DevOps lifecycle.”

“As one of the original early-stage investors of Opsera, we are proud to see the company continue to scale at an impressive rate,” said Rajeev Madhavan, co-founder and Partner of Clear Ventures. “Now, more than ever, leading global organizations are looking to tap the most value out of their current technology investments. With the introduction of Hummingbird AI, Opsera Unified DevOps platform empowers organizations to build high-performance engineering teams, reach new levels of productivity gains, and efficiencies and be equipped to tackle the complex challenges of today’s digital landscape.”

“Today marks a major milestone for Opsera and our customers as we continue to chart new strategies to help enterprise customers gain the most value out of their technology investments and innovations,” said Kumar Chivukula, co-founder and CEO of Opsera.

AiThority Interview Insights : AIThority Interview with David Lambert, VP & GM, Strategy & Growth, APAC, Medallia

“With the Opsera Unified DevOps Platform, our users release 80% faster and improve security and quality posture by 60%,” continued Chivukula. “Now with Hummingbird AI, users from across the organization will be able to improve efficiency, security and quality even more and have critical insights right at their fingertips with a 100% shift-left approach. With the support of Taiwania Capital and all of our investment partners, we will continue to accelerate how we help customers along their DevOps and DevSecOps journeys.”

The new Hummingbird AI capabilities within Opsera’s DevOps platform combine generative AI and MLOps technology to allow engineers to:

Improve Organizational Efficiency, Security, and Quality through prompt-based recommendations, analysis, remediations and insights driven by the entire organization’s software development lifecycle data and toolchain.

through prompt-based recommendations, analysis, remediations and insights driven by the entire organization’s software development lifecycle data and toolchain. Leverage the Best-in-Class Opsera Platform Capabilities for MLOps Orchestration, making deployments faster, smarter and more secure across multi-cloud solutions. Gain visibility across efficacy scoring and bias detection.

making deployments faster, smarter and more secure across multi-cloud solutions. Gain visibility across efficacy scoring and bias detection. Embrace Holistic Security and Observability with security score cards, remediation efforts and recommendations to improve the organization’s overall security and quality posture.

with security score cards, remediation efforts and recommendations to improve the organization’s overall security and quality posture. Gain AI-powered Critical Intelligence and Actionable Insights including DORA metrics, developer productivity and experience insights, and security and quality metrics.

including DORA metrics, developer productivity and experience insights, and security and quality metrics. Launch Developer-Friendly, Automated Workflows across SDLC, SaaS, IaC, and COTS applications.

across SDLC, SaaS, IaC, and COTS applications. Pipeline Summary and Remediations for each pipeline to improve the process and recover from the failures with reduced Mean Time to identification for issues/anomalies.

“DevOps teams are under pressure to support more critical apps across more clouds, and pipelines, data, security, and architecture are becoming more complex and harder to manage,” said Dan Turchin, CEO of PeopleReign and host of the popular podcast AI and the Future of Work. “Teams need to invest in automation and AI to detect issues that can lead to expensive outages. Only Opsera and Hummingbird AI combine the ease of use and conversational fluency expected from LLM-first applications with the flexibility to observe pipelines across workloads.”

With new funding and capabilities, Opsera empowers engineers to positively impact the entire software development lifecycle in a few clicks. With Hummingbird AI, Opsera is creating a unified, high-performing, intuitive DevOps experience driven by the latest AI innovations to help customers achieve their own innovations faster.

Recommended: Is Your Beautiful Content Going into a Black Hole?

[To share your insights with us, please write to sghosh@martechseries.com]"
Generative AI: The Foundation for the Next Era of Human-Computer ... - Medium,https://medium.com/@pareto_investor/generative-ai-the-foundation-for-the-next-era-of-human-computer-interaction-2a1e65b4fff6,"Thu, 05 Oct 2023 09:00:24 GMT",Medium,
Canva Bolsters AI Toolkit with Video Generation by Runway - Decrypt,https://decrypt.co/200251/canva-ai-magic-generative-tool-runway,"Thu, 05 Oct 2023 01:48:44 GMT",Decrypt,
"Google's Android 14 features generative AI wallpapers, six-digit PINs and more - Neowin",https://www.neowin.net/news/googles-android-14-features-generative-ai-wallpapers-six-digit-pins-and-more/,"Wed, 04 Oct 2023 18:01:00 GMT",Neowin,"Google has showcased the latest version of Android, Android 14, at today's Google Event. Alongside several other launches like Pixel 8, Pixel Watch 2, and Pixel Buds Pro, the company has shared new features and customization options available with Android 14.

In a blog post, Google introduced Android 14 stating:

“Android releases are one of the many ways your Android phone gets better over time. Last year, we introduced Android 13, bringing you features like Spatial Audio, messaging app streaming, cross-device copy/paste, a new media player and so much more. We also did something a bit unusual for us: We brought forward several large-screen features originally planned for Android 14 and made them available as updates to Android 13. Those updates include improved multitasking, a refined Taskbar, and improved foldable support with bigger and better apps.”

Android 14 brings an updated customization picker that makes it easier for users to switch between wallpapers and update what they want to see at a glance. Users can set custom lock screen shortcuts to apps such as the QR reader or the Google Home app to have easy one-tap access right from their lock screens.

There are also new lock screen templates for fonts, widgets, and colors that individuals can choose from to personalize their devices further. The capability uses AI to adjust screens based on the user's situation, so if there are unexpected changes in the weather, the weather widget becomes more prominent.

Coming to Pixel 8/8 Pro first, Android 14 is also offering generative AI wallpapers. The feature employs AI-generated text-to-image diffusion models to help users create their desired wallpapers. They can also choose from pre-set suggestions to enjoy unique wallpapers.

Building on the technology of high dynamic range (HDR) video in Android 13, Android 14 brings users HDR images with Ultra HDR to display and snap high-definition photos with vibrant colors.

Google also mentioned that Health Connect is now built into Android 14 settings, which organizes user data in one place and ensures privacy through data encryption. The update also provides more transparency to users on how their data is being used.

Google stated that on Android 14 when an app asks for permission for information like location, users will be notified whenever that app is sharing that data with third parties to help the user decide whether or not to grant access.

Additionally, Android 14 provides stronger digital protection for device PIN codes as well. It does so by allowing individuals to set a six-digit PIN, which, once entered correctly, will cause the device to unlock automatically.

Apart from these, Google has also introduced vision-and hearing-inclusive features. Low-vision users can get an improved magnifier where they can pinch to zoom in and out from 100%. They can also change the magnifier size and opt for the “Keep on when switching apps” feature to prevent the magnifier from being disabled when switching apps.

Additionally, Android 14’s font size Quick Settings tile offers users nonlinear font scaling to prevent texts from getting larger than necessary. Other accessibility features include a dedicated hearing-aid setup and “Flash notifications” from the Accessibility and Notifications settings to get visual light flashes for incoming notifications.

Android 14 has been released today on supported Pixel devices. But, on other Android devices like Samsung Galaxy, iQOO, Nothing, OnePlus, Oppo, Realme, Sharp, Sony, Tecno, Vivo, and Xiaomi, it will be available later this year. You can read more on Android 14 here."
